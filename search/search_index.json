{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Overview # Join Red Hat\u00ae and Microsoft for a hands-on workshop with Azure Red Hat OpenShift\u00ae (ARO). During the event, Red Hat Cloud Services experts will guide you through the ARO architecture and answer your questions. The workshop will cover both Operations and Developer activities, and will give the user a feel for how ARO will work for your team and workloads. Who should attend: This in-person workshop is ideal for developers, architects and operations engineers who need a flexible and proven platform to build, deploy and scale applications. What to expect: During the workshop, we will guide you through content to help you understand some of the concepts of deploying container-based applications on Azure Red Hat OpenShift and how to operate an Azure Red Hat OpenShift cluster. We will cover the following: Content Overview: # Learn how simple it is to deploy and configure Azure Red Hat Openshift Complete Day 2 operations tasks such as configuring node and cluster scaling policies, configuring managed upgrades, and using labels for deterministic app placement on nodes Learn how to leverage Azure Service Operator to manage and use Azure Services directly from OpenShift Deploy an application using CI/CD and expose the application using the Azure Front Door Service Use Azure Arc for logging and monitoring of OpenShift and containerized applications Deploy an application that uses an Azure Managed Database Learn how to use OpenShift Service Mesh for application observability and tracing Make an application on OpenShift scalable and resistant to node failures and upgrades Get experience with, and an informed view of Azure Red Hat OpenShift. Confirm your spot in this workshop, register today to save your seat. Prerequisites: Access to an Azure subscription and Azure Red Hat OpenShift environment which will be provided during the lab. You will receive access at the beginning of the workshop. Get a personal GitHub account. You can sign up for free here . Registration: https://events.redhat.com/profile/form/index.cfm?PKformID=0x688979abcd","title":"Welcome"},{"location":"#overview","text":"Join Red Hat\u00ae and Microsoft for a hands-on workshop with Azure Red Hat OpenShift\u00ae (ARO). During the event, Red Hat Cloud Services experts will guide you through the ARO architecture and answer your questions. The workshop will cover both Operations and Developer activities, and will give the user a feel for how ARO will work for your team and workloads. Who should attend: This in-person workshop is ideal for developers, architects and operations engineers who need a flexible and proven platform to build, deploy and scale applications. What to expect: During the workshop, we will guide you through content to help you understand some of the concepts of deploying container-based applications on Azure Red Hat OpenShift and how to operate an Azure Red Hat OpenShift cluster. We will cover the following:","title":"Overview"},{"location":"#content-overview","text":"Learn how simple it is to deploy and configure Azure Red Hat Openshift Complete Day 2 operations tasks such as configuring node and cluster scaling policies, configuring managed upgrades, and using labels for deterministic app placement on nodes Learn how to leverage Azure Service Operator to manage and use Azure Services directly from OpenShift Deploy an application using CI/CD and expose the application using the Azure Front Door Service Use Azure Arc for logging and monitoring of OpenShift and containerized applications Deploy an application that uses an Azure Managed Database Learn how to use OpenShift Service Mesh for application observability and tracing Make an application on OpenShift scalable and resistant to node failures and upgrades Get experience with, and an informed view of Azure Red Hat OpenShift. Confirm your spot in this workshop, register today to save your seat. Prerequisites: Access to an Azure subscription and Azure Red Hat OpenShift environment which will be provided during the lab. You will receive access at the beginning of the workshop. Get a personal GitHub account. You can sign up for free here . Registration: https://events.redhat.com/profile/form/index.cfm?PKformID=0x688979abcd","title":"Content Overview:"},{"location":"app/2-1-deploy-frontend/","text":"Install the Frontend # To install the frontend part of the application, we will be manually building the container image, storing the image in Azure Container Registry and then use manifests to install the frontend. Later on in the workshop, we will be making changes to the source code so the first step you will need to do is fork the code repository. Open the following GitHub repository and Fork it to your local Git Hub account. https://github.com/rh-mobb/aro-workshop-ratings-web Setup git # git config --global user.email \"<your github email>\" git config --global user.name \u201c<your github username>\u201d git init Clone the Git Repo # From the Azure Cloud Shell, clone the git repo. git clone https://github.com/<YOUR GIT NAME>/aro-workshop-ratings-web Deploy the application # oc new-app --name rating-web https://github.com/<YOUR GIT NAME/aro-workshop-ratings-web Set the API endpoint environment variable oc set env deploy/rating-web API = http://rating-api.ratingsapp.svc.cluster.local:3000 Expose the application oc expose svc rating-web Get the application url oc get routes Open the hostname retrieved above in your web browser with http:// ... not HTTP and not HTTPS Now that we have a working app, we are going to update the build to push the image to your Azure Container Registry. Start by getting the password for your Azure Container Registry Instance: az acr update -n $REGISTRY_NAME --admin-enabled true ACRPWD = $( az acr credential show -n $REGISTRY_NAME --query 'passwords[0].value' -o tsv ) Create a secret for ACR and link it. oc create secret docker-registry \\ --docker-server = $REGISTRY_NAME .azurecr.io \\ --docker-username = $REGISTRY_NAME \\ --docker-password = $ACRPWD \\ --docker-email = unused \\ acr-secret -n ratingsapp oc secrets link default acr-secret --for = pull,mount oc secrets link builder acr-secret --for = pull,mount Update the BuildConfig to user Azure Container Registry # From the OpenShift Console, click on Builds, BuildConfigs and then the rating-web build config Click on YAML and then scroll down to the output section and change it so it loosk like this and click save. Info Make sure to change the acr registry URL to match the one you created. ACR does not allow '-' in the name so the name of your registry starts with your userid without the '-' followed by registry. The example below is for the user-8 userid. output: to: kind: DockerImage name: <YOUR USER ID>registry.azurecr.io/ratings-web pushSecret: name: acr-secret Rebuild the application so that is now pushes the image to the Azure Container Registry. oc start-build rating-web View the logs of the build. Start by find the build pod name: oc get pods look for the name of the builder pod that is running and get the logs of that pod oc logs rating-web-2-build -f The build process takes a few minutes, wait until the process finishes and you see that the image was succesfully push to ACR. Finally, you can check with ACR directly to see the repository and images that you have pushed for the frontend. From the Azure Cloud Shell, run: az acr repository show-tags --name user8registry --repository ratings-web -o table Expected Output:","title":"Deploy the frontend"},{"location":"app/2-1-deploy-frontend/#install-the-frontend","text":"To install the frontend part of the application, we will be manually building the container image, storing the image in Azure Container Registry and then use manifests to install the frontend. Later on in the workshop, we will be making changes to the source code so the first step you will need to do is fork the code repository. Open the following GitHub repository and Fork it to your local Git Hub account. https://github.com/rh-mobb/aro-workshop-ratings-web","title":"Install the Frontend"},{"location":"app/2-1-deploy-frontend/#setup-git","text":"git config --global user.email \"<your github email>\" git config --global user.name \u201c<your github username>\u201d git init","title":"Setup git"},{"location":"app/2-1-deploy-frontend/#clone-the-git-repo","text":"From the Azure Cloud Shell, clone the git repo. git clone https://github.com/<YOUR GIT NAME>/aro-workshop-ratings-web","title":"Clone the Git Repo"},{"location":"app/2-1-deploy-frontend/#deploy-the-application","text":"oc new-app --name rating-web https://github.com/<YOUR GIT NAME/aro-workshop-ratings-web Set the API endpoint environment variable oc set env deploy/rating-web API = http://rating-api.ratingsapp.svc.cluster.local:3000 Expose the application oc expose svc rating-web Get the application url oc get routes Open the hostname retrieved above in your web browser with http:// ... not HTTP and not HTTPS Now that we have a working app, we are going to update the build to push the image to your Azure Container Registry. Start by getting the password for your Azure Container Registry Instance: az acr update -n $REGISTRY_NAME --admin-enabled true ACRPWD = $( az acr credential show -n $REGISTRY_NAME --query 'passwords[0].value' -o tsv ) Create a secret for ACR and link it. oc create secret docker-registry \\ --docker-server = $REGISTRY_NAME .azurecr.io \\ --docker-username = $REGISTRY_NAME \\ --docker-password = $ACRPWD \\ --docker-email = unused \\ acr-secret -n ratingsapp oc secrets link default acr-secret --for = pull,mount oc secrets link builder acr-secret --for = pull,mount","title":"Deploy the application"},{"location":"app/2-1-deploy-frontend/#update-the-buildconfig-to-user-azure-container-registry","text":"From the OpenShift Console, click on Builds, BuildConfigs and then the rating-web build config Click on YAML and then scroll down to the output section and change it so it loosk like this and click save. Info Make sure to change the acr registry URL to match the one you created. ACR does not allow '-' in the name so the name of your registry starts with your userid without the '-' followed by registry. The example below is for the user-8 userid. output: to: kind: DockerImage name: <YOUR USER ID>registry.azurecr.io/ratings-web pushSecret: name: acr-secret Rebuild the application so that is now pushes the image to the Azure Container Registry. oc start-build rating-web View the logs of the build. Start by find the build pod name: oc get pods look for the name of the builder pod that is running and get the logs of that pod oc logs rating-web-2-build -f The build process takes a few minutes, wait until the process finishes and you see that the image was succesfully push to ACR. Finally, you can check with ACR directly to see the repository and images that you have pushed for the frontend. From the Azure Cloud Shell, run: az acr repository show-tags --name user8registry --repository ratings-web -o table Expected Output:","title":"Update the BuildConfig to user Azure Container Registry"},{"location":"app/2-2-deploy-backend/","text":"Deploy the backend Application # We will start by deploying a backend application that will connect to the Cosmos Database that we just created. Create a new project # Start by creating a new project that will contain both our frontend and backend microservices for the applications oc new-project ratingsapp Create the backend part of the application. # We will be using the source to image process to create the backend where all we will need to do is point to the github repository that contains the code for the backend. OpenShift will take care of the rest and will build and deploy the backend. oc new-app --name rating-api https://github.com/rh-mobb/aro-workshop-ratings-api Next, we need to set a couple environment variables to connect the back to our database: cosmosKey = $( az cosmosdb keys list -n $COSMOSDB_NAME -g $USERID --query \"primaryMasterKey\" -o tsv ) COSMOSDB_URI_CONNECTIONSTRING = \"mongodb:// $COSMOSDB_NAME : $cosmosKey @ $COSMOSDB_NAME .mongo.cosmos.azure.com:10255/ratingsdb?ssl=true&replicaSet=globaldb&retrywrites=false&appName=@ $COSMOSDB_NAME @\" oc set env deploy/rating-api MONGODB_URI = $COSMOSDB_URI_CONNECTIONSTRING Check the Pods # note it will take about 3 minutes for the application pods to be created. oc get pods expected output: Make sure the database is connected # Using the name of the pod above, check the pod logs and look for a log entry that shows the database is connected.","title":"Deploy the backend"},{"location":"app/2-2-deploy-backend/#deploy-the-backend-application","text":"We will start by deploying a backend application that will connect to the Cosmos Database that we just created.","title":"Deploy the backend Application"},{"location":"app/2-2-deploy-backend/#create-a-new-project","text":"Start by creating a new project that will contain both our frontend and backend microservices for the applications oc new-project ratingsapp","title":"Create a new project"},{"location":"app/2-2-deploy-backend/#create-the-backend-part-of-the-application","text":"We will be using the source to image process to create the backend where all we will need to do is point to the github repository that contains the code for the backend. OpenShift will take care of the rest and will build and deploy the backend. oc new-app --name rating-api https://github.com/rh-mobb/aro-workshop-ratings-api Next, we need to set a couple environment variables to connect the back to our database: cosmosKey = $( az cosmosdb keys list -n $COSMOSDB_NAME -g $USERID --query \"primaryMasterKey\" -o tsv ) COSMOSDB_URI_CONNECTIONSTRING = \"mongodb:// $COSMOSDB_NAME : $cosmosKey @ $COSMOSDB_NAME .mongo.cosmos.azure.com:10255/ratingsdb?ssl=true&replicaSet=globaldb&retrywrites=false&appName=@ $COSMOSDB_NAME @\" oc set env deploy/rating-api MONGODB_URI = $COSMOSDB_URI_CONNECTIONSTRING","title":"Create the backend part of the application."},{"location":"app/2-2-deploy-backend/#check-the-pods","text":"note it will take about 3 minutes for the application pods to be created. oc get pods expected output:","title":"Check the Pods"},{"location":"app/2-2-deploy-backend/#make-sure-the-database-is-connected","text":"Using the name of the pod above, check the pod logs and look for a log entry that shows the database is connected.","title":"Make sure the database is connected"},{"location":"app/2A-deploy-app/","text":"Deploy and Expose an Application ( Part 1 ) # Securing exposing an Internet facing application with an ARO Cluster. When you create a cluster on ARO you have several options in making the cluster public or private. With a public cluster you are allowing Internet traffic to the api and *.apps endpoints. With a private cluster you can make either or both the api and .apps endpoints private. How can you allow Internet access to an application running on your private cluster where the .apps endpoint is private? This document will guide you through using Azure Frontdoor to expose your applications to the Internet. There are several advantages of this approach, namely your cluster and all the resources in your Azure account can remain private, providing you an extra layer of security. Azure FrontDoor operates at the edge so we are controlling traffic before it even gets into your Azure account. On top of that, Azure FrontDoor also offers WAF and DDoS protection, certificate management and SSL Offloading just to name a few benefits. Info In this workshop we are using public clusters to simplify connectity to the environment. Even though we are using a public cluster, the same methodology applies to expose an application to the Internet from a private cluster. To similate a private cluster, we will be creating a 2nd private Ingress Controller. Prerequisites # a unique USER ID Azure Database for PostgreSQL Azure Container Registry Instance and Password A public GitHub id ( only required for the 'Automate Deploying the App' ) Deploy an application # Now the fun part, let's deploy an application! We will be deploying a Java based application called microsweeper . This is an application that runs on OpenShift and uses a PostgreSQL database to store scores. With ARO being a first class service on Azure, we will create an Azure Database for PostgreSQL service and connect it to our cluster with a private endpoint. Prerequisites - this part of the workshop assumes you have already created a Azure Database for PostgreSQL database named -microsweeper-database that you created and configured in a previous step. Info Throughout this tutorial, we will be distinguishing your application and resources based on a USERID assigned to you. Please see a facilitator if they have not given you a USER ID. From the Azure Cloud Shell, set an environment variable for your user id and the Azure Resource Group given to you by the facilitor: export USERID = <The user ID a facilitator gave you> export ARORG = <The Azure Resource Group a facilitator gave you> export ARO_APP_FQDN = minesweeper. $USERID .azure.mobb.ninja Clone the git repository The first thing we need to do is get a copy of the code that we will build and deploy to our clusters. git clone https://github.com/rh-mobb/aro-hackaton-app Change to the root directory cd aro-hackaton-app Log into your openshift cluster with Azure Cloud Shell Switch to your OpenShift Project oc project <USER ID> Info As part of the workshop setup, an OpenShift project has been created using your USERID as the name of the project Add the OpenShift extension to quarkus quarkus ext add openshift Edit aro-hackaton-app/src/main/resources/application.properties Make sure your file looks like the one below, changing the following line: %prod.quarkus.datasource.jdbc.url=jdbc:postgresql:// -minesweeper-database:5432/score Change the above line with your USERID for the database that has been already been configured for you %prod.quarkus.container-image.group= Change the above line with your USERID for the namespace to deploy the application to Info Note the options in OpenShift Configurations. - %prod.quarkus.openshift.deployment-kind=Deployment We will be creating a deployment for the application. - %prod.quarkus.openshift.build-strategy=docker The application will be built uisng Docker. - %prod.quarkus.container-image.group=minesweeper The application will use the namespace your facilitator assigned to you. - %prod.quarkus.openshift.expose=true We will expose the route using the default openshift router domain - apps.\\<cluster-id>.eastus.aroapp.io Sample microsweeper-quarkus/src/main/resources/application.properties # Database configurations %prod.quarkus.datasource.db-kind=postgresql %prod.quarkus.datasource.jdbc.url=jdbc:postgresql://<USERID>-minesweeper-database:5432/score %prod.quarkus.datasource.jdbc.driver=org.postgresql.Driver %prod.quarkus.datasource.username=quarkus %prod.quarkus.datasource.password=r3dh4t1! %prod.quarkus.hibernate-orm.database.generation=drop-and-create %prod.quarkus.hibernate-orm.database.generation=update # OpenShift configurations %prod.quarkus.kubernetes-client.trust-certs=true %prod.quarkus.kubernetes.deploy=true %prod.quarkus.kubernetes.deployment-target=openshift #%prod.quarkus.kubernetes.deployment-target=knative %prod.quarkus.openshift.build-strategy=docker %prod.quarkus.openshift.expose=true %prod.quarkus.openshift.deployment-kind=Deployment %prod.quarkus.container-image.group=<CHANGE TO YOUR NAMESPACE> # Serverless configurations #%prod.quarkus.container-image.group=microsweeper-%prod.quarkus #%prod.quarkus.container-image.registry=image-registry.openshift-image-registry.svc:5000 # macOS configurations #%prod.quarkus.native.container-build=true Build and deploy the quarkus application to OpenShift. One of the great things about OpenShift is the concept of Source to Image, where you simply point to your source code and OpenShift will build and deploy your application. In this first example, we will be using source to image and build configs that come built in with Quarkus and OpenShift. To start the build ( and deploy ) process simply run the following command. quarkus build --no-tests Let's take a look at what this did along with everything that was created in your cluster. Container Images # Log into the OpenShift Console and from the Administrator perspective, expand Builds and then Image Streams, and select the minesweeper Project. You will see two images that were created on your behalf when you ran the quarkus build command. There is one image for openjdk-11 that comes with OpenShift as a Universal Base Image (UBI) that the application will run under. With UBI, you get highly optimized and secure container images that you can build your applications with. For more information on UBI please read this article The second image you see is the the microsweeper-appservice image. This is the image for the application that was built automatically for you and pushed to the container registry that comes with OpenShift. Image Build # How did those images get built you ask? Back on the OpenShift Console, click on Build Configs and then the microsweeper-appservice entry. When you ran the quarkus build command, this created the BuildConfig you can see here. In our quarkus settings, we set the deployment strategy to build the image using Docker. The Dockerfile file from the git repo that we cloned was used for this Build Config. Info A build configuration describes a single build definition and a set of triggers for when a new build is created. Build configurations are defined by a BuildConfig, which is a REST object that can be used in a POST to the API server to create a new instance. You can read more about BuildConfigs here Once the BuildConfig was created, the source to image process kicked off a Build of that BuildConfig. The build is what actually does the work in building and deploying the image. We started with defining what to be built with the BuildConfig and then actually did the work with the Build. You can read more about Builds here To look at what the build actually did, click on Builds tab and then into the first Build in the list. On the next screen, explore around and look at the YAML definition of the build, Logs to see what the build actually did. If you build failed for some reason, logs is a great first place to start to look at to debug what happened. Image Deployment # After the image was built, the S2I process then deployed the application for us. In the quarkus properties file, we specified that a deployment should be created. You can view the deployment under Workloads, Deployments, and then click on the Deployment name. Explore around the deployment screen, check out the different tabs, look at the YAML that was created. Look at the pod the deployment created, and see that it is running. The last thing we will look at is the Route that was created for our application. In the quarkus properties file, we specified that the application should be exposed to the Internet. When you create a Route, you have the option to specify a hostname. To start with, we will just use the default domain that comes with ARO useast.aroapp.io in our case. In next section, we will expose the same appplication to a custom domain leveraging Azure Front Door. You can read more about Routes here From the OpenShift menu, click on Networking, Routes, and the microsweeper-appservice route. Test the application # While in the Route section of the OpenShift UI, click the url under location: You can also get the the url for your application using the command line: oc get routes -o json | jq -r '.items[0].spec.host' Point your browser to the application!! Application IP # Let's take a quick look at what IP the application resolves to. Back in your Cloud Shell environment, run nslookup <route host name> i.e. nslookup microsweeper-appservice-minesweeper.apps.fiehcjr1.eastus.aroapp.io You should see results like the following: Notice the IP address - can you guess where it comes from? It comes from the ARO Load Balancer. In this workshop, we are using a Public Cluster which means the load balancer is exposed to the Internet. If this was a private cluster, you would have to have connectivity to the VNET ARO is running on whether that be VPN, Express Route, or something else. To view the ARO load balancer, on the Azure Portal, Search for 'Load Balancers' and click on the Load balancers service. Scroll down the list of load balancers until you see the one with your cluster name. You will notice two load balancers, one that has -internal in the name and one that does not. The '*-internal' load balancer is used for the OpenShift API. The other load balancer ( without -internal ) in the name is use the public load balancer used for the default Ingress Controller. Click into the load balancer for applications. On the next screen, click on Frontend IP configuration. Notice the IP address of the 2nd load balancer on the list. This IP address matches what you found with the nslookup command. For the fun of it, we can also look at what backends this load balancer is connected to. Click into the 2nd load balancer on the list above, and then click into the first rule. On the next screen, notice the Backend pool. This is the subnet that contains all the workers. And the best part is all of this came with OpenShift and ARO! Continue to Part 2 of Deploy and Expose an App to expose the same application using a custom domain leveraging Azure Front Door.","title":"Deploy and Expose an Application ( Part 1 )"},{"location":"app/2A-deploy-app/#deploy-and-expose-an-application-part-1","text":"Securing exposing an Internet facing application with an ARO Cluster. When you create a cluster on ARO you have several options in making the cluster public or private. With a public cluster you are allowing Internet traffic to the api and *.apps endpoints. With a private cluster you can make either or both the api and .apps endpoints private. How can you allow Internet access to an application running on your private cluster where the .apps endpoint is private? This document will guide you through using Azure Frontdoor to expose your applications to the Internet. There are several advantages of this approach, namely your cluster and all the resources in your Azure account can remain private, providing you an extra layer of security. Azure FrontDoor operates at the edge so we are controlling traffic before it even gets into your Azure account. On top of that, Azure FrontDoor also offers WAF and DDoS protection, certificate management and SSL Offloading just to name a few benefits. Info In this workshop we are using public clusters to simplify connectity to the environment. Even though we are using a public cluster, the same methodology applies to expose an application to the Internet from a private cluster. To similate a private cluster, we will be creating a 2nd private Ingress Controller.","title":"Deploy and Expose an Application ( Part 1 )"},{"location":"app/2A-deploy-app/#prerequisites","text":"a unique USER ID Azure Database for PostgreSQL Azure Container Registry Instance and Password A public GitHub id ( only required for the 'Automate Deploying the App' )","title":"Prerequisites"},{"location":"app/2A-deploy-app/#deploy-an-application","text":"Now the fun part, let's deploy an application! We will be deploying a Java based application called microsweeper . This is an application that runs on OpenShift and uses a PostgreSQL database to store scores. With ARO being a first class service on Azure, we will create an Azure Database for PostgreSQL service and connect it to our cluster with a private endpoint. Prerequisites - this part of the workshop assumes you have already created a Azure Database for PostgreSQL database named -microsweeper-database that you created and configured in a previous step. Info Throughout this tutorial, we will be distinguishing your application and resources based on a USERID assigned to you. Please see a facilitator if they have not given you a USER ID. From the Azure Cloud Shell, set an environment variable for your user id and the Azure Resource Group given to you by the facilitor: export USERID = <The user ID a facilitator gave you> export ARORG = <The Azure Resource Group a facilitator gave you> export ARO_APP_FQDN = minesweeper. $USERID .azure.mobb.ninja Clone the git repository The first thing we need to do is get a copy of the code that we will build and deploy to our clusters. git clone https://github.com/rh-mobb/aro-hackaton-app Change to the root directory cd aro-hackaton-app Log into your openshift cluster with Azure Cloud Shell Switch to your OpenShift Project oc project <USER ID> Info As part of the workshop setup, an OpenShift project has been created using your USERID as the name of the project Add the OpenShift extension to quarkus quarkus ext add openshift Edit aro-hackaton-app/src/main/resources/application.properties Make sure your file looks like the one below, changing the following line: %prod.quarkus.datasource.jdbc.url=jdbc:postgresql:// -minesweeper-database:5432/score Change the above line with your USERID for the database that has been already been configured for you %prod.quarkus.container-image.group= Change the above line with your USERID for the namespace to deploy the application to Info Note the options in OpenShift Configurations. - %prod.quarkus.openshift.deployment-kind=Deployment We will be creating a deployment for the application. - %prod.quarkus.openshift.build-strategy=docker The application will be built uisng Docker. - %prod.quarkus.container-image.group=minesweeper The application will use the namespace your facilitator assigned to you. - %prod.quarkus.openshift.expose=true We will expose the route using the default openshift router domain - apps.\\<cluster-id>.eastus.aroapp.io Sample microsweeper-quarkus/src/main/resources/application.properties # Database configurations %prod.quarkus.datasource.db-kind=postgresql %prod.quarkus.datasource.jdbc.url=jdbc:postgresql://<USERID>-minesweeper-database:5432/score %prod.quarkus.datasource.jdbc.driver=org.postgresql.Driver %prod.quarkus.datasource.username=quarkus %prod.quarkus.datasource.password=r3dh4t1! %prod.quarkus.hibernate-orm.database.generation=drop-and-create %prod.quarkus.hibernate-orm.database.generation=update # OpenShift configurations %prod.quarkus.kubernetes-client.trust-certs=true %prod.quarkus.kubernetes.deploy=true %prod.quarkus.kubernetes.deployment-target=openshift #%prod.quarkus.kubernetes.deployment-target=knative %prod.quarkus.openshift.build-strategy=docker %prod.quarkus.openshift.expose=true %prod.quarkus.openshift.deployment-kind=Deployment %prod.quarkus.container-image.group=<CHANGE TO YOUR NAMESPACE> # Serverless configurations #%prod.quarkus.container-image.group=microsweeper-%prod.quarkus #%prod.quarkus.container-image.registry=image-registry.openshift-image-registry.svc:5000 # macOS configurations #%prod.quarkus.native.container-build=true Build and deploy the quarkus application to OpenShift. One of the great things about OpenShift is the concept of Source to Image, where you simply point to your source code and OpenShift will build and deploy your application. In this first example, we will be using source to image and build configs that come built in with Quarkus and OpenShift. To start the build ( and deploy ) process simply run the following command. quarkus build --no-tests Let's take a look at what this did along with everything that was created in your cluster.","title":"Deploy an application"},{"location":"app/2A-deploy-app/#container-images","text":"Log into the OpenShift Console and from the Administrator perspective, expand Builds and then Image Streams, and select the minesweeper Project. You will see two images that were created on your behalf when you ran the quarkus build command. There is one image for openjdk-11 that comes with OpenShift as a Universal Base Image (UBI) that the application will run under. With UBI, you get highly optimized and secure container images that you can build your applications with. For more information on UBI please read this article The second image you see is the the microsweeper-appservice image. This is the image for the application that was built automatically for you and pushed to the container registry that comes with OpenShift.","title":"Container Images"},{"location":"app/2A-deploy-app/#image-build","text":"How did those images get built you ask? Back on the OpenShift Console, click on Build Configs and then the microsweeper-appservice entry. When you ran the quarkus build command, this created the BuildConfig you can see here. In our quarkus settings, we set the deployment strategy to build the image using Docker. The Dockerfile file from the git repo that we cloned was used for this Build Config. Info A build configuration describes a single build definition and a set of triggers for when a new build is created. Build configurations are defined by a BuildConfig, which is a REST object that can be used in a POST to the API server to create a new instance. You can read more about BuildConfigs here Once the BuildConfig was created, the source to image process kicked off a Build of that BuildConfig. The build is what actually does the work in building and deploying the image. We started with defining what to be built with the BuildConfig and then actually did the work with the Build. You can read more about Builds here To look at what the build actually did, click on Builds tab and then into the first Build in the list. On the next screen, explore around and look at the YAML definition of the build, Logs to see what the build actually did. If you build failed for some reason, logs is a great first place to start to look at to debug what happened.","title":"Image Build"},{"location":"app/2A-deploy-app/#image-deployment","text":"After the image was built, the S2I process then deployed the application for us. In the quarkus properties file, we specified that a deployment should be created. You can view the deployment under Workloads, Deployments, and then click on the Deployment name. Explore around the deployment screen, check out the different tabs, look at the YAML that was created. Look at the pod the deployment created, and see that it is running. The last thing we will look at is the Route that was created for our application. In the quarkus properties file, we specified that the application should be exposed to the Internet. When you create a Route, you have the option to specify a hostname. To start with, we will just use the default domain that comes with ARO useast.aroapp.io in our case. In next section, we will expose the same appplication to a custom domain leveraging Azure Front Door. You can read more about Routes here From the OpenShift menu, click on Networking, Routes, and the microsweeper-appservice route.","title":"Image Deployment"},{"location":"app/2A-deploy-app/#test-the-application","text":"While in the Route section of the OpenShift UI, click the url under location: You can also get the the url for your application using the command line: oc get routes -o json | jq -r '.items[0].spec.host' Point your browser to the application!!","title":"Test the application"},{"location":"app/2A-deploy-app/#application-ip","text":"Let's take a quick look at what IP the application resolves to. Back in your Cloud Shell environment, run nslookup <route host name> i.e. nslookup microsweeper-appservice-minesweeper.apps.fiehcjr1.eastus.aroapp.io You should see results like the following: Notice the IP address - can you guess where it comes from? It comes from the ARO Load Balancer. In this workshop, we are using a Public Cluster which means the load balancer is exposed to the Internet. If this was a private cluster, you would have to have connectivity to the VNET ARO is running on whether that be VPN, Express Route, or something else. To view the ARO load balancer, on the Azure Portal, Search for 'Load Balancers' and click on the Load balancers service. Scroll down the list of load balancers until you see the one with your cluster name. You will notice two load balancers, one that has -internal in the name and one that does not. The '*-internal' load balancer is used for the OpenShift API. The other load balancer ( without -internal ) in the name is use the public load balancer used for the default Ingress Controller. Click into the load balancer for applications. On the next screen, click on Frontend IP configuration. Notice the IP address of the 2nd load balancer on the list. This IP address matches what you found with the nslookup command. For the fun of it, we can also look at what backends this load balancer is connected to. Click into the 2nd load balancer on the list above, and then click into the first rule. On the next screen, notice the Backend pool. This is the subnet that contains all the workers. And the best part is all of this came with OpenShift and ARO! Continue to Part 2 of Deploy and Expose an App to expose the same application using a custom domain leveraging Azure Front Door.","title":"Application IP"},{"location":"app/2B-deploy-app/","text":"Expose the application with Front Door # Up to this point, we have deployed the minesweeper app using the publically available Ingress Controller that comes with OpenShift. Best practices for ARO clusters is to make them private ( both the api server and the ingress controller) and then exposing the application you need with something like Azure Front Door. In the following section of the workshop, we will go through setting up Azure Front Door and then exposing our ratings application with Azure Front Door using a custom domain. The following diagram shows what we will configure. There are several advantages of this approach, namely your cluster and all the resources in your Azure account can remain private, providing you an extra layer of security. Azure FrontDoor operates at the edge so we are controlling traffic before it even gets into your Azure account. On top of that, Azure FrontDoor also offers WAF and DDoS protection, certificate management and SSL Offloading just to name a few benefits. As you can see in the diagram, Azure Front Door sits on the edge of the Microsoft network and is connected to the cluster via a private link service. With a private cluster, this means all traffic goes through Front Door and is secured at the edge. Front Door is then connected to your cluster through a private connection over the Microsoft backbone. Setting up and configuring Azure Front Door for the ratings application is typically something the operations team would do. If you are interested in going through the steps, you can do so here Verify the private Ingress Controller # As you will remember the first part of the workshop, we created a public cluster where the API and default Applications endpoints are exposed to the Internet. To similate a private environment for the applications endpoint, a second Ingress Controller only exposed to the private network of our cluster has been created for you. Let's check to make sure the IngressController has been created. oc get IngressController -n openshift-ingress-operator Expected output, you should see a 2nd private IngressController: Now, check that the corresponding LoadBalancer service has been created. oc get svc -n openshift-ingress The output of this command should show that a route-internal-private and a router-private LoadBalancer service has been created. Note that there are no public IPs associated with the newly created LoadBalancer services. Expected Output: Extra Credit Validate the Load Balancer using the Azure Portal. From the Azure Portal, search for Load Balancers and then click on the \\<cluster name - id>-internal Load Balancer On the next screen click on Frontend IP configuration and note the IP address matches the LoadBalancer service you just retrieved with the CLI. Configure the application to use Front Door # Your operations team has already configured Front Door for you with a custom domain so now we can configure the application to use Azure Front Door and your custom domain. Create new route All we have to do is create a new route with our custom domain: envsubst << EOF | oc apply -f - apiVersion: route.openshift.io/v1 kind: Route metadata: labels: app: rating-web app.kubernetes.io/component: rating-web app.kubernetes.io/instance: rating-web type: private name: rating-web-fd spec: host: $ARO_APP_FQDN to: kind: Service name: rating-web weight: 100 targetPort: port: 8080 wildcardPolicy: None EOF Validate the Custom Domain From the OpenShift Console, click on Networking, Routes and then click on the url next to the newly create microsweeper-appservice-fd route. Notice that the application is secured! This is done automatically for us by Front Door. The last thing we will validate it where is your custom domain coming from. If you remember, one of the benefits of using Azure Front Door is that traffic is sent through and secured at the Microsoft edge rather than your application. To check where the traffic is coming from run the following command from your cloudshell: nslookup $ARO_APP_FQDN Notice how the results show traffic coming from *.t-msedge.net Congratulations, you now have an application exposed with Front Door using a custom domain. Continue to the next part to automate provisioning the application using OpenShift Pipelines.","title":"2B deploy app"},{"location":"app/2B-deploy-app/#expose-the-application-with-front-door","text":"Up to this point, we have deployed the minesweeper app using the publically available Ingress Controller that comes with OpenShift. Best practices for ARO clusters is to make them private ( both the api server and the ingress controller) and then exposing the application you need with something like Azure Front Door. In the following section of the workshop, we will go through setting up Azure Front Door and then exposing our ratings application with Azure Front Door using a custom domain. The following diagram shows what we will configure. There are several advantages of this approach, namely your cluster and all the resources in your Azure account can remain private, providing you an extra layer of security. Azure FrontDoor operates at the edge so we are controlling traffic before it even gets into your Azure account. On top of that, Azure FrontDoor also offers WAF and DDoS protection, certificate management and SSL Offloading just to name a few benefits. As you can see in the diagram, Azure Front Door sits on the edge of the Microsoft network and is connected to the cluster via a private link service. With a private cluster, this means all traffic goes through Front Door and is secured at the edge. Front Door is then connected to your cluster through a private connection over the Microsoft backbone. Setting up and configuring Azure Front Door for the ratings application is typically something the operations team would do. If you are interested in going through the steps, you can do so here","title":"Expose the application with Front Door"},{"location":"app/2B-deploy-app/#verify-the-private-ingress-controller","text":"As you will remember the first part of the workshop, we created a public cluster where the API and default Applications endpoints are exposed to the Internet. To similate a private environment for the applications endpoint, a second Ingress Controller only exposed to the private network of our cluster has been created for you. Let's check to make sure the IngressController has been created. oc get IngressController -n openshift-ingress-operator Expected output, you should see a 2nd private IngressController: Now, check that the corresponding LoadBalancer service has been created. oc get svc -n openshift-ingress The output of this command should show that a route-internal-private and a router-private LoadBalancer service has been created. Note that there are no public IPs associated with the newly created LoadBalancer services. Expected Output: Extra Credit Validate the Load Balancer using the Azure Portal. From the Azure Portal, search for Load Balancers and then click on the \\<cluster name - id>-internal Load Balancer On the next screen click on Frontend IP configuration and note the IP address matches the LoadBalancer service you just retrieved with the CLI.","title":"Verify the private Ingress Controller"},{"location":"app/2B-deploy-app/#configure-the-application-to-use-front-door","text":"Your operations team has already configured Front Door for you with a custom domain so now we can configure the application to use Azure Front Door and your custom domain. Create new route All we have to do is create a new route with our custom domain: envsubst << EOF | oc apply -f - apiVersion: route.openshift.io/v1 kind: Route metadata: labels: app: rating-web app.kubernetes.io/component: rating-web app.kubernetes.io/instance: rating-web type: private name: rating-web-fd spec: host: $ARO_APP_FQDN to: kind: Service name: rating-web weight: 100 targetPort: port: 8080 wildcardPolicy: None EOF Validate the Custom Domain From the OpenShift Console, click on Networking, Routes and then click on the url next to the newly create microsweeper-appservice-fd route. Notice that the application is secured! This is done automatically for us by Front Door. The last thing we will validate it where is your custom domain coming from. If you remember, one of the benefits of using Azure Front Door is that traffic is sent through and secured at the Microsoft edge rather than your application. To check where the traffic is coming from run the following command from your cloudshell: nslookup $ARO_APP_FQDN Notice how the results show traffic coming from *.t-msedge.net Congratulations, you now have an application exposed with Front Door using a custom domain. Continue to the next part to automate provisioning the application using OpenShift Pipelines.","title":"Configure the application to use Front Door"},{"location":"app/2C-deploy-app/","text":"Automate deploying the application with OpenShift Pipelines ( Part 3 ) # We will be using OpenShift Pipelines which is based on the Open Source Tekton project to automatically deploy our application using a CI/CD pipeline. If you would like to read more about OpenShift Pipelines, click here The first thing you need to do is fork the code repositories so that you can make changes to the code base and then OpenShift pipelines will build and deploy the new code. Opening your browser, go to the following github repos https://github.com/rh-mobb/common-java-dependencies https://github.com/rh-mobb/aro-hackaton-app For each of the repositories, click Fork and then choose your own Git Account. Clone git repos Next, we will need to make a directory and clone your personal github repository that you just forked to. mkdir $USERID cd $USERID git clone https://github.com/<YOUR GITHUB USER ID>/common-java-dependencies git clone https://github.com/kmcolli/aro-hackaton-app Review OpenShift Pipeline Tasks The next thing we need to do is import common Tekton tasks that our pipeline will use. These common tasks are designed to be reused across multiple pipelines. Let's start by taking a look at the reusable Tasks that we will be using. From your cloud shell, change directorys to ~/aro-hackaton-app/pipeline and list the files. cd ~/aro-hackaton-app/pipeline/tasks ls | tr \u201c\u201d \u201c \\n \u201d Expected output: 1-git-clone.yaml Clones a given GitHub Repo. 2-mvn.yaml This Task can be used to run a Maven build 3-mvn-build-image.yaml Packages source with maven builds and into a container image, then pushes it to a container registry. Builds source into a container image using Project Atomic's Buildah build tool. It uses Buildah's support for building from Dockerfiles, using its buildah bud command.This command executes the directives in the Dockerfile to assemble a container image, then pushes that image to a container registry. 4-apply-manifest.yaml Applied manifest files to the cluster 5-update-deployment.yaml Updates a deployment with the new container image. From the Cloud Shell, we need to apply all of these tasks to our cluster. Run the following command: oc apply -f ~/aro-hackaton-app/pipeline/tasks expected output: Configure Azure Container Registry Next, we need to create a secret to push and pull images into Azure Container Registry. Each attendee has their own Azure Container Registry service assigned to them, with the naming convention acr.azurecr.io ACRPWD = $( az acr credential show -n ${ USERID } acr -g $ARORG --query 'passwords[0].value' -o tsv ) oc create secret docker-registry --docker-server = ${ USERID } acr.azurecr.io --docker-username = ${ USERID } acr --docker-password = $ACRPWD --docker-email = unused acr-secret Configure the pipleine service account Create the pipeline service account and permissions that the pipeline tasks will run under: oc create -f ~/aro-hackaton-app/pipeline/1-pipeline-account.yaml Expected output: Link the acr-secret you just created to it can mount and pull images oc secrets link pipeline acr-secret --for = pull,mount Make sure the secret is linked to the pipeline service account. oc describe sa pipeline expected output: We also need to give the pipeline permission for certain security context constraints to that it can execute. oc adm policy add-scc-to-user anyuid -z pipeline oc adm policy add-scc-to-user privileged -z pipeline Create a PVC that the pipeline will use to store the build images \\ oc create -f ~/aro-hackaton-app/pipeline/2-pipeline-pvc.yaml Review the Pipeline Definition Next we need to create the pipeline definition. Before we actually create the pipeline, lets take a look at the pipeline definition. Open a browser to the git repo to browse the pipeline.yaml file. https://github.com/rh-mobb/aro-hackaton-app/blob/main/pipeline/3-pipeline.yaml Browse through the file and notice all the tasks that are being executed. These are the tasks we imported in the previous step. The pipeline definition simply says which order the tasks are run and what parameters should be passed between tasks. Update Application Settings Now that we have the source code forked, we need to copy the properties file we created earlier to our new code base. Let's create a new directory, clone the repo and copy the file. Using the cloud shell, run the following commands. cd ~/ $USERID cp ../aro-hackaton-app/src/main/resources/application.properties aro-hackaton-app/src/main/resources/application.properties Setup git and push changes to the properties file git config --global user.email \"<your github email>\" git config --global user.name \u201c<your github username>\u201d git init Commit changes to git cd aro-hackaton-app git add * git commit -am \"Update Propereties File\" git push Info when prompted log in with your git user name ( email ) and git token. If you need a git token, please refer to this document Create git secret While you have your github userid and secret handy, let's also create a secret containing your github credentials that we will need later. First set git envrionment variables and then run a script to create the secret. export GIT_USER = <your git email> export GIT_TOKEN = <your git token> ~/aro-hackaton-app/pipeline/0-github-secret.sh Create the pipeline definition on your cluster oc create -f ~/aro-hackaton-app/pipeline/3-pipeline.yaml Update the deployment to use ACR Finally we will create a pipeline run that will execute the pipeline, which will pull code from the your git repo that you forked, will build the image and deploy it to OpenShift. There are a couple settings in the pipeline run that we will need to update. Before we can actually run the pipeline that will update the deployment, we need to tell the deployment to use the ACR pull secret we created in the previous step. To do so, run the following command. oc patch deploy/microsweeper-appservice --patch-file ~/aro-hackaton-app/pipeline/5-deployment-patch.yaml Edit the ~/$USERID/aro-hackaton-app/pipeline/4-pipeline-run.yaml file. The three things to change is the: * dependency-git-url - to point to your personal git repository * application-git-url - to point to your personal git repository * image-name - change this to reflect to the ACR Registry created for you ... this should be $USERIDacr.azurecr.io/minesweeper Create the pipeline run oc create -f ~/ $USERID /aro-hackaton-app/pipeline/4-pipeline-run.yaml This will start a pipeline run and redeploy the minesweeper application, but this time will build the code from your github repository and the pipeline will deploy the application as well to OpenShift. Validate the pipeline Let's take a look at the OpenShift console to see what was created and if the application was successfully deployed. From the OpenShift Conole - Administrator view, click on Pipelines and then Tasks. Notice the 5 tasks that we imported and click into them to view the yaml defitions. Next, lets look at the Pipeline. Click on Pipelines. Notice that that last run was successful. Click on maven-pipeline to view the pipeline details. On the following screen, click on Pipeline Runs to view the status of each Pipeline Run. Lastely, click on the PipeRun name and you can see all the details and steps of the Pipeline. If your are curious, also click on logs and view the logs of the different tasks that were ran. Event Triggering # At this point, we can successfully build and deploy new code by manually runnning a pipeline run. But how can we configure the pipeline to run automatically when we commit code with git? We can do so with an Event Listener and a Trigger! Let's start by looking at the resources we will be creating to create our event listener and trigger. ls ~/ $USER /aro-hackaton-app/pipeline/tasks/event-listener | tr \u201c\u201d \u201c \\n \u201d expected output: Take a look at the files listed: 1-web-trigger-binding.yaml This TriggerBinding allows you to extract fields, such as the git repository name, git commit number, and the git repository URL in this case. To learn more about TriggerBindings, click here 2-web-trigger-template.yaml The TriggerTemplate specifies how the pipeline should be run. Browsing the file above, you will see there is a definition of the PipelineRun that looks exactly like the PipelineRun you create in the previous step. This is by design! ... it should be the same. You will need to edit this file so it points to your git repository and acr image repository. Change the following entries to point to your GIT Repository. - name: dependency-git-url value: https://github.com/<YOUR-GITHUB-ID>/common-java-dependencies - name: application-git-url value: https://github.com/<YOUR-GITHUB-ID>/aro-hackaton-app Note As a reminder, each attendee has their own Azure Container Registry service assigned to them, with the naming convention acr.azurecr.io - name: image-name value: <CHANGE-ME>.azurecr.io/minesweeper To learn more about TriggerTemplates, click here 3-web-trigger.yaml The next file we have is the Trigger. The Trigger specifies what should happen when the EventListener detects an Event. Looking at this file, you will see that we are looking for 'Push' events that will create an instance of the TriggerTemplate that we just created. This in turn will start the PipelineRun. To learn more about Triggers, click here 4-event-listenter.yaml The last file we have is the Event Listener. An EventListener is a Kubernetes object that listens for events at a specified port on your OpenShift cluster. It exposes an OpenShift Route that receives incoming event and specifies one or more Triggers. To learn more about EventListeners, click here Now that you have reviewed all the files, let's apply them to our cluster. oc create -f ~/ $USER /aro-hackaton-app/pipeline/tasks/event-listener Before we test out our EventListener and Trigger, lets review what was created in OpenShift. From the OpenShift console, under Pipelines, click on Triggers. Browse the EventListener, TriggerTemplate and TriggerBindings that you just created. The next thing we need to do, is connect our EventListener with Git. When an action, such as a git push, happens, git will need to call our EventListner to start the build and deploy process. The first thing we need to do is exposing our EventListner service. From the Cloud Shell, let's start by looking at the event listener service. oc get svc expected output: Expose the service so that Git is able to connect to the event listener. Note Since this is public cluster, we can simply use the included OpenShift Ingress Controller as it is exposed to the Internet. For a private cluster, you can follow the same process as we did above in exposing the minesweeper application with Front Door! oc expose svc el-minesweeper-el To get the url of the Event Listener Route that we just created, run the following command: oc get route el-minesweeper-el expected output: The last step we need to do, is configure git to call this event listner URL when events occur. From your browser, go to your personal GitHub aro-hackaton-app repository, and click on Settings. On the next screen, click on webhooks. Click on add webhook On the next screen, enter the following settings: - PayloadURL - enter http:// - ContentType - select application/json - Secret - this your github token Where does this secret value come from? Refer to the ~/$USERID/aro-hackaton-app/pipeline/tasks/event-listener/web-trigger.yaml file. You will see the following snippet that contains the secret to access git. interceptors: - ref: name: \"github\" params: - name: \"secretRef\" value: secretName: gitsecret secretKey: secretToken - name: \"eventTypes\" value: [ \"push\" ] The secret you enter here for the git webhook, needs to match the value for the secretToken key of the a secret named gitsecret. If you remember in the previous step, we create this secret and used your git token as this value. Keep the remaining defaults, and click Add webhook Test it out!! # Now that we have our trigger, eventlistener and git webhook setup, lets test it out. Make sure you are in the directory for your personal git repo where the application is, and edit the /src/main/resources/META-INF/resources/index.html file. Search for Leaderboard and change it to \\<YOUR NAME> Leaderboard. cd ~/ $USERID /aro-hackaton-app vi src/main/resources/META-INF/resources/index.html Now commit and push the change git commit -am 'updated leaderboard title' git push Pushing the change to the your git repository will kick of the event listener which will start the pipeline. As a bonus, if you want to look at the logs of the event listener, you can use the tekton (tkn) cli. tkn eventlistener logs minesweeper-el Quickly switch over to your OpenShift Console, and watch the pipeline run. Once the pipeline finishes, check out the change. From the OpenShift Console, click on Networking and the Routes. and drum roll ... you should see the updated application with a new title for the leaderboard.","title":"Automate deploying the application with OpenShift Pipelines ( Part 3 )"},{"location":"app/2C-deploy-app/#automate-deploying-the-application-with-openshift-pipelines-part-3","text":"We will be using OpenShift Pipelines which is based on the Open Source Tekton project to automatically deploy our application using a CI/CD pipeline. If you would like to read more about OpenShift Pipelines, click here The first thing you need to do is fork the code repositories so that you can make changes to the code base and then OpenShift pipelines will build and deploy the new code. Opening your browser, go to the following github repos https://github.com/rh-mobb/common-java-dependencies https://github.com/rh-mobb/aro-hackaton-app For each of the repositories, click Fork and then choose your own Git Account. Clone git repos Next, we will need to make a directory and clone your personal github repository that you just forked to. mkdir $USERID cd $USERID git clone https://github.com/<YOUR GITHUB USER ID>/common-java-dependencies git clone https://github.com/kmcolli/aro-hackaton-app Review OpenShift Pipeline Tasks The next thing we need to do is import common Tekton tasks that our pipeline will use. These common tasks are designed to be reused across multiple pipelines. Let's start by taking a look at the reusable Tasks that we will be using. From your cloud shell, change directorys to ~/aro-hackaton-app/pipeline and list the files. cd ~/aro-hackaton-app/pipeline/tasks ls | tr \u201c\u201d \u201c \\n \u201d Expected output: 1-git-clone.yaml Clones a given GitHub Repo. 2-mvn.yaml This Task can be used to run a Maven build 3-mvn-build-image.yaml Packages source with maven builds and into a container image, then pushes it to a container registry. Builds source into a container image using Project Atomic's Buildah build tool. It uses Buildah's support for building from Dockerfiles, using its buildah bud command.This command executes the directives in the Dockerfile to assemble a container image, then pushes that image to a container registry. 4-apply-manifest.yaml Applied manifest files to the cluster 5-update-deployment.yaml Updates a deployment with the new container image. From the Cloud Shell, we need to apply all of these tasks to our cluster. Run the following command: oc apply -f ~/aro-hackaton-app/pipeline/tasks expected output: Configure Azure Container Registry Next, we need to create a secret to push and pull images into Azure Container Registry. Each attendee has their own Azure Container Registry service assigned to them, with the naming convention acr.azurecr.io ACRPWD = $( az acr credential show -n ${ USERID } acr -g $ARORG --query 'passwords[0].value' -o tsv ) oc create secret docker-registry --docker-server = ${ USERID } acr.azurecr.io --docker-username = ${ USERID } acr --docker-password = $ACRPWD --docker-email = unused acr-secret Configure the pipleine service account Create the pipeline service account and permissions that the pipeline tasks will run under: oc create -f ~/aro-hackaton-app/pipeline/1-pipeline-account.yaml Expected output: Link the acr-secret you just created to it can mount and pull images oc secrets link pipeline acr-secret --for = pull,mount Make sure the secret is linked to the pipeline service account. oc describe sa pipeline expected output: We also need to give the pipeline permission for certain security context constraints to that it can execute. oc adm policy add-scc-to-user anyuid -z pipeline oc adm policy add-scc-to-user privileged -z pipeline Create a PVC that the pipeline will use to store the build images \\ oc create -f ~/aro-hackaton-app/pipeline/2-pipeline-pvc.yaml Review the Pipeline Definition Next we need to create the pipeline definition. Before we actually create the pipeline, lets take a look at the pipeline definition. Open a browser to the git repo to browse the pipeline.yaml file. https://github.com/rh-mobb/aro-hackaton-app/blob/main/pipeline/3-pipeline.yaml Browse through the file and notice all the tasks that are being executed. These are the tasks we imported in the previous step. The pipeline definition simply says which order the tasks are run and what parameters should be passed between tasks. Update Application Settings Now that we have the source code forked, we need to copy the properties file we created earlier to our new code base. Let's create a new directory, clone the repo and copy the file. Using the cloud shell, run the following commands. cd ~/ $USERID cp ../aro-hackaton-app/src/main/resources/application.properties aro-hackaton-app/src/main/resources/application.properties Setup git and push changes to the properties file git config --global user.email \"<your github email>\" git config --global user.name \u201c<your github username>\u201d git init Commit changes to git cd aro-hackaton-app git add * git commit -am \"Update Propereties File\" git push Info when prompted log in with your git user name ( email ) and git token. If you need a git token, please refer to this document Create git secret While you have your github userid and secret handy, let's also create a secret containing your github credentials that we will need later. First set git envrionment variables and then run a script to create the secret. export GIT_USER = <your git email> export GIT_TOKEN = <your git token> ~/aro-hackaton-app/pipeline/0-github-secret.sh Create the pipeline definition on your cluster oc create -f ~/aro-hackaton-app/pipeline/3-pipeline.yaml Update the deployment to use ACR Finally we will create a pipeline run that will execute the pipeline, which will pull code from the your git repo that you forked, will build the image and deploy it to OpenShift. There are a couple settings in the pipeline run that we will need to update. Before we can actually run the pipeline that will update the deployment, we need to tell the deployment to use the ACR pull secret we created in the previous step. To do so, run the following command. oc patch deploy/microsweeper-appservice --patch-file ~/aro-hackaton-app/pipeline/5-deployment-patch.yaml Edit the ~/$USERID/aro-hackaton-app/pipeline/4-pipeline-run.yaml file. The three things to change is the: * dependency-git-url - to point to your personal git repository * application-git-url - to point to your personal git repository * image-name - change this to reflect to the ACR Registry created for you ... this should be $USERIDacr.azurecr.io/minesweeper Create the pipeline run oc create -f ~/ $USERID /aro-hackaton-app/pipeline/4-pipeline-run.yaml This will start a pipeline run and redeploy the minesweeper application, but this time will build the code from your github repository and the pipeline will deploy the application as well to OpenShift. Validate the pipeline Let's take a look at the OpenShift console to see what was created and if the application was successfully deployed. From the OpenShift Conole - Administrator view, click on Pipelines and then Tasks. Notice the 5 tasks that we imported and click into them to view the yaml defitions. Next, lets look at the Pipeline. Click on Pipelines. Notice that that last run was successful. Click on maven-pipeline to view the pipeline details. On the following screen, click on Pipeline Runs to view the status of each Pipeline Run. Lastely, click on the PipeRun name and you can see all the details and steps of the Pipeline. If your are curious, also click on logs and view the logs of the different tasks that were ran.","title":"Automate deploying the application with OpenShift Pipelines ( Part 3 )"},{"location":"app/2C-deploy-app/#event-triggering","text":"At this point, we can successfully build and deploy new code by manually runnning a pipeline run. But how can we configure the pipeline to run automatically when we commit code with git? We can do so with an Event Listener and a Trigger! Let's start by looking at the resources we will be creating to create our event listener and trigger. ls ~/ $USER /aro-hackaton-app/pipeline/tasks/event-listener | tr \u201c\u201d \u201c \\n \u201d expected output: Take a look at the files listed: 1-web-trigger-binding.yaml This TriggerBinding allows you to extract fields, such as the git repository name, git commit number, and the git repository URL in this case. To learn more about TriggerBindings, click here 2-web-trigger-template.yaml The TriggerTemplate specifies how the pipeline should be run. Browsing the file above, you will see there is a definition of the PipelineRun that looks exactly like the PipelineRun you create in the previous step. This is by design! ... it should be the same. You will need to edit this file so it points to your git repository and acr image repository. Change the following entries to point to your GIT Repository. - name: dependency-git-url value: https://github.com/<YOUR-GITHUB-ID>/common-java-dependencies - name: application-git-url value: https://github.com/<YOUR-GITHUB-ID>/aro-hackaton-app Note As a reminder, each attendee has their own Azure Container Registry service assigned to them, with the naming convention acr.azurecr.io - name: image-name value: <CHANGE-ME>.azurecr.io/minesweeper To learn more about TriggerTemplates, click here 3-web-trigger.yaml The next file we have is the Trigger. The Trigger specifies what should happen when the EventListener detects an Event. Looking at this file, you will see that we are looking for 'Push' events that will create an instance of the TriggerTemplate that we just created. This in turn will start the PipelineRun. To learn more about Triggers, click here 4-event-listenter.yaml The last file we have is the Event Listener. An EventListener is a Kubernetes object that listens for events at a specified port on your OpenShift cluster. It exposes an OpenShift Route that receives incoming event and specifies one or more Triggers. To learn more about EventListeners, click here Now that you have reviewed all the files, let's apply them to our cluster. oc create -f ~/ $USER /aro-hackaton-app/pipeline/tasks/event-listener Before we test out our EventListener and Trigger, lets review what was created in OpenShift. From the OpenShift console, under Pipelines, click on Triggers. Browse the EventListener, TriggerTemplate and TriggerBindings that you just created. The next thing we need to do, is connect our EventListener with Git. When an action, such as a git push, happens, git will need to call our EventListner to start the build and deploy process. The first thing we need to do is exposing our EventListner service. From the Cloud Shell, let's start by looking at the event listener service. oc get svc expected output: Expose the service so that Git is able to connect to the event listener. Note Since this is public cluster, we can simply use the included OpenShift Ingress Controller as it is exposed to the Internet. For a private cluster, you can follow the same process as we did above in exposing the minesweeper application with Front Door! oc expose svc el-minesweeper-el To get the url of the Event Listener Route that we just created, run the following command: oc get route el-minesweeper-el expected output: The last step we need to do, is configure git to call this event listner URL when events occur. From your browser, go to your personal GitHub aro-hackaton-app repository, and click on Settings. On the next screen, click on webhooks. Click on add webhook On the next screen, enter the following settings: - PayloadURL - enter http:// - ContentType - select application/json - Secret - this your github token Where does this secret value come from? Refer to the ~/$USERID/aro-hackaton-app/pipeline/tasks/event-listener/web-trigger.yaml file. You will see the following snippet that contains the secret to access git. interceptors: - ref: name: \"github\" params: - name: \"secretRef\" value: secretName: gitsecret secretKey: secretToken - name: \"eventTypes\" value: [ \"push\" ] The secret you enter here for the git webhook, needs to match the value for the secretToken key of the a secret named gitsecret. If you remember in the previous step, we create this secret and used your git token as this value. Keep the remaining defaults, and click Add webhook","title":"Event Triggering"},{"location":"app/2C-deploy-app/#test-it-out","text":"Now that we have our trigger, eventlistener and git webhook setup, lets test it out. Make sure you are in the directory for your personal git repo where the application is, and edit the /src/main/resources/META-INF/resources/index.html file. Search for Leaderboard and change it to \\<YOUR NAME> Leaderboard. cd ~/ $USERID /aro-hackaton-app vi src/main/resources/META-INF/resources/index.html Now commit and push the change git commit -am 'updated leaderboard title' git push Pushing the change to the your git repository will kick of the event listener which will start the pipeline. As a bonus, if you want to look at the logs of the event listener, you can use the tekton (tkn) cli. tkn eventlistener logs minesweeper-el Quickly switch over to your OpenShift Console, and watch the pipeline run. Once the pipeline finishes, check out the change. From the OpenShift Console, click on Networking and the Routes. and drum roll ... you should see the updated application with a new title for the leaderboard.","title":"Test it out!!"},{"location":"app/3-scale-app/","text":"Make Application Resilient # In this section of the workshop, we will deploy an application to an ARO cluster, Ensure the application is resilient to node failure and scale when under load. Set resource limits # This first thing we need to do when it comes to scaling is set resource limits and requests, which also happens to be best practices when it comes to Kubernetes. We will start by creating very large resource requests so the horizontal pod autoscaler that we will create next will kick in. oc set resources deployment/rating-web \\ --limits = cpu = 2 ,memory = 2Gi \\ --requests = cpu = 1 ,memory = 1Gi Right now the application is deployed inside one pod, and in case the worker running the pod crashes, the ReplicaSet object will register that the pod is down and recreate it on another node. You can scale the application to run on multiple pods using the following command oc scale deployment/rating-web --replicas = 3 oc get pods Expected Output: Pod Disruption Budget # A Pod disruption Budget (PBD) allows you to limit the disruption to your application when its pods need to be rescheduled for upgrades or routine maintenance work on ARO nodes. In essence, it lets developers define the minimum tolerable operational requirements for a Deployment so that it remains stable even during a disruption. For example, rating-web deployed as part of the last step contains two replicas distributed evenly across two nodes. We can tolerate losing one pods but not two, so we create a PDB that requires a minimum of two replicas. A PodDisruptionBudget object\u2019s configuration consists of the following key partsi: A label selector, which is a label query over a set of pods. An availability level, which specifies the minimum number of pods that must be available simultaneously, either: minAvailable is the number of pods must always be available, even during a disruption. maxUnavailable is the number of pods can be unavailable during a disruption. Note A maxUnavailable of 0% or 0 or a minAvailable of 100% or equal to the number of replicas is permitted but can block nodes from being drained. Create a PDB by running the following. cat <<EOF | oc apply -f - apiVersion: policy/v1 kind: PodDisruptionBudget metadata: name: rating-web-pdb spec: minAvailable: 2 selector: matchLabels: deployment: rating-web EOF After creating PDB, OpenShift API will ensure two pods of rating-web is running all the time while cluster is going through upgrade. Check the status of PBD oc get poddisruptionbudgets Expected Output: Horizontal Pod Autoscaler (HPA) # As a developer, you can use a horizontal pod autoscaler (HPA) to specify how OpenShift Container Platform should automatically increase or decrease the scale of a replication controller or deployment configuration, based on metrics collected from the pods that belong to that replication controller or deployment configuration. You can create an HPA for any any deployment, deployment config, replica set, replication controller, or stateful set. In this exercise we will scale frontend application based either CPU or Memory utilization. We will set the thresholds initially to be very small and and the number of replicas to be large so the cluster autoscaler will also kick in. Scale out when average CPU utilization is greater than 1% of CPU or memory limit Maximum pods is 15 Scale down to min replicas if utilization is lower than threshold for 60 sec cat <<EOF | oc apply -f - apiVersion: autoscaling/v2 kind: HorizontalPodAutoscaler metadata: name: rating-web-cpu namespace: ratingsapp spec: scaleTargetRef: apiVersion: apps/v1 kind: Deployment name: rating-web minReplicas: 2 maxReplicas: 15 metrics: - type: Resource resource: name: memory target: type: Utilization averageUtilization: 1 - type: Resource resource: name: cpu target: type: Utilization averageUtilization: 1 behavior: scaleDown: stabilizationWindowSeconds: 60 policies: - type: Percent value: 100 periodSeconds: 15 EOF Check HPA status watch oc get horizontalpodautoscaler/rating-web-cpu -n ratingsapp Watch the output for a while and watch the replicas scale up. Hit Cntl-C to exit. Expected Output: Next check out the pods that are running: Expected Output: Notice that several pods are Pending. This is the indication for the cluster autoscaler to start scaling nodes as no more rating-web pods can fit on the nodes we have. Let's check the machines. oc get machines -n openshift-machine-api Expected Output Wait a couple of minutes and run the same: oc get machines -n openshift-machine-api and you will see the machines have move to running from provisioned ... meaning the machines have been succesfully add as nodes to the cluster. Expected Output: Next, lets look at the pods again. oc get pods Notice that there are only a couple of pods left that are pending. Why are there still pods pending? Because the cluster autoscaler had a maximum setting of adding 2 additional nodes. Expected output: Finally, let's set the resource limits and horizonal pod autoscaled to something more reasonable which will then scale the cluster back down. oc set resources deployment/rating-web \\ --limits = cpu = 512m,memory = 512Mi \\ --requests = cpu = 128m,memory = 128Mi cat <<EOF | oc apply -f - apiVersion: autoscaling/v2 kind: HorizontalPodAutoscaler metadata: name: rating-web-cpu namespace: ratingsapp spec: scaleTargetRef: apiVersion: apps/v1 kind: Deployment name: rating-web minReplicas: 2 maxReplicas: 5 metrics: - type: Resource resource: name: memory target: type: Utilization averageUtilization: 60 - type: Resource resource: name: cpu target: type: Utilization averageUtilization: 60 behavior: scaleDown: stabilizationWindowSeconds: 60 policies: - type: Percent value: 100 periodSeconds: 15 EOF Now that we have updated the HPA and Resource Limits, lets take a look at the pods. oc get pods watch the pods terminate and scale down Expected Output: Next, let's watch the machines scale back down. watch oc get machines -n openshift-machine-api Watch as the machines go through the deleting phase and eventually disappear. Hit Cntl-C ot escape: Expected output of machines being deleted: After a few minutes the two additional machines will no longer appear as the cluster has been scaled back down to it's original and optimal size.","title":"Make Applications Resilient"},{"location":"app/3-scale-app/#make-application-resilient","text":"In this section of the workshop, we will deploy an application to an ARO cluster, Ensure the application is resilient to node failure and scale when under load.","title":"Make Application Resilient"},{"location":"app/3-scale-app/#set-resource-limits","text":"This first thing we need to do when it comes to scaling is set resource limits and requests, which also happens to be best practices when it comes to Kubernetes. We will start by creating very large resource requests so the horizontal pod autoscaler that we will create next will kick in. oc set resources deployment/rating-web \\ --limits = cpu = 2 ,memory = 2Gi \\ --requests = cpu = 1 ,memory = 1Gi Right now the application is deployed inside one pod, and in case the worker running the pod crashes, the ReplicaSet object will register that the pod is down and recreate it on another node. You can scale the application to run on multiple pods using the following command oc scale deployment/rating-web --replicas = 3 oc get pods Expected Output:","title":"Set resource limits"},{"location":"app/3-scale-app/#pod-disruption-budget","text":"A Pod disruption Budget (PBD) allows you to limit the disruption to your application when its pods need to be rescheduled for upgrades or routine maintenance work on ARO nodes. In essence, it lets developers define the minimum tolerable operational requirements for a Deployment so that it remains stable even during a disruption. For example, rating-web deployed as part of the last step contains two replicas distributed evenly across two nodes. We can tolerate losing one pods but not two, so we create a PDB that requires a minimum of two replicas. A PodDisruptionBudget object\u2019s configuration consists of the following key partsi: A label selector, which is a label query over a set of pods. An availability level, which specifies the minimum number of pods that must be available simultaneously, either: minAvailable is the number of pods must always be available, even during a disruption. maxUnavailable is the number of pods can be unavailable during a disruption. Note A maxUnavailable of 0% or 0 or a minAvailable of 100% or equal to the number of replicas is permitted but can block nodes from being drained. Create a PDB by running the following. cat <<EOF | oc apply -f - apiVersion: policy/v1 kind: PodDisruptionBudget metadata: name: rating-web-pdb spec: minAvailable: 2 selector: matchLabels: deployment: rating-web EOF After creating PDB, OpenShift API will ensure two pods of rating-web is running all the time while cluster is going through upgrade. Check the status of PBD oc get poddisruptionbudgets Expected Output:","title":"Pod Disruption Budget"},{"location":"app/3-scale-app/#horizontal-pod-autoscaler-hpa","text":"As a developer, you can use a horizontal pod autoscaler (HPA) to specify how OpenShift Container Platform should automatically increase or decrease the scale of a replication controller or deployment configuration, based on metrics collected from the pods that belong to that replication controller or deployment configuration. You can create an HPA for any any deployment, deployment config, replica set, replication controller, or stateful set. In this exercise we will scale frontend application based either CPU or Memory utilization. We will set the thresholds initially to be very small and and the number of replicas to be large so the cluster autoscaler will also kick in. Scale out when average CPU utilization is greater than 1% of CPU or memory limit Maximum pods is 15 Scale down to min replicas if utilization is lower than threshold for 60 sec cat <<EOF | oc apply -f - apiVersion: autoscaling/v2 kind: HorizontalPodAutoscaler metadata: name: rating-web-cpu namespace: ratingsapp spec: scaleTargetRef: apiVersion: apps/v1 kind: Deployment name: rating-web minReplicas: 2 maxReplicas: 15 metrics: - type: Resource resource: name: memory target: type: Utilization averageUtilization: 1 - type: Resource resource: name: cpu target: type: Utilization averageUtilization: 1 behavior: scaleDown: stabilizationWindowSeconds: 60 policies: - type: Percent value: 100 periodSeconds: 15 EOF Check HPA status watch oc get horizontalpodautoscaler/rating-web-cpu -n ratingsapp Watch the output for a while and watch the replicas scale up. Hit Cntl-C to exit. Expected Output: Next check out the pods that are running: Expected Output: Notice that several pods are Pending. This is the indication for the cluster autoscaler to start scaling nodes as no more rating-web pods can fit on the nodes we have. Let's check the machines. oc get machines -n openshift-machine-api Expected Output Wait a couple of minutes and run the same: oc get machines -n openshift-machine-api and you will see the machines have move to running from provisioned ... meaning the machines have been succesfully add as nodes to the cluster. Expected Output: Next, lets look at the pods again. oc get pods Notice that there are only a couple of pods left that are pending. Why are there still pods pending? Because the cluster autoscaler had a maximum setting of adding 2 additional nodes. Expected output: Finally, let's set the resource limits and horizonal pod autoscaled to something more reasonable which will then scale the cluster back down. oc set resources deployment/rating-web \\ --limits = cpu = 512m,memory = 512Mi \\ --requests = cpu = 128m,memory = 128Mi cat <<EOF | oc apply -f - apiVersion: autoscaling/v2 kind: HorizontalPodAutoscaler metadata: name: rating-web-cpu namespace: ratingsapp spec: scaleTargetRef: apiVersion: apps/v1 kind: Deployment name: rating-web minReplicas: 2 maxReplicas: 5 metrics: - type: Resource resource: name: memory target: type: Utilization averageUtilization: 60 - type: Resource resource: name: cpu target: type: Utilization averageUtilization: 60 behavior: scaleDown: stabilizationWindowSeconds: 60 policies: - type: Percent value: 100 periodSeconds: 15 EOF Now that we have updated the HPA and Resource Limits, lets take a look at the pods. oc get pods watch the pods terminate and scale down Expected Output: Next, let's watch the machines scale back down. watch oc get machines -n openshift-machine-api Watch as the machines go through the deleting phase and eventually disappear. Hit Cntl-C ot escape: Expected output of machines being deleted: After a few minutes the two additional machines will no longer appear as the cluster has been scaled back down to it's original and optimal size.","title":"Horizontal Pod Autoscaler (HPA)"},{"location":"app/afd/","text":"Up to this point, we have deployed the microsweeper app using the publicly available ingress controller that comes with our public Azure Red Hat OpenShift cluster. Now, we will continue our work to expose our application via Azure Front Door using the private ingress controller that we created earlier in the workshop. A quick diagram of the ARO and Azure Front Door integration: There are several advantages of this approach: The ARO cluster and all the resources in your Azure account can be private. Azure Front Door operates at the edge so we are controlling traffic before it gets into your Azure account. Azure Front Door offers WAF and DDoS protection, certificate management, and SSL offloading, as well as many other security and performance related features. As you can see in the diagram, Azure Front Door sits on the edge of the Microsoft network and is connected to the cluster via an Azure Private Link service. First, let's verify that the ingress controller we created earlier in the workshop is still there. To do so, run the following command: oc get IngressController private -n openshift-ingress-operator -o jsonpath = '{.status.conditions}' | jq You'll see a lot of output, but the main thing you're looking for is that the deployment is available: [ ... ] { \"lastTransitionTime\" : \"2022-11-15T04:02:05Z\" , \"message\" : \"The deployment has Available status condition set to True\" , \"reason\" : \"DeploymentAvailable\" , \"status\" : \"True\" , \"type\" : \"DeploymentAvailable\" }, [ ... ] Since we've already configured Azure Front Door with a custom domain, we just need to tell OpenShift to expect traffic to come from our custom domain via a route. To create our route, run the following command: cat <<EOF | oc apply -f - apiVersion : route.openshift.io/v1 kind : Route metadata : labels : app.kubernetes.io/name : microsweeper-appservice app.kubernetes.io/version : 1.0.0-SNAPSHOT app.openshift.io/runtime : quarkus type : private name : microsweeper-appservice-fd namespace : microsweeper-ex spec : host : app.${AZ_USER}.ws.mobb.cloud to : kind : Service name : microsweeper-appservice weight : 100 targetPort : port : 8080 wildcardPolicy : None EOF Now, we're ready to validate our Azure Front Door endpoint. To do so, we need to get the custom domain to use. To do so, run the following command: oc -n microsweeper-ex get route microsweeper-appservice-fd -o jsonpath = '{.spec.host}' Then visit the URL presented in a new tab in your web browser (using HTTPS). For example, your output will look something similar to: app.user1.ws.mobb.cloud In that case, you'd visit https://app.user1.ws.mobb.cloud in your browser. Notice that the application is secured! This is done automatically for us by Front Door. If you remember, one of the benefits of using Azure Front Door is that traffic is sent through and secured at the Microsoft edge, rather than your application. You can get some idea of how the traffic flows by looking at how the DNS for the custom domain is resolving: nslookup app. ${ AZ_USER } .ws.mobb.cloud Your output will look something similar to: Server: 168 .63.129.16 Address: 168 .63.129.16#53 Non-authoritative answer: app.user1.ws.mobb.cloud canonical name = user1-ilb-3686-fqchgscue9gqb7hq.z01.azurefd.net. user1-ilb-3686-fqchgscue9gqb7hq.z01.azurefd.net canonical name = star-azurefd-prod.trafficmanager.net. star-azurefd-prod.trafficmanager.net canonical name = dual.part-0029.t-0009.t-msedge.net. dual.part-0029.t-0009.t-msedge.net canonical name = part-0029.t-0009.t-msedge.net. Name: part-0029.t-0009.t-msedge.net Address: 13 .107.246.57 Name: part-0029.t-0009.t-msedge.net Address: 13 .107.213.57 Name: part-0029.t-0009.t-msedge.net Address: 2620 :1ec:46::57 Name: part-0029.t-0009.t-msedge.net Address: 2620 :1ec:bdf::57 Notice how the results show traffic coming from *.t-msedge.net . Congratulations! You have now deployed a custom application, and exposed it to the internet using Azure Front Door.","title":"Afd"},{"location":"app/cicd/","text":"Next, we'll automate deploying our application using the OpenShift Pipelines operator, which is based on the open source Tekton project. If you would like to read more about OpenShift Pipelines, see the Red Hat documentation . GitHub Account Required This section of the workshop requires a personal GitHub account. If you do not have a GitHub account and do not wish to create one, you can skip this section and move to the next section. Install the OpenShift Pipelines operator # Return to your tab with the OpenShift Web Console. If you need to reauthenticate, follow the steps in the Access Your Cluster section. Using the menu on the left Select Operator -> OperatorHub . In the search box, search for \"OpenShift Pipelines\" and click on the Red Hat OpenShift Pipelines box. Click on Install on the page that appears. Accept the defaults that are presented and select Install to install the operator. Allow the operator a few minutes to successfully install the OpenShift Pipelines operator into the cluster. Configure the GitHub integration # In your web browser, go to the following GitHub repositories: https://github.com/rh-mobb/common-java-dependencies https://github.com/rh-mobb/aro-workshop-app Ensure you are logged in to GitHub and select the Fork button for both repositories and then choose your own GitHub account. Next, browse to https://github.com/settings/tokens/new and create a new GitHub Personal Access Token. Set the Scope to \"repo\" and click Generate Token . Warning Do not forget to delete this token once the workshop is over. Next, save the token to your Cloud Shell instance. To do so, run the following command, ensuring you replace the INSERT_TOKEN_HERE with your Personal Access Token: GH_PAT = INSERT_TOKEN_HERE echo \"export GH_PAT= ${ GH_PAT } \" >> ~/.workshoprc Then, save your GitHub username as a variable. To do so, run the following command, ensuring you replace the GITHUB_USER_ID with your GitHub username. export GH_USER = GITHUB_USER_ID echo \"export GH_USER= ${ GH_USER } \" >> ~/.workshoprc Next, we'll create a new working directory to clone our forked GitHub repositories. To do so, run the following commands: mkdir ~/gitops cd ~/gitops git clone https://github.com/ ${ GH_USER } /common-java-dependencies.git git clone https://github.com/ ${ GH_USER } /aro-workshop-app.git Import tasks to our pipeline # The next thing we need to do is import common tasks that our pipeline will use. These common tasks are designed to be reused across multiple pipelines. Let's start by taking a look at the reusable tasks that we will be using. To do so, run the following command: ls ~/gitops/aro-workshop-app/pipeline/tasks/*.yaml Expected output: /home/user/gitops/aro-workshop-app/pipeline/tasks/1-git-clone.yaml /home/user/gitops/aro-workshop-app/pipeline/tasks/2-mvn.yaml /home/user/gitops/aro-workshop-app/pipeline/tasks/3-mvn-build-image.yaml /home/user/gitops/aro-workshop-app/pipeline/tasks/4-apply-manifest.yaml /home/user/gitops/aro-workshop-app/pipeline/tasks/5-update-deployment.yaml 1-git-clone.yaml Clones a given GitHub Repo. 2-mvn.yaml This Task can be used to run a Maven build 3-mvn-build-image.yaml Packages source with maven builds and into a container image, then pushes it to a container registry. Builds source into a container image using Project Atomic's Buildah build tool. It uses Buildah's support for building from Dockerfiles, using its buildah bud command.This command executes the directives in the Dockerfile to assemble a container image, then pushes that image to a container registry. 4-apply-manifest.yaml Applied manifest files to the cluster 5-update-deployment.yaml Updates a deployment with the new container image. Next, we need to apply all of these tasks to our cluster. To do so, run the following command: oc apply -f ~/gitops/aro-workshop-app/pipeline/tasks Your output should match this: task.tekton.dev/git-clone configured task.tekton.dev/maven configured task.tekton.dev/build-maven-image configured task.tekton.dev/apply-manifests configured task.tekton.dev/update-deployment configured Configure Azure Container Registry # Next we need to create an Azure Container Registry. To do so, run the following command: az acr create --resource-group ${ AZ_RG } \\ --name ${ AZ_USER }${ UNIQUE } --sku Basic az acr update -n ${ AZ_USER }${ UNIQUE } --admin-enabled true Next, we need to create a secret to push and pull images into the Azure Container Registry. To do so, run the following command to retrieve the token: ACR_PWD = $( az acr credential show -n ${ AZ_USER }${ UNIQUE } -g ${ AZ_RG } --query 'passwords[0].value' -o tsv ) echo \"ACR Token (Sensitive Value): ${ ACR_PWD } \" Then, create the secret using the retrieved token. To do so, run the following command: oc -n microsweeper-ex create secret docker-registry --docker-server = ${ AZ_USER }${ UNIQUE } .azurecr.io \\ --docker-username = \" ${ AZ_USER }${ UNIQUE } \" --docker-password = \" ${ ACR_PWD } \" \\ --docker-email = unused acr-secret Configure our pipeline # Next, create the pipeline service account and permissions that the pipeline tasks will run under. To do so, run the following command: oc create -f ~/gitops/aro-workshop-app/pipeline/1-pipeline-account.yaml Your output should match this: serviceaccount/pipeline configured secret/kube-api-secret created role.rbac.authorization.k8s.io/pipeline-role created rolebinding.rbac.authorization.k8s.io/pipeline-role-binding created Next, we need to link the ACR credential secret we just created, so the service account can mount and pull images from ACR. To do so, run the following command: oc -n microsweeper-ex secrets link pipeline acr-secret --for = pull,mount Next, we should verify that our secret is linked to our service account, to do so, run the following command: oc -n microsweeper-ex describe sa pipeline | grep \"acr-secret\" You should see the following output: acr-secret Mountable secrets: acr-secret We also need to give the pipeline permission for certain privileged security context constraints to that it can execute builds. To grant these permissions, run the following command: oc -n microsweeper-ex adm policy add-scc-to-user anyuid -z pipeline oc -n microsweeper-ex adm policy add-scc-to-user privileged -z pipeline Create a persistent volume claim that the pipeline will use to store build images. To do so, run the following command: oc create -f ~/gitops/aro-workshop-app/pipeline/2-pipeline-pvc.yaml Next, let's review the pipeline definition. To do so, open the following link in a new tab: https://github.com/rh-mobb/aro-hackaton-app/blob/main/pipeline/3-pipeline.yaml . Browse through the file and notice all the tasks that are being executed. These are the tasks we imported in the previous step. The pipeline definition simply says which order the tasks are run and what parameters should be passed between tasks. Update Application Settings # Now that we have the source code forked, we need to copy the properties file we created in the previous section to our new code base. To do so, run the following command: cp ~/aro-workshop-app/src/main/resources/application.properties \\ ~/gitops/aro-workshop-app/src/main/resources/application.properties Next, let's configure our Git CLI. To do so, run the following commands: git config --global user.email \" ${ GH_USER } @github.io\" git config --global user.name \" ${ GH_USER } \" Finally, let's commit our changes to GitHub. To do so, run the following set of commands: cd ~/gitops/aro-workshop-app git remote set-url origin https://${GH_USER}:${GH_PAT}@github.com/${GH_USER}/aro-workshop-app git add . git commit -am \"Update Properties File\" git push In addition, let's go ahead and create a secret with our GitHub credentials that we will need later. To do so, run the following command: cat << EOF | oc apply -f - apiVersion : v1 kind : Secret metadata : name : gitsecret annotations : tekton.dev/git-0 : https://github.com namespace : microsweeper-ex type : kubernetes.io/basic-auth stringData : username : ${GH_USER} secretToken : ${GH_PAT} EOF Now let's proceed with creating our pipeline definition. To do so, run the following command: oc create -f ~/gitops/aro-workshop-app/pipeline/3-pipeline.yaml Next, let's tell the deployment to use ACR instead of the built-in OpenShift image registry. To do so, run the following command: oc patch deploy/microsweeper-appservice \\ --patch-file ~/gitops/aro-workshop-app/pipeline/5-deployment-patch.yaml Finally, we will create a pipeline run that will execute the pipeline, pull the code from your forked GitHub repositories, build the image, and deploy it to ARO. To do this, run the following command: cat << EOF | oc create -f - apiVersion : tekton.dev/v1beta1 kind : PipelineRun metadata : generateName : minesweeper-pipeline- namespace : microsweeper-ex spec : pipelineRef : name : maven-pipeline serviceAccountName : pipeline params : - name : application-name value : microsweeper-appservice - name : dependency-git-url value : https://github.com/${GH_USER}/common-java-dependencies - name : application-git-url value : https://github.com/${GH_USER}/aro-workshop-app - name : dockerfile-path value : src/main/docker/Dockerfile.jvm - name : image-name value : ${AZ_USER}${UNIQUE}.azurecr.io/minesweeper workspaces : - name : source persistentVolumeClaim : claimName : minesweeper-source-pvc EOF Validate the pipeline # Let's take a look at the OpenShift Web Console to see what was created and if the application was successfully deployed. From the OpenShift Web Console, click on Pipelines -> Tasks . Notice the 5 tasks that we imported and click into them to view the YAML definitions. Next, lets look at the Pipeline. Click on Pipelines . Notice that it is either still running, or the last run was successful. Click on maven-pipeline to view the pipeline details. On the following screen, click on PipelineRuns to view the status of each Pipeline Run. Lastly, click on the PipelineRun name and you can see all the details and steps of the pipeline. If your are curious, you can also view the logs of the different tasks that were run. Event Triggering # At this point, we can successfully build and deploy new code by manually running our pipeline. But how can we configure the pipeline to run automatically when we commit code to Git? We can do so with an Event Listener and a Trigger. Let's start by looking at the resources we will be creating to create our event listener and trigger. ls ~/gitops/aro-workshop-app/pipeline/tasks/event-listener/*.yaml Your output should match: /home/user/gitops/aro-workshop-app/pipeline/tasks/event-listener/1-web-trigger-binding.yaml /home/user/gitops/aro-workshop-app/pipeline/tasks/event-listener/2-web-trigger-template.yaml /home/user/gitops/aro-workshop-app/pipeline/tasks/event-listener/3-web-trigger.yaml /home/user/gitops/aro-workshop-app/pipeline/tasks/event-listener/4-event-listener.yaml Take a look at the files listed: 1-web-trigger-binding.yaml This TriggerBinding allows you to extract fields, such as the git repository name, git commit number, and the git repository URL in this case. To learn more about TriggerBindings, click here 2-web-trigger-template.yaml The TriggerTemplate specifies how the pipeline should be run. Browsing the file above, you will see there is a definition of the PipelineRun that looks exactly like the PipelineRun you create in the previous step. This is by design! ... it should be the same. Edit /home/user/gitops/aro-workshop-app/pipeline/tasks/event-listener/2-web-trigger-template.yaml with your favorite text editor (vim!) and replace the <> sections with the values of from the following command: echo \"GITHUB_USER: ${ GH_USER } \" echo \"ACR_ENDPOINT: ${ AZ_USER }${ UNIQUE } .azurecr.io/minesweeper\" - name: dependency-git-url value: https://github.com/GITHUB_USER_ID/common-java-dependencies - name: application-git-url value: https://github.com/GITHUB_USER_ID/aro-workshop-app [...] - name: image-name value: ACR_ENDPOINT.azurecr.io/minesweeper To learn more about TriggerTemplates, review the Tekton documentation . 3-web-trigger.yaml The next file we have is the Trigger. The Trigger specifies what should happen when the EventListener detects an Event. Looking at this file, you will see that we are looking for 'Push' events that will create an instance of the TriggerTemplate that we just created. This in turn will start the PipelineRun. To learn more about Triggers, review the Tekton documentation . 4-event-listenter.yaml The last file we have is the Event Listener. An EventListener is a Kubernetes object that listens for events at a specified port on your OpenShift cluster. It exposes an OpenShift Route that receives incoming event and specifies one or more Triggers. To learn more about EventListeners, review the Tekton documentation . Now that you have reviewed all the files, let's apply them to our cluster. oc create -f ~/gitops/aro-workshop-app/pipeline/tasks/event-listener Before we test out our EventListener and Trigger, lets review what was created in OpenShift. From the OpenShift console, under Pipelines, click on Triggers. Browse the EventListener, TriggerTemplate and TriggerBindings that you just created. The next thing we need to do, is connect our EventListener with Git. When an action, such as a git push, happens, git will need to call our EventListener to start the build and deploy process. The first thing we need to do is expose our EventListener service to the internet. To do so, we'll run the oc expose command: oc -n microsweeper-ex expose svc el-minesweeper-el Note Since this is public cluster, we can simply use the default ingress controller. For a private cluster, you can use Azure Front Door to expose the endpoint. To get the URL of the Event Listener Route that we just created, run the following command: oc -n microsweeper-ex get route el-minesweeper-el -o jsonpath = '{.spec.host}' For example, your output will look something similar to: el-minesweeper-el-microsweeper-ex.apps.ce7l3kf6.eastus.aroapp.io In that case, you'd enter http://el-minesweeper-el-microsweeper-ex.apps.ce7l3kf6.eastus.aroapp.io in your browser. The last step we need to do, is configure GitHub to call this event listener URL when events occur. From your browser, go to your personal GitHub aro-workshop-app repository, and click on Settings . On the next screen, click on Webhooks . Click on the Add Webhook button. On the next screen, enter the following settings: PayloadURL - enter the URL you got above (for example: http://el-minesweeper-el-microsweeper-ex.apps.ce7l3kf6.eastus.aroapp.io ) ContentType - select application/json Secret - this your GitHub Personal Access Token Where does this secret value come from? Refer to the ~/gitops/aro-workshop-app/pipeline/tasks/event-listener/3-web-trigger.yaml file. You will see the following snippet that contains the secret to access git. interceptors: - ref: name: \"github\" params: - name: \"secretRef\" value: secretName: gitsecret secretKey: secretToken - name: \"eventTypes\" value: [ \"push\" ] The secret you enter here for the git webhook, needs to match the value for the secretToken key of the a secret named gitsecret. If you remember in the previous step, we create this secret and used your git token as this value. Keep the remaining defaults, and click Add webhook . Test the Event Triggering # Now that we have our trigger, eventlistener and git webhook setup, lets test it out. Make sure you are in the directory for your personal git repo where the application is, and edit the ./src/main/resources/META-INF/resources/index.html file. Search for Leaderboard and change it to \\<YOUR NAME> Leaderboard. cd ~/gitops/aro-workshop-app vi src/main/resources/META-INF/resources/index.html Now commit and push the change git commit -am 'Updated leaderboard title' git push Pushing the change to the your git repository will kick of the event listener which will start the pipeline. As a bonus, if you want to look at the logs of the event listener, you can use the tekton (tkn) cli. tkn eventlistener logs minesweeper-el Quickly switch over to your OpenShift Web Console, and watch the pipeline run. Once the pipeline finishes, check out the change. From the OpenShift Web Console, click on Networking -> Routes . Hopefully, you will see the updated application with a new title for the leaderboard!","title":"Cicd"},{"location":"app/cicd/#install-the-openshift-pipelines-operator","text":"Return to your tab with the OpenShift Web Console. If you need to reauthenticate, follow the steps in the Access Your Cluster section. Using the menu on the left Select Operator -> OperatorHub . In the search box, search for \"OpenShift Pipelines\" and click on the Red Hat OpenShift Pipelines box. Click on Install on the page that appears. Accept the defaults that are presented and select Install to install the operator. Allow the operator a few minutes to successfully install the OpenShift Pipelines operator into the cluster.","title":"Install the OpenShift Pipelines operator"},{"location":"app/cicd/#configure-the-github-integration","text":"In your web browser, go to the following GitHub repositories: https://github.com/rh-mobb/common-java-dependencies https://github.com/rh-mobb/aro-workshop-app Ensure you are logged in to GitHub and select the Fork button for both repositories and then choose your own GitHub account. Next, browse to https://github.com/settings/tokens/new and create a new GitHub Personal Access Token. Set the Scope to \"repo\" and click Generate Token . Warning Do not forget to delete this token once the workshop is over. Next, save the token to your Cloud Shell instance. To do so, run the following command, ensuring you replace the INSERT_TOKEN_HERE with your Personal Access Token: GH_PAT = INSERT_TOKEN_HERE echo \"export GH_PAT= ${ GH_PAT } \" >> ~/.workshoprc Then, save your GitHub username as a variable. To do so, run the following command, ensuring you replace the GITHUB_USER_ID with your GitHub username. export GH_USER = GITHUB_USER_ID echo \"export GH_USER= ${ GH_USER } \" >> ~/.workshoprc Next, we'll create a new working directory to clone our forked GitHub repositories. To do so, run the following commands: mkdir ~/gitops cd ~/gitops git clone https://github.com/ ${ GH_USER } /common-java-dependencies.git git clone https://github.com/ ${ GH_USER } /aro-workshop-app.git","title":"Configure the GitHub integration"},{"location":"app/cicd/#import-tasks-to-our-pipeline","text":"The next thing we need to do is import common tasks that our pipeline will use. These common tasks are designed to be reused across multiple pipelines. Let's start by taking a look at the reusable tasks that we will be using. To do so, run the following command: ls ~/gitops/aro-workshop-app/pipeline/tasks/*.yaml Expected output: /home/user/gitops/aro-workshop-app/pipeline/tasks/1-git-clone.yaml /home/user/gitops/aro-workshop-app/pipeline/tasks/2-mvn.yaml /home/user/gitops/aro-workshop-app/pipeline/tasks/3-mvn-build-image.yaml /home/user/gitops/aro-workshop-app/pipeline/tasks/4-apply-manifest.yaml /home/user/gitops/aro-workshop-app/pipeline/tasks/5-update-deployment.yaml 1-git-clone.yaml Clones a given GitHub Repo. 2-mvn.yaml This Task can be used to run a Maven build 3-mvn-build-image.yaml Packages source with maven builds and into a container image, then pushes it to a container registry. Builds source into a container image using Project Atomic's Buildah build tool. It uses Buildah's support for building from Dockerfiles, using its buildah bud command.This command executes the directives in the Dockerfile to assemble a container image, then pushes that image to a container registry. 4-apply-manifest.yaml Applied manifest files to the cluster 5-update-deployment.yaml Updates a deployment with the new container image. Next, we need to apply all of these tasks to our cluster. To do so, run the following command: oc apply -f ~/gitops/aro-workshop-app/pipeline/tasks Your output should match this: task.tekton.dev/git-clone configured task.tekton.dev/maven configured task.tekton.dev/build-maven-image configured task.tekton.dev/apply-manifests configured task.tekton.dev/update-deployment configured","title":"Import tasks to our pipeline"},{"location":"app/cicd/#configure-azure-container-registry","text":"Next we need to create an Azure Container Registry. To do so, run the following command: az acr create --resource-group ${ AZ_RG } \\ --name ${ AZ_USER }${ UNIQUE } --sku Basic az acr update -n ${ AZ_USER }${ UNIQUE } --admin-enabled true Next, we need to create a secret to push and pull images into the Azure Container Registry. To do so, run the following command to retrieve the token: ACR_PWD = $( az acr credential show -n ${ AZ_USER }${ UNIQUE } -g ${ AZ_RG } --query 'passwords[0].value' -o tsv ) echo \"ACR Token (Sensitive Value): ${ ACR_PWD } \" Then, create the secret using the retrieved token. To do so, run the following command: oc -n microsweeper-ex create secret docker-registry --docker-server = ${ AZ_USER }${ UNIQUE } .azurecr.io \\ --docker-username = \" ${ AZ_USER }${ UNIQUE } \" --docker-password = \" ${ ACR_PWD } \" \\ --docker-email = unused acr-secret","title":"Configure Azure Container Registry"},{"location":"app/cicd/#configure-our-pipeline","text":"Next, create the pipeline service account and permissions that the pipeline tasks will run under. To do so, run the following command: oc create -f ~/gitops/aro-workshop-app/pipeline/1-pipeline-account.yaml Your output should match this: serviceaccount/pipeline configured secret/kube-api-secret created role.rbac.authorization.k8s.io/pipeline-role created rolebinding.rbac.authorization.k8s.io/pipeline-role-binding created Next, we need to link the ACR credential secret we just created, so the service account can mount and pull images from ACR. To do so, run the following command: oc -n microsweeper-ex secrets link pipeline acr-secret --for = pull,mount Next, we should verify that our secret is linked to our service account, to do so, run the following command: oc -n microsweeper-ex describe sa pipeline | grep \"acr-secret\" You should see the following output: acr-secret Mountable secrets: acr-secret We also need to give the pipeline permission for certain privileged security context constraints to that it can execute builds. To grant these permissions, run the following command: oc -n microsweeper-ex adm policy add-scc-to-user anyuid -z pipeline oc -n microsweeper-ex adm policy add-scc-to-user privileged -z pipeline Create a persistent volume claim that the pipeline will use to store build images. To do so, run the following command: oc create -f ~/gitops/aro-workshop-app/pipeline/2-pipeline-pvc.yaml Next, let's review the pipeline definition. To do so, open the following link in a new tab: https://github.com/rh-mobb/aro-hackaton-app/blob/main/pipeline/3-pipeline.yaml . Browse through the file and notice all the tasks that are being executed. These are the tasks we imported in the previous step. The pipeline definition simply says which order the tasks are run and what parameters should be passed between tasks.","title":"Configure our pipeline"},{"location":"app/cicd/#update-application-settings","text":"Now that we have the source code forked, we need to copy the properties file we created in the previous section to our new code base. To do so, run the following command: cp ~/aro-workshop-app/src/main/resources/application.properties \\ ~/gitops/aro-workshop-app/src/main/resources/application.properties Next, let's configure our Git CLI. To do so, run the following commands: git config --global user.email \" ${ GH_USER } @github.io\" git config --global user.name \" ${ GH_USER } \" Finally, let's commit our changes to GitHub. To do so, run the following set of commands: cd ~/gitops/aro-workshop-app git remote set-url origin https://${GH_USER}:${GH_PAT}@github.com/${GH_USER}/aro-workshop-app git add . git commit -am \"Update Properties File\" git push In addition, let's go ahead and create a secret with our GitHub credentials that we will need later. To do so, run the following command: cat << EOF | oc apply -f - apiVersion : v1 kind : Secret metadata : name : gitsecret annotations : tekton.dev/git-0 : https://github.com namespace : microsweeper-ex type : kubernetes.io/basic-auth stringData : username : ${GH_USER} secretToken : ${GH_PAT} EOF Now let's proceed with creating our pipeline definition. To do so, run the following command: oc create -f ~/gitops/aro-workshop-app/pipeline/3-pipeline.yaml Next, let's tell the deployment to use ACR instead of the built-in OpenShift image registry. To do so, run the following command: oc patch deploy/microsweeper-appservice \\ --patch-file ~/gitops/aro-workshop-app/pipeline/5-deployment-patch.yaml Finally, we will create a pipeline run that will execute the pipeline, pull the code from your forked GitHub repositories, build the image, and deploy it to ARO. To do this, run the following command: cat << EOF | oc create -f - apiVersion : tekton.dev/v1beta1 kind : PipelineRun metadata : generateName : minesweeper-pipeline- namespace : microsweeper-ex spec : pipelineRef : name : maven-pipeline serviceAccountName : pipeline params : - name : application-name value : microsweeper-appservice - name : dependency-git-url value : https://github.com/${GH_USER}/common-java-dependencies - name : application-git-url value : https://github.com/${GH_USER}/aro-workshop-app - name : dockerfile-path value : src/main/docker/Dockerfile.jvm - name : image-name value : ${AZ_USER}${UNIQUE}.azurecr.io/minesweeper workspaces : - name : source persistentVolumeClaim : claimName : minesweeper-source-pvc EOF","title":"Update Application Settings"},{"location":"app/cicd/#validate-the-pipeline","text":"Let's take a look at the OpenShift Web Console to see what was created and if the application was successfully deployed. From the OpenShift Web Console, click on Pipelines -> Tasks . Notice the 5 tasks that we imported and click into them to view the YAML definitions. Next, lets look at the Pipeline. Click on Pipelines . Notice that it is either still running, or the last run was successful. Click on maven-pipeline to view the pipeline details. On the following screen, click on PipelineRuns to view the status of each Pipeline Run. Lastly, click on the PipelineRun name and you can see all the details and steps of the pipeline. If your are curious, you can also view the logs of the different tasks that were run.","title":"Validate the pipeline"},{"location":"app/cicd/#event-triggering","text":"At this point, we can successfully build and deploy new code by manually running our pipeline. But how can we configure the pipeline to run automatically when we commit code to Git? We can do so with an Event Listener and a Trigger. Let's start by looking at the resources we will be creating to create our event listener and trigger. ls ~/gitops/aro-workshop-app/pipeline/tasks/event-listener/*.yaml Your output should match: /home/user/gitops/aro-workshop-app/pipeline/tasks/event-listener/1-web-trigger-binding.yaml /home/user/gitops/aro-workshop-app/pipeline/tasks/event-listener/2-web-trigger-template.yaml /home/user/gitops/aro-workshop-app/pipeline/tasks/event-listener/3-web-trigger.yaml /home/user/gitops/aro-workshop-app/pipeline/tasks/event-listener/4-event-listener.yaml Take a look at the files listed: 1-web-trigger-binding.yaml This TriggerBinding allows you to extract fields, such as the git repository name, git commit number, and the git repository URL in this case. To learn more about TriggerBindings, click here 2-web-trigger-template.yaml The TriggerTemplate specifies how the pipeline should be run. Browsing the file above, you will see there is a definition of the PipelineRun that looks exactly like the PipelineRun you create in the previous step. This is by design! ... it should be the same. Edit /home/user/gitops/aro-workshop-app/pipeline/tasks/event-listener/2-web-trigger-template.yaml with your favorite text editor (vim!) and replace the <> sections with the values of from the following command: echo \"GITHUB_USER: ${ GH_USER } \" echo \"ACR_ENDPOINT: ${ AZ_USER }${ UNIQUE } .azurecr.io/minesweeper\" - name: dependency-git-url value: https://github.com/GITHUB_USER_ID/common-java-dependencies - name: application-git-url value: https://github.com/GITHUB_USER_ID/aro-workshop-app [...] - name: image-name value: ACR_ENDPOINT.azurecr.io/minesweeper To learn more about TriggerTemplates, review the Tekton documentation . 3-web-trigger.yaml The next file we have is the Trigger. The Trigger specifies what should happen when the EventListener detects an Event. Looking at this file, you will see that we are looking for 'Push' events that will create an instance of the TriggerTemplate that we just created. This in turn will start the PipelineRun. To learn more about Triggers, review the Tekton documentation . 4-event-listenter.yaml The last file we have is the Event Listener. An EventListener is a Kubernetes object that listens for events at a specified port on your OpenShift cluster. It exposes an OpenShift Route that receives incoming event and specifies one or more Triggers. To learn more about EventListeners, review the Tekton documentation . Now that you have reviewed all the files, let's apply them to our cluster. oc create -f ~/gitops/aro-workshop-app/pipeline/tasks/event-listener Before we test out our EventListener and Trigger, lets review what was created in OpenShift. From the OpenShift console, under Pipelines, click on Triggers. Browse the EventListener, TriggerTemplate and TriggerBindings that you just created. The next thing we need to do, is connect our EventListener with Git. When an action, such as a git push, happens, git will need to call our EventListener to start the build and deploy process. The first thing we need to do is expose our EventListener service to the internet. To do so, we'll run the oc expose command: oc -n microsweeper-ex expose svc el-minesweeper-el Note Since this is public cluster, we can simply use the default ingress controller. For a private cluster, you can use Azure Front Door to expose the endpoint. To get the URL of the Event Listener Route that we just created, run the following command: oc -n microsweeper-ex get route el-minesweeper-el -o jsonpath = '{.spec.host}' For example, your output will look something similar to: el-minesweeper-el-microsweeper-ex.apps.ce7l3kf6.eastus.aroapp.io In that case, you'd enter http://el-minesweeper-el-microsweeper-ex.apps.ce7l3kf6.eastus.aroapp.io in your browser. The last step we need to do, is configure GitHub to call this event listener URL when events occur. From your browser, go to your personal GitHub aro-workshop-app repository, and click on Settings . On the next screen, click on Webhooks . Click on the Add Webhook button. On the next screen, enter the following settings: PayloadURL - enter the URL you got above (for example: http://el-minesweeper-el-microsweeper-ex.apps.ce7l3kf6.eastus.aroapp.io ) ContentType - select application/json Secret - this your GitHub Personal Access Token Where does this secret value come from? Refer to the ~/gitops/aro-workshop-app/pipeline/tasks/event-listener/3-web-trigger.yaml file. You will see the following snippet that contains the secret to access git. interceptors: - ref: name: \"github\" params: - name: \"secretRef\" value: secretName: gitsecret secretKey: secretToken - name: \"eventTypes\" value: [ \"push\" ] The secret you enter here for the git webhook, needs to match the value for the secretToken key of the a secret named gitsecret. If you remember in the previous step, we create this secret and used your git token as this value. Keep the remaining defaults, and click Add webhook .","title":"Event Triggering"},{"location":"app/cicd/#test-the-event-triggering","text":"Now that we have our trigger, eventlistener and git webhook setup, lets test it out. Make sure you are in the directory for your personal git repo where the application is, and edit the ./src/main/resources/META-INF/resources/index.html file. Search for Leaderboard and change it to \\<YOUR NAME> Leaderboard. cd ~/gitops/aro-workshop-app vi src/main/resources/META-INF/resources/index.html Now commit and push the change git commit -am 'Updated leaderboard title' git push Pushing the change to the your git repository will kick of the event listener which will start the pipeline. As a bonus, if you want to look at the logs of the event listener, you can use the tekton (tkn) cli. tkn eventlistener logs minesweeper-el Quickly switch over to your OpenShift Web Console, and watch the pipeline run. Once the pipeline finishes, check out the change. From the OpenShift Web Console, click on Networking -> Routes . Hopefully, you will see the updated application with a new title for the leaderboard!","title":"Test the Event Triggering"},{"location":"app/deploy/","text":"Introduction # It's time for us to put our cluster to work and deploy a workload. We're going to build an example Java application, microsweeper , using Quarkus (a Kubernetes Native Java stack) and Azure Database for PostgreSQL . We'll then deploy the application to our Azure Red Hat OpenShift cluster, connect to the database using Azure Private Link, and securely expose this application over the internet using Azure Front Door. Create Azure Database for PostgreSQL instance # To deploy our PostgreSQL database, we'll use the Azure Service Operator (ASO). First, let's create a namespace (also known as a project in OpenShift). To do so, run the following command: oc new-project microsweeper-ex Next, let's inherit our existing Azure Resource Group (again) to hold Azure resources that we create with ASO. To do so, run the following commmand: cat <<EOF | oc apply -f - apiVersion : resources.azure.com/v1beta20200601 kind : ResourceGroup metadata : name : \"${AZ_RG}\" namespace : microsweeper-ex annotations : serviceoperator.azure.com/reconcile-policy : skip spec : location : eastus EOF Let's verify that our Azure Resource Group has been successfully inherited. To do so, run the following command: oc get resourcegroup.resources.azure.com/ ${ AZ_RG } You should receive output that shows your resource group is Ready and Succeeded , similar to this: NAME READY REASON MESSAGE user1-rg True Succeeded Let's now create a secret for the database to use for the admin password. We'll re-use our random OpenShift password. To do so, run the following command: cat <<EOF | oc apply -f - apiVersion : v1 kind : Secret metadata : name : server-admin-pw namespace : microsweeper-ex stringData : password : \"${OCP_PASS}\" type : Opaque EOF Next, let's create the Azure Postgres Flexible Server resource. To do so, run the following command: cat <<EOF | oc apply -f - apiVersion : dbforpostgresql.azure.com/v1beta20210601 kind : FlexibleServer metadata : name : \"${AZ_USER}-minesweeper-database\" namespace : microsweeper-ex spec : location : \"${AZ_LOCATION}\" owner : name : \"${AZ_RG}\" version : \"13\" sku : name : Standard_B1ms tier : Burstable administratorLogin : myAdmin administratorLoginPassword : name : server-admin-pw key : password storage : storageSizeGB : 32 EOF Now, let's create an Azure Postgres Flexible Server Configuration resource. To do so, run the following command: cat <<EOF | oc apply -f - apiVersion: dbforpostgresql.azure.com/v1beta20210601 kind: FlexibleServersConfiguration metadata: name: pgaudit namespace: microsweeper-ex spec: owner: name: \"${AZ_USER}-minesweeper-database\" azureName: pgaudit.log source: user-override value: READ EOF Now, let's create a wide-open firewall rule for the database. To do so, run the following command: cat <<EOF | oc apply -f - apiVersion: dbforpostgresql.azure.com/v1beta20210601 kind: FlexibleServersFirewallRule metadata: name: wksp-fw-rule name: microsweeper-ex spec: owner: name: \"${AZ_USER}-minesweeper-database\" startIpAddress: 0.0.0.0 endIpAddress: 255.255.255.255 EOF Next, let's create a Azure Postgres Flexible Server Database instance. To do so, run the following command: cat <<EOF | oc apply -f - apiVersion: dbforpostgresql.azure.com/v1beta20210601 kind: FlexibleServersDatabase metadata: name: score namespace: microsweeper-ex spec: owner: name: \"${AZ_USER}-minesweeper-database\" charset: utf8 EOF Warning It takes about 10 minutes for the database to become fully operational and running. Next, let's monitor the creation process, run the following command: watch ~/bin/oc -n microsweeper-ex get flexibleservers.dbforpostgresql.azure.com ${ AZ_USER } -minesweeper-database Your output will look like this: NAME READY SEVERITY REASON MESSAGE user1-minesweeper-database False Info Reconciling The resource is in the process of being reconciled by the operator Eventually, the result will show: NAME READY SEVERITY REASON MESSAGE user1-minesweeper-database True Succeeded Info Watch will refresh the output of a command every second. Hit CTRL and c on your keyboard to exit the watch command when you're ready to move on to the next part of the workshop. (Optional) Once created, you can view the resource in the Azure Portal. To do so, search for \"Postgres\" in the search bar. Warning The resource will not show up until after the PostgreSQL instance has been created. Then, click on the the database name itself. Finally, let's check connectivity from our Cloud Shell to our database. To do so, run the following command: psql \\ \"host= ${ AZ_USER } -minesweeper-database.postgres.database.azure.com port=5432 dbname=score user=myAdmin password= ${ OCP_PASS } sslmode=require\" \\ -c \"select now();\" Your output should look similar to: now ------------------------------- 2022 -11-15 06 :39:13.903299+00 ( 1 row ) Build and deploy the Microsweeper app # Now that we've got a PostgreSQL instance up and running, let's build and deploy our application. First, let's clone the application from GitHub to our local Cloud Shell. To do so, run the following command: git clone https://github.com/rh-mobb/aro-workshop-app.git Next, let's change directory into the newly cloned Git repository. To do so, run the following command: cd aro-workshop-app Next, we will add the OpenShift extension to the Quarkus CLI. To do so, run the following command: quarkus ext add openshift Now, we'll configure Quarkus to use the PostgreSQL database that we created earlier in this section. To do so, we'll create an application.properties file using by running the following command: cat < <EOF > ./src/main/resources/application.properties # Database configurations %prod.quarkus.datasource.db-kind=postgresql %prod.quarkus.datasource.jdbc.url=jdbc:postgresql://${AZ_USER}-minesweeper-database.postgres.database.azure.com:5432/score %prod.quarkus.datasource.jdbc.driver=org.postgresql.Driver %prod.quarkus.datasource.username=myAdmin %prod.quarkus.datasource.password=${OCP_PASS} %prod.quarkus.hibernate-orm.database.generation=drop-and-create %prod.quarkus.hibernate-orm.database.generation=update # OpenShift configurations %prod.quarkus.kubernetes-client.trust-certs=true %prod.quarkus.kubernetes.deploy=true %prod.quarkus.kubernetes.deployment-target=openshift %prod.quarkus.openshift.build-strategy=docker %prod.quarkus.openshift.expose=true %prod.quarkus.openshift.deployment-kind=Deployment %prod.quarkus.container-image.group=microsweeper-ex EOF Now that we've provided the proper configuration, we will build our application. We'll do this using source-to-image , a tool built-in to OpenShift. To start the build and deploy, run the following command: quarkus build --no-tests Review # Let's take a look at what this command did, along with everything that was created in your cluster. Return to your tab with the OpenShift Web Console. If you need to reauthenticate, follow the steps in the Access Your Cluster section. Container Images # From the Administrator perspective, expand Builds and then ImageStreams , and select the microsweeper-ex project. . You will see two images that were created on your behalf when you ran the quarkus build command. There is one image for openjdk-11 that comes with OpenShift as a Universal Base Image (UBI) that the application will run under. With UBI, you get highly optimized and secure container images that you can build your applications with. For more information on UBI please read this article . The second image you see is the the microsweeper-appservice image. This is the image for the application that was built automatically for you and pushed to the built-in container registry inside of OpenShift. Image Build # How did those images get built you ask? Back on the OpenShift Web Console, click on BuildConfigs and then the microsweeper-appservice entry. When you ran the quarkus build command, this created the BuildConfig you can see here. In our quarkus settings, we set the deployment strategy to build the image using Docker. The Dockerfile file from the git repo that we cloned was used for this BuildConfig. Info A build configuration describes a single build definition and a set of triggers for when a new build is created. Build configurations are defined by a BuildConfig, which is a REST object that can be used in a POST to the API server to create a new instance. You can read more about BuildConfigs here Once the BuildConfig was created, the source-to-image process kicked off a Build of that BuildConfig. The build is what actually does the work in building and deploying the image. We started with defining what to be built with the BuildConfig and then actually did the work with the Build. You can read more about Builds here To look at what the build actually did, click on Builds tab and then into the first Build in the list. On the next screen, explore around. Look specifically at the YAML definition of the build and the logs to see what the build actually did. If you build failed for some reason, the logs are a great first place to start to look at to debug what happened. Image Deployment # After the image was built, the source-to-image process then deployed the application for us. In the quarkus properties file, we specified that a deployment should be created. You can view the deployment under Workloads -> Deployments , and then click on the Deployment name. Explore around the deployment screen, check out the different tabs, look at the YAML that was created. Look at the pod the deployment created, and see that it is running. The last thing we will look at is the route that was created for our application. In the quarkus properties file, we specified that the application should be exposed to the Internet. When you create a Route, you have the option to specify a hostname. To start with, we will just use the default domain that comes with ARO ( useast.aroapp.io in our case). In next section, we will expose the same application to a custom domain leveraging Azure Front Door. You can read more about routes in the Red Hat documentation From the OpenShift Web Console menu, click on Networking -> Routes , and the microsweeper-appservice route. Test the application # While in the route section of the OpenShift Web Console, click the URL under Location : You can also get the the URL for your application using the command line: oc -n microsweeper-ex get route microsweeper-appservice -o jsonpath = '{.spec.host}' Application IP # Let's take a quick look at what IP the application resolves to. Back in your Cloud Shell environment, run the following command: nslookup $( oc -n microsweeper-ex get route microsweeper-appservice -o jsonpath = '{.spec.host}' ) The output of the command will look similar to this: Server: 168 .63.129.16 Address: 168 .63.129.16#53 Non-authoritative answer: Name: microsweeper-appservice-microsweeper-ex.apps.ce7l3kf6.eastus.aroapp.io Address: 40 .117.143.193 Notice the IP address; can you guess where it comes from? It comes from the ARO Load Balancer. In this workshop, we are using a public cluster which means the load balancer is exposed to the Internet. If this was a private cluster, you would have to have connectivity to the vNet ARO is running on. This could be via a VPN connection, Azure ExpressRoute, or something else. To view the ARO load balancer, on the Azure Portal, search for \"Load Balancers\" in the search bar and click on the Load balancers service. You will notice two load balancers, one that has -internal in the name and one that does not. The -internal load balancer is used for the OpenShift API. The other load balancer (without the -internal suffix) in the name is use the public load balancer used for the default Ingress Controller. Click into the load balancer for applications. On the next screen, click on Frontend IP configuration. Notice the IP address of the 2nd load balancer on the list. This IP address matches what you found with the nslookup command. For the fun of it, we can also look at what backends this load balancer is connected to. Next, click on the pool that ends in 443. Notice the Backend pool . This is the subnet that contains all the worker nodes. And the best part is all of this came with Azure Red Hat OpenShift out of the box!","title":"Introduction"},{"location":"app/deploy/#introduction","text":"It's time for us to put our cluster to work and deploy a workload. We're going to build an example Java application, microsweeper , using Quarkus (a Kubernetes Native Java stack) and Azure Database for PostgreSQL . We'll then deploy the application to our Azure Red Hat OpenShift cluster, connect to the database using Azure Private Link, and securely expose this application over the internet using Azure Front Door.","title":"Introduction"},{"location":"app/deploy/#create-azure-database-for-postgresql-instance","text":"To deploy our PostgreSQL database, we'll use the Azure Service Operator (ASO). First, let's create a namespace (also known as a project in OpenShift). To do so, run the following command: oc new-project microsweeper-ex Next, let's inherit our existing Azure Resource Group (again) to hold Azure resources that we create with ASO. To do so, run the following commmand: cat <<EOF | oc apply -f - apiVersion : resources.azure.com/v1beta20200601 kind : ResourceGroup metadata : name : \"${AZ_RG}\" namespace : microsweeper-ex annotations : serviceoperator.azure.com/reconcile-policy : skip spec : location : eastus EOF Let's verify that our Azure Resource Group has been successfully inherited. To do so, run the following command: oc get resourcegroup.resources.azure.com/ ${ AZ_RG } You should receive output that shows your resource group is Ready and Succeeded , similar to this: NAME READY REASON MESSAGE user1-rg True Succeeded Let's now create a secret for the database to use for the admin password. We'll re-use our random OpenShift password. To do so, run the following command: cat <<EOF | oc apply -f - apiVersion : v1 kind : Secret metadata : name : server-admin-pw namespace : microsweeper-ex stringData : password : \"${OCP_PASS}\" type : Opaque EOF Next, let's create the Azure Postgres Flexible Server resource. To do so, run the following command: cat <<EOF | oc apply -f - apiVersion : dbforpostgresql.azure.com/v1beta20210601 kind : FlexibleServer metadata : name : \"${AZ_USER}-minesweeper-database\" namespace : microsweeper-ex spec : location : \"${AZ_LOCATION}\" owner : name : \"${AZ_RG}\" version : \"13\" sku : name : Standard_B1ms tier : Burstable administratorLogin : myAdmin administratorLoginPassword : name : server-admin-pw key : password storage : storageSizeGB : 32 EOF Now, let's create an Azure Postgres Flexible Server Configuration resource. To do so, run the following command: cat <<EOF | oc apply -f - apiVersion: dbforpostgresql.azure.com/v1beta20210601 kind: FlexibleServersConfiguration metadata: name: pgaudit namespace: microsweeper-ex spec: owner: name: \"${AZ_USER}-minesweeper-database\" azureName: pgaudit.log source: user-override value: READ EOF Now, let's create a wide-open firewall rule for the database. To do so, run the following command: cat <<EOF | oc apply -f - apiVersion: dbforpostgresql.azure.com/v1beta20210601 kind: FlexibleServersFirewallRule metadata: name: wksp-fw-rule name: microsweeper-ex spec: owner: name: \"${AZ_USER}-minesweeper-database\" startIpAddress: 0.0.0.0 endIpAddress: 255.255.255.255 EOF Next, let's create a Azure Postgres Flexible Server Database instance. To do so, run the following command: cat <<EOF | oc apply -f - apiVersion: dbforpostgresql.azure.com/v1beta20210601 kind: FlexibleServersDatabase metadata: name: score namespace: microsweeper-ex spec: owner: name: \"${AZ_USER}-minesweeper-database\" charset: utf8 EOF Warning It takes about 10 minutes for the database to become fully operational and running. Next, let's monitor the creation process, run the following command: watch ~/bin/oc -n microsweeper-ex get flexibleservers.dbforpostgresql.azure.com ${ AZ_USER } -minesweeper-database Your output will look like this: NAME READY SEVERITY REASON MESSAGE user1-minesweeper-database False Info Reconciling The resource is in the process of being reconciled by the operator Eventually, the result will show: NAME READY SEVERITY REASON MESSAGE user1-minesweeper-database True Succeeded Info Watch will refresh the output of a command every second. Hit CTRL and c on your keyboard to exit the watch command when you're ready to move on to the next part of the workshop. (Optional) Once created, you can view the resource in the Azure Portal. To do so, search for \"Postgres\" in the search bar. Warning The resource will not show up until after the PostgreSQL instance has been created. Then, click on the the database name itself. Finally, let's check connectivity from our Cloud Shell to our database. To do so, run the following command: psql \\ \"host= ${ AZ_USER } -minesweeper-database.postgres.database.azure.com port=5432 dbname=score user=myAdmin password= ${ OCP_PASS } sslmode=require\" \\ -c \"select now();\" Your output should look similar to: now ------------------------------- 2022 -11-15 06 :39:13.903299+00 ( 1 row )","title":"Create Azure Database for PostgreSQL instance"},{"location":"app/deploy/#build-and-deploy-the-microsweeper-app","text":"Now that we've got a PostgreSQL instance up and running, let's build and deploy our application. First, let's clone the application from GitHub to our local Cloud Shell. To do so, run the following command: git clone https://github.com/rh-mobb/aro-workshop-app.git Next, let's change directory into the newly cloned Git repository. To do so, run the following command: cd aro-workshop-app Next, we will add the OpenShift extension to the Quarkus CLI. To do so, run the following command: quarkus ext add openshift Now, we'll configure Quarkus to use the PostgreSQL database that we created earlier in this section. To do so, we'll create an application.properties file using by running the following command: cat < <EOF > ./src/main/resources/application.properties # Database configurations %prod.quarkus.datasource.db-kind=postgresql %prod.quarkus.datasource.jdbc.url=jdbc:postgresql://${AZ_USER}-minesweeper-database.postgres.database.azure.com:5432/score %prod.quarkus.datasource.jdbc.driver=org.postgresql.Driver %prod.quarkus.datasource.username=myAdmin %prod.quarkus.datasource.password=${OCP_PASS} %prod.quarkus.hibernate-orm.database.generation=drop-and-create %prod.quarkus.hibernate-orm.database.generation=update # OpenShift configurations %prod.quarkus.kubernetes-client.trust-certs=true %prod.quarkus.kubernetes.deploy=true %prod.quarkus.kubernetes.deployment-target=openshift %prod.quarkus.openshift.build-strategy=docker %prod.quarkus.openshift.expose=true %prod.quarkus.openshift.deployment-kind=Deployment %prod.quarkus.container-image.group=microsweeper-ex EOF Now that we've provided the proper configuration, we will build our application. We'll do this using source-to-image , a tool built-in to OpenShift. To start the build and deploy, run the following command: quarkus build --no-tests","title":"Build and deploy the Microsweeper app"},{"location":"app/deploy/#review","text":"Let's take a look at what this command did, along with everything that was created in your cluster. Return to your tab with the OpenShift Web Console. If you need to reauthenticate, follow the steps in the Access Your Cluster section.","title":"Review"},{"location":"app/deploy/#container-images","text":"From the Administrator perspective, expand Builds and then ImageStreams , and select the microsweeper-ex project. . You will see two images that were created on your behalf when you ran the quarkus build command. There is one image for openjdk-11 that comes with OpenShift as a Universal Base Image (UBI) that the application will run under. With UBI, you get highly optimized and secure container images that you can build your applications with. For more information on UBI please read this article . The second image you see is the the microsweeper-appservice image. This is the image for the application that was built automatically for you and pushed to the built-in container registry inside of OpenShift.","title":"Container Images"},{"location":"app/deploy/#image-build","text":"How did those images get built you ask? Back on the OpenShift Web Console, click on BuildConfigs and then the microsweeper-appservice entry. When you ran the quarkus build command, this created the BuildConfig you can see here. In our quarkus settings, we set the deployment strategy to build the image using Docker. The Dockerfile file from the git repo that we cloned was used for this BuildConfig. Info A build configuration describes a single build definition and a set of triggers for when a new build is created. Build configurations are defined by a BuildConfig, which is a REST object that can be used in a POST to the API server to create a new instance. You can read more about BuildConfigs here Once the BuildConfig was created, the source-to-image process kicked off a Build of that BuildConfig. The build is what actually does the work in building and deploying the image. We started with defining what to be built with the BuildConfig and then actually did the work with the Build. You can read more about Builds here To look at what the build actually did, click on Builds tab and then into the first Build in the list. On the next screen, explore around. Look specifically at the YAML definition of the build and the logs to see what the build actually did. If you build failed for some reason, the logs are a great first place to start to look at to debug what happened.","title":"Image Build"},{"location":"app/deploy/#image-deployment","text":"After the image was built, the source-to-image process then deployed the application for us. In the quarkus properties file, we specified that a deployment should be created. You can view the deployment under Workloads -> Deployments , and then click on the Deployment name. Explore around the deployment screen, check out the different tabs, look at the YAML that was created. Look at the pod the deployment created, and see that it is running. The last thing we will look at is the route that was created for our application. In the quarkus properties file, we specified that the application should be exposed to the Internet. When you create a Route, you have the option to specify a hostname. To start with, we will just use the default domain that comes with ARO ( useast.aroapp.io in our case). In next section, we will expose the same application to a custom domain leveraging Azure Front Door. You can read more about routes in the Red Hat documentation From the OpenShift Web Console menu, click on Networking -> Routes , and the microsweeper-appservice route.","title":"Image Deployment"},{"location":"app/deploy/#test-the-application","text":"While in the route section of the OpenShift Web Console, click the URL under Location : You can also get the the URL for your application using the command line: oc -n microsweeper-ex get route microsweeper-appservice -o jsonpath = '{.spec.host}'","title":"Test the application"},{"location":"app/deploy/#application-ip","text":"Let's take a quick look at what IP the application resolves to. Back in your Cloud Shell environment, run the following command: nslookup $( oc -n microsweeper-ex get route microsweeper-appservice -o jsonpath = '{.spec.host}' ) The output of the command will look similar to this: Server: 168 .63.129.16 Address: 168 .63.129.16#53 Non-authoritative answer: Name: microsweeper-appservice-microsweeper-ex.apps.ce7l3kf6.eastus.aroapp.io Address: 40 .117.143.193 Notice the IP address; can you guess where it comes from? It comes from the ARO Load Balancer. In this workshop, we are using a public cluster which means the load balancer is exposed to the Internet. If this was a private cluster, you would have to have connectivity to the vNet ARO is running on. This could be via a VPN connection, Azure ExpressRoute, or something else. To view the ARO load balancer, on the Azure Portal, search for \"Load Balancers\" in the search bar and click on the Load balancers service. You will notice two load balancers, one that has -internal in the name and one that does not. The -internal load balancer is used for the OpenShift API. The other load balancer (without the -internal suffix) in the name is use the public load balancer used for the default Ingress Controller. Click into the load balancer for applications. On the next screen, click on Frontend IP configuration. Notice the IP address of the 2nd load balancer on the list. This IP address matches what you found with the nslookup command. For the fun of it, we can also look at what backends this load balancer is connected to. Next, click on the pool that ends in 443. Notice the Backend pool . This is the subnet that contains all the worker nodes. And the best part is all of this came with Azure Red Hat OpenShift out of the box!","title":"Application IP"},{"location":"app/resilience/","text":"In this section of the workshop, we will deploy an application to an ARO cluster, ensure the application is resilient to node failure, and scale the application when under load. Deploy an application # First, let's deploy an application. To do so, run the following set of commands: oc new-project resilience-ex oc -n resilience-ex new-app https://github.com/sohaibazed/frontend-js.git --name frontend-js oc -n resilience-ex expose svc frontend-js oc -n resilience-ex set resources deployment/frontend-js \\ --limits = cpu = 60m,memory = 150Mi \\ --requests = cpu = 50m,memory = 100Mi While the application is being built from source, you can watch the deployment object to see when its finished. watch ~/bin/oc -n resilience-ex get deployment frontend-js Initially, your output will look like: NAME READY UP-TO-DATE AVAILABLE AGE frontend-js 0 /1 0 0 28s Eventually, your application will be ready and your output will look like this: NAME READY UP-TO-DATE AVAILABLE AGE frontend-js 1 /1 0 0 59s Info Watch will refresh the output of a command every second. Hit CTRL and c on your keyboard to exit the watch command when you're ready to move on to the next part of the workshop. We can now use the route to view the application in your web browser. To get the route, run the following command: oc -n resilience-ex get route frontend-js -o jsonpath = '{.spec.host}' Then visit the URL presented in a new tab in your web browser (using HTTP). For example, your output will look something similar to: frontend-js-resilience-ex.apps.ce7l3kf6.eastus.aroapp.io In that case, you'd visit http://frontend-js-resilience-ex.apps.ce7l3kf6.eastus.aroapp.io in your browser. Initially, this application is deployed with only one pod. In the event a worker node goes down or the pod crashes, there will be an outage of the application. To prevent that, let's scale the number of instances of our applications up to three. To do so, run the following command: oc -n resilience-ex scale deployment frontend-js --replicas = 3 Next, check to see that the application has scaled. To do so, run the following command to see the pods. Then check that it has scaled oc -n resilience-ex get pods -l deployment = frontend-js Your output should look similar to this: NAME READY STATUS RESTARTS AGE frontend-js-7cdc846c94-5mrk8 1 /1 Running 0 3m45s frontend-js-7cdc846c94-bj4wq 1 /1 Running 0 3m45s frontend-js-7cdc846c94-gjxv6 1 /1 Running 0 4m39s Pod Disruption Budget # A Pod disruption Budget (PBD) allows you to limit the disruption to your application when its pods need to be rescheduled for upgrades or routine maintenance work on ARO nodes. In essence, it lets developers define the minimum tolerable operational requirements for a deployment so that it remains stable even during a disruption. For example, frontend-js deployed as part of the last step contains three replicas distributed evenly across three nodes. We can tolerate losing two pods but not one, so we create a PDB that requires a minimum of one replica. A PodDisruptionBudget object\u2019s configuration consists of the following key parts: A label selector, which is a label query over a set of pods. An availability level, which specifies the minimum number of pods that must be available simultaneously, either: minAvailable is the number of pods must always be available, even during a disruption. maxUnavailable is the number of pods can be unavailable during a disruption. Danger A maxUnavailable of 0% or 0 or a minAvailable of 100% or equal to the number of replicas can be used but will block nodes from being drained and can result in application instability during maintenance activities. Let's create a Pod Disruption Budget for our frontend-js application. To do so, run the following command: cat <<EOF | oc apply -f - apiVersion: policy/v1 kind: PodDisruptionBudget metadata: name: frontend-js-pdb namespace: resilience-ex spec: minAvailable: 1 selector: matchLabels: deployment: frontend-js EOF After creating the PDB, OpenShift API will ensure at least one pod of frontend-js is running all the time, even when maintenance is going on with the cluster. Next, let's check the status of Pod Disruption Budget. To do so, run the following command: oc -n resilience-ex get poddisruptionbudgets Your output should match this: NAME MIN AVAILABLE MAX UNAVAILABLE ALLOWED DISRUPTIONS AGE frontend-js-pdb 1 N/A 2 7m39s Horizontal Pod Autoscaler (HPA) # As a developer, you can use a horizontal pod autoscaler (HPA) to specify how Azure Red Hat OpenShift clusters should automatically increase or decrease the scale of a replication controller or deployment configuration, based on metrics collected from the pods that belong to that replication controller or deployment configuration. You can create an HPA for any any deployment, replica set, replication controller, or stateful set. In this exercise we will scale the frontend-js application based on CPU utilization: Scale out when average CPU utilization is greater than 50% of CPU limit Maximum pods is 4 Scale down to min replicas if utilization is lower than threshold for 60 sec First, we should create the HorizontalPodAutoscaler. To do so, run the following command: cat <<EOF | oc apply -f - apiVersion: autoscaling/v2 kind: HorizontalPodAutoscaler metadata: name: frontend-js-cpu namespace: resilience-ex spec: scaleTargetRef: apiVersion: apps/v1 kind: Deployment name: frontend-js minReplicas: 2 maxReplicas: 4 metrics: - type: Resource resource: name: cpu target: averageUtilization: 50 type: Utilization behavior: scaleDown: stabilizationWindowSeconds: 60 policies: - type: Percent value: 100 periodSeconds: 15 EOF Next, check the status of the HPA. To do so, run the following command: oc -n resilience-ex get horizontalpodautoscaler/frontend-js-cpu Your output should match the following: NAME REFERENCE TARGETS MINPODS MAXPODS REPLICAS AGE frontend-js-cpu Deployment/frontend-js 0 %/50% 2 4 3 45s Next, let's generate some load against the frontend-js application. To do so, run the following command: FRONTEND_URL=http://$(oc -n resilience-ex get route frontend-js -o jsonpath='{.spec.host}') siege -c 60 $FRONTEND_URL Wait for a minute and then kill the siege command (by hitting CTRL and c on your keyboard). Then immediately check the status of Horizontal Pod Autoscaler. To do so, run the following command: oc -n resilience-ex get horizontalpodautoscaler/frontend-js-cpu Your output should look similar to this: NAME REFERENCE TARGETS MINPODS MAXPODS REPLICAS AGE frontend-js-cpu Deployment/frontend-js 113%/50% 2 4 4 3m13s This means you are now running 4 replicas, instead of the original three that we started with. Once you've killed the seige command, the traffic going to frontend-js service will cool down and after a 60 second cool down period, your application's replica count will drop back down to two. To demonstrate this, run the following command: oc -n resilience-ex get horizontalpodautoscaler/frontend-js-cpu After a minute or two, your output should be similar to this: NAME REFERENCE TARGETS MINPODS MAXPODS REPLICAS AGE frontend-js-cpu Deployment/frontend-js 0 %/50% 2 4 2 7m26s","title":"Resilience"},{"location":"app/resilience/#deploy-an-application","text":"First, let's deploy an application. To do so, run the following set of commands: oc new-project resilience-ex oc -n resilience-ex new-app https://github.com/sohaibazed/frontend-js.git --name frontend-js oc -n resilience-ex expose svc frontend-js oc -n resilience-ex set resources deployment/frontend-js \\ --limits = cpu = 60m,memory = 150Mi \\ --requests = cpu = 50m,memory = 100Mi While the application is being built from source, you can watch the deployment object to see when its finished. watch ~/bin/oc -n resilience-ex get deployment frontend-js Initially, your output will look like: NAME READY UP-TO-DATE AVAILABLE AGE frontend-js 0 /1 0 0 28s Eventually, your application will be ready and your output will look like this: NAME READY UP-TO-DATE AVAILABLE AGE frontend-js 1 /1 0 0 59s Info Watch will refresh the output of a command every second. Hit CTRL and c on your keyboard to exit the watch command when you're ready to move on to the next part of the workshop. We can now use the route to view the application in your web browser. To get the route, run the following command: oc -n resilience-ex get route frontend-js -o jsonpath = '{.spec.host}' Then visit the URL presented in a new tab in your web browser (using HTTP). For example, your output will look something similar to: frontend-js-resilience-ex.apps.ce7l3kf6.eastus.aroapp.io In that case, you'd visit http://frontend-js-resilience-ex.apps.ce7l3kf6.eastus.aroapp.io in your browser. Initially, this application is deployed with only one pod. In the event a worker node goes down or the pod crashes, there will be an outage of the application. To prevent that, let's scale the number of instances of our applications up to three. To do so, run the following command: oc -n resilience-ex scale deployment frontend-js --replicas = 3 Next, check to see that the application has scaled. To do so, run the following command to see the pods. Then check that it has scaled oc -n resilience-ex get pods -l deployment = frontend-js Your output should look similar to this: NAME READY STATUS RESTARTS AGE frontend-js-7cdc846c94-5mrk8 1 /1 Running 0 3m45s frontend-js-7cdc846c94-bj4wq 1 /1 Running 0 3m45s frontend-js-7cdc846c94-gjxv6 1 /1 Running 0 4m39s","title":"Deploy an application"},{"location":"app/resilience/#pod-disruption-budget","text":"A Pod disruption Budget (PBD) allows you to limit the disruption to your application when its pods need to be rescheduled for upgrades or routine maintenance work on ARO nodes. In essence, it lets developers define the minimum tolerable operational requirements for a deployment so that it remains stable even during a disruption. For example, frontend-js deployed as part of the last step contains three replicas distributed evenly across three nodes. We can tolerate losing two pods but not one, so we create a PDB that requires a minimum of one replica. A PodDisruptionBudget object\u2019s configuration consists of the following key parts: A label selector, which is a label query over a set of pods. An availability level, which specifies the minimum number of pods that must be available simultaneously, either: minAvailable is the number of pods must always be available, even during a disruption. maxUnavailable is the number of pods can be unavailable during a disruption. Danger A maxUnavailable of 0% or 0 or a minAvailable of 100% or equal to the number of replicas can be used but will block nodes from being drained and can result in application instability during maintenance activities. Let's create a Pod Disruption Budget for our frontend-js application. To do so, run the following command: cat <<EOF | oc apply -f - apiVersion: policy/v1 kind: PodDisruptionBudget metadata: name: frontend-js-pdb namespace: resilience-ex spec: minAvailable: 1 selector: matchLabels: deployment: frontend-js EOF After creating the PDB, OpenShift API will ensure at least one pod of frontend-js is running all the time, even when maintenance is going on with the cluster. Next, let's check the status of Pod Disruption Budget. To do so, run the following command: oc -n resilience-ex get poddisruptionbudgets Your output should match this: NAME MIN AVAILABLE MAX UNAVAILABLE ALLOWED DISRUPTIONS AGE frontend-js-pdb 1 N/A 2 7m39s","title":"Pod Disruption Budget"},{"location":"app/resilience/#horizontal-pod-autoscaler-hpa","text":"As a developer, you can use a horizontal pod autoscaler (HPA) to specify how Azure Red Hat OpenShift clusters should automatically increase or decrease the scale of a replication controller or deployment configuration, based on metrics collected from the pods that belong to that replication controller or deployment configuration. You can create an HPA for any any deployment, replica set, replication controller, or stateful set. In this exercise we will scale the frontend-js application based on CPU utilization: Scale out when average CPU utilization is greater than 50% of CPU limit Maximum pods is 4 Scale down to min replicas if utilization is lower than threshold for 60 sec First, we should create the HorizontalPodAutoscaler. To do so, run the following command: cat <<EOF | oc apply -f - apiVersion: autoscaling/v2 kind: HorizontalPodAutoscaler metadata: name: frontend-js-cpu namespace: resilience-ex spec: scaleTargetRef: apiVersion: apps/v1 kind: Deployment name: frontend-js minReplicas: 2 maxReplicas: 4 metrics: - type: Resource resource: name: cpu target: averageUtilization: 50 type: Utilization behavior: scaleDown: stabilizationWindowSeconds: 60 policies: - type: Percent value: 100 periodSeconds: 15 EOF Next, check the status of the HPA. To do so, run the following command: oc -n resilience-ex get horizontalpodautoscaler/frontend-js-cpu Your output should match the following: NAME REFERENCE TARGETS MINPODS MAXPODS REPLICAS AGE frontend-js-cpu Deployment/frontend-js 0 %/50% 2 4 3 45s Next, let's generate some load against the frontend-js application. To do so, run the following command: FRONTEND_URL=http://$(oc -n resilience-ex get route frontend-js -o jsonpath='{.spec.host}') siege -c 60 $FRONTEND_URL Wait for a minute and then kill the siege command (by hitting CTRL and c on your keyboard). Then immediately check the status of Horizontal Pod Autoscaler. To do so, run the following command: oc -n resilience-ex get horizontalpodautoscaler/frontend-js-cpu Your output should look similar to this: NAME REFERENCE TARGETS MINPODS MAXPODS REPLICAS AGE frontend-js-cpu Deployment/frontend-js 113%/50% 2 4 4 3m13s This means you are now running 4 replicas, instead of the original three that we started with. Once you've killed the seige command, the traffic going to frontend-js service will cool down and after a 60 second cool down period, your application's replica count will drop back down to two. To demonstrate this, run the following command: oc -n resilience-ex get horizontalpodautoscaler/frontend-js-cpu After a minute or two, your output should be similar to this: NAME REFERENCE TARGETS MINPODS MAXPODS REPLICAS AGE frontend-js-cpu Deployment/frontend-js 0 %/50% 2 4 2 7m26s","title":"Horizontal Pod Autoscaler (HPA)"},{"location":"general/1-workshop-setup/","text":"Access Azure Portal and CLI # Access the Azure Portal through https://portal.azure.com Azure Credentials # Azure credentials will be provided to you by the organizing staff on the day of the event. Access CloudShell and Attach Persistent Storage # Azure Cloud Shell is an interactive, authenticated, browser-accessible shell for managing Azure resources. To start Cloud Shell, launch it from the top navigation of the Azure Portal. Select the option to use Bash. When selecting a Cloud Shell region you must select a backing storage account co-located in the same region. When the storage setup prompt appears, `Create storage'. When your shell is ready and you are at the bash prompt, run the following commands: wget https://rh-mobb.github.io/aro-hackathon-content/assets/cloudshell-setup.sh chmod +x cloudshell-setup.sh ./cloudshell-setup.sh","title":"Azure portal and CLI setup"},{"location":"general/1-workshop-setup/#access-azure-portal-and-cli","text":"Access the Azure Portal through https://portal.azure.com","title":"Access Azure Portal and CLI"},{"location":"general/1-workshop-setup/#azure-credentials","text":"Azure credentials will be provided to you by the organizing staff on the day of the event.","title":"Azure Credentials"},{"location":"general/1-workshop-setup/#access-cloudshell-and-attach-persistent-storage","text":"Azure Cloud Shell is an interactive, authenticated, browser-accessible shell for managing Azure resources. To start Cloud Shell, launch it from the top navigation of the Azure Portal. Select the option to use Bash. When selecting a Cloud Shell region you must select a backing storage account co-located in the same region. When the storage setup prompt appears, `Create storage'. When your shell is ready and you are at the bash prompt, run the following commands: wget https://rh-mobb.github.io/aro-hackathon-content/assets/cloudshell-setup.sh chmod +x cloudshell-setup.sh ./cloudshell-setup.sh","title":"Access CloudShell and Attach Persistent Storage"},{"location":"ops/1-1-create-cluster/","text":"Create an ARO Cluster # During this workshop, you will be working on a cluster that you will create yourself in this step. This cluster will be dedicated to you. Each person has been assigned a workshop user id, if you need a user id please see a facilitator. The first step we need to do is assign an environment variable to this user id. All the Azure resources that you will be creating will be placed in a resource group that matches this user id. The user id will be in the following format: user-x. For example user-1. While in the Azure Cloud Shell that you should still have open from the workshop-setup section, run the following command: echo 'export USERID=<user id you were given>' >> ~/.bashrc && source ~/.bashrc for example if you were given user-8 as your user id you would enter: echo 'export USERID=user-8' >> ~/.bashrc && source ~/.bashrc * Note: we are adding the environment variable to .bashrc as the cloud shell times out every 20 minutes. Adding it to .bashrc preserves the variable throughout the workshop. Get a Red Hat pull secret # The next step is to get a Red Hat pull secret for your ARO cluster. This pull secret will give you permissions to deploy ARO and access to Red Hat's Operator Hub among things. wget https://rh-mobb.github.io/aro-hackathon-content/assets/pull-secrets/pullsecret- ${ USERID } .txt AZR_PULL_SECRET = pullsecret- ${ USERID } .txt Networking # Before we can create an ARO cluster, we need to setup the Virtual Network that the cluster will used. Create a virtual network with two empty subnets Create virtual network az network vnet create \\ --address-prefixes 10 .0.0.0/22 \\ --name \" $USERID -aro-vnet-eastus\" \\ --resource-group $USERID Create control plane subnet az network vnet subnet create \\ --resource-group $USERID \\ --vnet-name \" $USERID -aro-vnet-eastus\" \\ --name \" $USERID -aro-control-subnet-eastus\" \\ --address-prefixes 10 .0.0.0/23 \\ --service-endpoints Microsoft.ContainerRegistry Create machine subnet az network vnet subnet create \\ --resource-group $USERID \\ --vnet-name \" $USERID -aro-vnet-eastus\" \\ --name \" $USERID -aro-machine-subnet-eastus\" \\ --address-prefixes 10 .0.2.0/23 \\ --service-endpoints Microsoft.ContainerRegistry Disable network policies on the control plane subnet This is required for the service to be able to connect to and manage the cluster. az network vnet subnet update \\ --name \" $USERID -aro-control-subnet-eastus\" \\ --resource-group $USERID \\ --vnet-name \" $USERID -aro-vnet-eastus\" \\ --disable-private-link-service-network-policies true Disable network policies on the machine subnet This is required to create a private link service that we will use to connect front door later in the workshop. az network vnet subnet update \\ --name \" $USERID -aro-machine-subnet-eastus\" \\ --resource-group $USERID \\ --vnet-name \" $USERID -aro-vnet-eastus\" \\ --disable-private-link-service-network-policies true Create the cluster This will take between 30 and 45 minutes. az aro create \\ --resource-group $USERID \\ --name $USERID \\ --vnet \" $USERID -aro-vnet-eastus\" \\ --master-subnet \" $USERID -aro-control-subnet-eastus\" \\ --worker-subnet \" $USERID -aro-machine-subnet-eastus\" \\ --pull-secret @ $AZR_PULL_SECRET While the cluster is being created, let's learn more about what you will be doing in this workshop.","title":"Create an ARO Cluster"},{"location":"ops/1-1-create-cluster/#create-an-aro-cluster","text":"During this workshop, you will be working on a cluster that you will create yourself in this step. This cluster will be dedicated to you. Each person has been assigned a workshop user id, if you need a user id please see a facilitator. The first step we need to do is assign an environment variable to this user id. All the Azure resources that you will be creating will be placed in a resource group that matches this user id. The user id will be in the following format: user-x. For example user-1. While in the Azure Cloud Shell that you should still have open from the workshop-setup section, run the following command: echo 'export USERID=<user id you were given>' >> ~/.bashrc && source ~/.bashrc for example if you were given user-8 as your user id you would enter: echo 'export USERID=user-8' >> ~/.bashrc && source ~/.bashrc * Note: we are adding the environment variable to .bashrc as the cloud shell times out every 20 minutes. Adding it to .bashrc preserves the variable throughout the workshop.","title":"Create an ARO Cluster"},{"location":"ops/1-1-create-cluster/#get-a-red-hat-pull-secret","text":"The next step is to get a Red Hat pull secret for your ARO cluster. This pull secret will give you permissions to deploy ARO and access to Red Hat's Operator Hub among things. wget https://rh-mobb.github.io/aro-hackathon-content/assets/pull-secrets/pullsecret- ${ USERID } .txt AZR_PULL_SECRET = pullsecret- ${ USERID } .txt","title":"Get a Red Hat pull secret"},{"location":"ops/1-1-create-cluster/#networking","text":"Before we can create an ARO cluster, we need to setup the Virtual Network that the cluster will used. Create a virtual network with two empty subnets Create virtual network az network vnet create \\ --address-prefixes 10 .0.0.0/22 \\ --name \" $USERID -aro-vnet-eastus\" \\ --resource-group $USERID Create control plane subnet az network vnet subnet create \\ --resource-group $USERID \\ --vnet-name \" $USERID -aro-vnet-eastus\" \\ --name \" $USERID -aro-control-subnet-eastus\" \\ --address-prefixes 10 .0.0.0/23 \\ --service-endpoints Microsoft.ContainerRegistry Create machine subnet az network vnet subnet create \\ --resource-group $USERID \\ --vnet-name \" $USERID -aro-vnet-eastus\" \\ --name \" $USERID -aro-machine-subnet-eastus\" \\ --address-prefixes 10 .0.2.0/23 \\ --service-endpoints Microsoft.ContainerRegistry Disable network policies on the control plane subnet This is required for the service to be able to connect to and manage the cluster. az network vnet subnet update \\ --name \" $USERID -aro-control-subnet-eastus\" \\ --resource-group $USERID \\ --vnet-name \" $USERID -aro-vnet-eastus\" \\ --disable-private-link-service-network-policies true Disable network policies on the machine subnet This is required to create a private link service that we will use to connect front door later in the workshop. az network vnet subnet update \\ --name \" $USERID -aro-machine-subnet-eastus\" \\ --resource-group $USERID \\ --vnet-name \" $USERID -aro-vnet-eastus\" \\ --disable-private-link-service-network-policies true Create the cluster This will take between 30 and 45 minutes. az aro create \\ --resource-group $USERID \\ --name $USERID \\ --vnet \" $USERID -aro-vnet-eastus\" \\ --master-subnet \" $USERID -aro-control-subnet-eastus\" \\ --worker-subnet \" $USERID -aro-machine-subnet-eastus\" \\ --pull-secret @ $AZR_PULL_SECRET While the cluster is being created, let's learn more about what you will be doing in this workshop.","title":"Networking"},{"location":"ops/1-3-get-credentials/","text":"Access the OpenShift Console and CLI # To access the OpenShift oc CLI and web console you will need to retrieve your cluster credentials. Use the cluster name and Resource Group name that were provided to you. To retrieve the credentials run: az aro list-credentials --name $USERID --resource-group $USERID To retrieve the console URL run: az aro show --name $USERID --resource-group $USERID -o tsv --query consoleProfile Login to the console with the kubeadmin user through a browser. OpenShift CLI Login # Retrieve the API server's address. apiServer = $( az aro show -g $USERID -n $USERID --query apiserverProfile.url -o tsv ) Login to the OpenShift cluster's API server using the following command. Replace with the password you just retrieved. oc login $apiServer -u kubeadmin -p <kubeadmin password>","title":"Retieve ARO Cluster Credentials"},{"location":"ops/1-3-get-credentials/#access-the-openshift-console-and-cli","text":"To access the OpenShift oc CLI and web console you will need to retrieve your cluster credentials. Use the cluster name and Resource Group name that were provided to you. To retrieve the credentials run: az aro list-credentials --name $USERID --resource-group $USERID To retrieve the console URL run: az aro show --name $USERID --resource-group $USERID -o tsv --query consoleProfile Login to the console with the kubeadmin user through a browser.","title":"Access the OpenShift Console and CLI"},{"location":"ops/1-3-get-credentials/#openshift-cli-login","text":"Retrieve the API server's address. apiServer = $( az aro show -g $USERID -n $USERID --query apiserverProfile.url -o tsv ) Login to the OpenShift cluster's API server using the following command. Replace with the password you just retrieved. oc login $apiServer -u kubeadmin -p <kubeadmin password>","title":"OpenShift CLI Login"},{"location":"ops/2-1-pipeline-operator/","text":"Install the Red Hat OpenShift Pipeline Operator # Log in to the OpenShift Container Platform web console as a kubeadmin user you retrieved in the Retieve Cluster Credentials Step . In the OpenShift Container Platform web console, from the administrator view click Operators \u2192 OperatorHub. Type the Pipelines into the filter box and search. Click on the Red Hat OpenShift Pipelines Operator to install it. Click Install . On the Install Operator page for the Red Hat OpenShift Pipelines Operator, accept the default settings. The operators takes about a minute to install and will when successful, you will see this screen.","title":"2 1 pipeline operator"},{"location":"ops/2-1-pipeline-operator/#install-the-red-hat-openshift-pipeline-operator","text":"Log in to the OpenShift Container Platform web console as a kubeadmin user you retrieved in the Retieve Cluster Credentials Step . In the OpenShift Container Platform web console, from the administrator view click Operators \u2192 OperatorHub. Type the Pipelines into the filter box and search. Click on the Red Hat OpenShift Pipelines Operator to install it. Click Install . On the Install Operator page for the Red Hat OpenShift Pipelines Operator, accept the default settings. The operators takes about a minute to install and will when successful, you will see this screen.","title":"Install the Red Hat OpenShift Pipeline Operator"},{"location":"ops/2-4-label-nodes/","text":"Introduction # To add a node label it is recommended to set the label in the machine set. While you can directly add a label the node, this is not recommended since nodes could be overwritten and then the label would disappear. Once the machine set is modified to contain the desired label any new machines created from that set would have the newly added labels. This means that existing machines (nodes) will not get the label. Therefore, to make sure all nodes have the label, you should scale the machine set down to zero and then scale the machine set back up. Labels are a useful way to select which nodes / machine sets that an application will run on. If you have a memory intensitve application, you may choose to use a memory heavy node type to place that application on. By using labels on the machinesets and selectors on your pod / deployment specification, you ensure thats where the application lands. oc get pods Use the Web Console to Label Nodes # Select \"MachineSets\" from the left menu. You will see the list of machinesets. We'll select the first one \"ok0620-rq5tl-worker-westus21\" Click on the second tab \"YAML\" Click into the YAML and under spec.template.metadata.labels add a key:value pair for the label you want. In our example we can add a label \"tier: frontend\". Click Save. The already existing machine won't get this label but any new machines will. So to ensure that all machines get the label, we will scale down this machine set to zero. Click the three dots next to the first node that we add the label to, and select Edit Machine Count. Set the machine count to 0. Repeat the same steps, but this time set the machine count to 1. Click on the machine that was just created. You can see that the label is now there. Later on, when we deploy our application, this frontend will be deployed to this node.","title":"Label Nodes"},{"location":"ops/2-4-label-nodes/#introduction","text":"To add a node label it is recommended to set the label in the machine set. While you can directly add a label the node, this is not recommended since nodes could be overwritten and then the label would disappear. Once the machine set is modified to contain the desired label any new machines created from that set would have the newly added labels. This means that existing machines (nodes) will not get the label. Therefore, to make sure all nodes have the label, you should scale the machine set down to zero and then scale the machine set back up. Labels are a useful way to select which nodes / machine sets that an application will run on. If you have a memory intensitve application, you may choose to use a memory heavy node type to place that application on. By using labels on the machinesets and selectors on your pod / deployment specification, you ensure thats where the application lands. oc get pods","title":"Introduction"},{"location":"ops/2-4-label-nodes/#use-the-web-console-to-label-nodes","text":"Select \"MachineSets\" from the left menu. You will see the list of machinesets. We'll select the first one \"ok0620-rq5tl-worker-westus21\" Click on the second tab \"YAML\" Click into the YAML and under spec.template.metadata.labels add a key:value pair for the label you want. In our example we can add a label \"tier: frontend\". Click Save. The already existing machine won't get this label but any new machines will. So to ensure that all machines get the label, we will scale down this machine set to zero. Click the three dots next to the first node that we add the label to, and select Edit Machine Count. Set the machine count to 0. Repeat the same steps, but this time set the machine count to 1. Click on the machine that was just created. You can see that the label is now there. Later on, when we deploy our application, this frontend will be deployed to this node.","title":"Use the Web Console to Label Nodes"},{"location":"ops/2-5-deploy-cosmos/","text":"Introduction # The appliction we will be deploying utilizes Azure Cosmos DB for the database. The following instructions install the database. COSMOSDB_NAME = $USERID -cosmos az cosmosdb create \\ --name $COSMOSDB_NAME \\ --resource-group $USERID \\ --kind MongoDB \\ --server-version '4.0' \\ --enable-public-network true \\ --default-consistency-level Eventual It can take around 5 minutes of the database to create. The expected output should look like the following where you will see a message stating provisioning succeeded. The last step to create an instance of the cosmos database to use: # az cosmosdb mongodb database create \\ --account-name $COSMOSDB_NAME \\ --resource-group $USERID \\ --name ratingsdb Expected output:","title":"Deploy Cosmos Database"},{"location":"ops/2-5-deploy-cosmos/#introduction","text":"The appliction we will be deploying utilizes Azure Cosmos DB for the database. The following instructions install the database. COSMOSDB_NAME = $USERID -cosmos az cosmosdb create \\ --name $COSMOSDB_NAME \\ --resource-group $USERID \\ --kind MongoDB \\ --server-version '4.0' \\ --enable-public-network true \\ --default-consistency-level Eventual It can take around 5 minutes of the database to create. The expected output should look like the following where you will see a message stating provisioning succeeded.","title":"Introduction"},{"location":"ops/2-5-deploy-cosmos/#the-last-step-to-create-an-instance-of-the-cosmos-database-to-use","text":"az cosmosdb mongodb database create \\ --account-name $COSMOSDB_NAME \\ --resource-group $USERID \\ --name ratingsdb Expected output:","title":"The last step to create an instance of the cosmos database to use:"},{"location":"ops/3-deploy-azure-service-operator/","text":"Deploy Azure Service Operator # Azure Service Operator(ASO) is an open-source project by Microsoft Azure. ASO gives you the ability to provision and manages Azure resources such as compute, databases, resoure group, vnet, subnet,... within the Kubernetes plane by using familiar Kubernetes tooling and primitives. ASO consists of: 1. Custom Resource Definitions (CRDs) for each of the Azure services that a Kubernetes user can provision. 2. A Kubernetes controller that manages the Azure resources represented by the user-specified Custom Resources. The controller attempts to synchronize the desired state in the user-specified Custom Resource with the actual state of that resource in Azure, creating it if it doesn't exist, updating it if it has been changed, or deleting it. We deploy ASO on an ARO cluster to provision and manage Azure resources. In the next part we use ASO to provision a Cosmos database. To install ASO we need: A SP(service principal) with right permission. A certificate: We use cert-manager to issue certificate Install and run ASO on your ARO cluster # Create an Azure Service Principal to grant ASO permissions to create resources in your subscription An Azure service principal is an identity created for use with applications, hosted services, and automated tools to access Azure resources. bash AZURE_TENANT_ID=\"$(az account show -o tsv --query tenantId)\" echo \"Azure Tenant ID $AZURE_TENANT_ID\" AZURE_SUBSCRIPTION_ID=\"$(az account show -o tsv --query id)\" echo \"Azure subscription ID $AZURE_SUBSCRIPTION_ID\" AZURE_SP=\"$(az ad sp create-for-rbac -n wksp-sp-$RANDOM --role contributor --scopes /subscriptions/$AZURE_SUBSCRIPTION_ID -o json )\" echo \" Azure SP ID/SECRET $AZURE_SP\" AZURE_CLIENT_ID=\"$(echo $AZURE_SP | jq -r '.appId')\" echo \"SP ID $AZURE_CLIENT_ID\" AZURE_CLIENT_SECRET=\"$(echo $AZURE_SP | jq -r '.password')\" echo \"SP SECRET $AZURE_CLIENT_SECRET\" Create a secret for ASO cat <<EOF | oc apply -f - apiVersion: v1 kind: Secret metadata: name: azureoperatorsettings namespace: openshift-operators stringData: AZURE_TENANT_ID: $AZURE_TENANT_ID AZURE_SUBSCRIPTION_ID: $AZURE_SUBSCRIPTION_ID AZURE_CLIENT_ID: $AZURE_CLIENT_ID AZURE_CLIENT_SECRET: $AZURE_CLIENT_SECRET EOF Install cert-manager operator Create Namespace for cert-manager-operator cat <<EOF | oc apply -f - kind: Namespace apiVersion: v1 metadata: name: openshift-cert-manager-operator EOF Create operator group cat <<EOF | oc apply -f - apiVersion: operators.coreos.com/v1 kind: OperatorGroup metadata: name: openshift-cert-manager-operator-group namespace: openshift-cert-manager-operator spec: {} EOF Create subscription cat <<EOF | oc apply -f - apiVersion: operators.coreos.com/v1alpha1 kind: Subscription metadata: name: openshift-cert-manager-operator namespace: openshift-cert-manager-operator spec: channel: tech-preview installPlanApproval: Automatic name: openshift-cert-manager-operator source: redhat-operators sourceNamespace: openshift-marketplace startingCSV: openshift-cert-manager.v1.7.1 EOF Wait for cert-manager operator to be up and running Note: this can take a few minutes while [[ $( oc get pods -l app = cert-manager -n openshift-cert-manager -o 'jsonpath={..status.conditions[?(@.type==\"Ready\")].status}' ) ! = \"True\" ]] ; do echo \"waiting for cert-manager pod\" && sleep 10 ; done deploy ASO v2 on the ARO * cluster * helm repo add aso2 https://raw.githubusercontent.com/Azure/azure-service-operator/main/v2/charts helm upgrade --install --devel aso2 aso2/azure-service-operator \\ --create-namespace \\ --namespace = azureserviceoperator-system \\ --set azureSubscriptionID = $AZURE_SUBSCRIPTION_ID \\ --set azureTenantID = $AZURE_TENANT_ID \\ --set azureClientID = $AZURE_CLIENT_ID \\ --set azureClientSecret = $AZURE_CLIENT_SECRET Note: It takes up to 5 min for ASO operator to be up and running. There are pods in the azureserviceoperator-system namespace with two containers, run the following command to check the logs will likely show a string of \u2018TLS handshake error\u2019 messages as the operator waits for a Certificate to be issued, but when they stop, the operator will be ready. Watch the timestamps for the logs, when the logs stop scrolling you are ready. Grab another coffee, mingle a little bit and come back and check if the certificate has been issued. Check ASO operator ASOPODNAME = $( oc get po -n azureserviceoperator-system -o json | jq -r .items [ 0 ] .metadata.name ) oc logs $ASOPODNAME -n azureserviceoperator-system --timestamps -f","title":"Azure Service Operator"},{"location":"ops/3-deploy-azure-service-operator/#deploy-azure-service-operator","text":"Azure Service Operator(ASO) is an open-source project by Microsoft Azure. ASO gives you the ability to provision and manages Azure resources such as compute, databases, resoure group, vnet, subnet,... within the Kubernetes plane by using familiar Kubernetes tooling and primitives. ASO consists of: 1. Custom Resource Definitions (CRDs) for each of the Azure services that a Kubernetes user can provision. 2. A Kubernetes controller that manages the Azure resources represented by the user-specified Custom Resources. The controller attempts to synchronize the desired state in the user-specified Custom Resource with the actual state of that resource in Azure, creating it if it doesn't exist, updating it if it has been changed, or deleting it. We deploy ASO on an ARO cluster to provision and manage Azure resources. In the next part we use ASO to provision a Cosmos database. To install ASO we need: A SP(service principal) with right permission. A certificate: We use cert-manager to issue certificate","title":"Deploy Azure Service Operator"},{"location":"ops/3-deploy-azure-service-operator/#install-and-run-aso-on-your-aro-cluster","text":"Create an Azure Service Principal to grant ASO permissions to create resources in your subscription An Azure service principal is an identity created for use with applications, hosted services, and automated tools to access Azure resources. bash AZURE_TENANT_ID=\"$(az account show -o tsv --query tenantId)\" echo \"Azure Tenant ID $AZURE_TENANT_ID\" AZURE_SUBSCRIPTION_ID=\"$(az account show -o tsv --query id)\" echo \"Azure subscription ID $AZURE_SUBSCRIPTION_ID\" AZURE_SP=\"$(az ad sp create-for-rbac -n wksp-sp-$RANDOM --role contributor --scopes /subscriptions/$AZURE_SUBSCRIPTION_ID -o json )\" echo \" Azure SP ID/SECRET $AZURE_SP\" AZURE_CLIENT_ID=\"$(echo $AZURE_SP | jq -r '.appId')\" echo \"SP ID $AZURE_CLIENT_ID\" AZURE_CLIENT_SECRET=\"$(echo $AZURE_SP | jq -r '.password')\" echo \"SP SECRET $AZURE_CLIENT_SECRET\" Create a secret for ASO cat <<EOF | oc apply -f - apiVersion: v1 kind: Secret metadata: name: azureoperatorsettings namespace: openshift-operators stringData: AZURE_TENANT_ID: $AZURE_TENANT_ID AZURE_SUBSCRIPTION_ID: $AZURE_SUBSCRIPTION_ID AZURE_CLIENT_ID: $AZURE_CLIENT_ID AZURE_CLIENT_SECRET: $AZURE_CLIENT_SECRET EOF Install cert-manager operator Create Namespace for cert-manager-operator cat <<EOF | oc apply -f - kind: Namespace apiVersion: v1 metadata: name: openshift-cert-manager-operator EOF Create operator group cat <<EOF | oc apply -f - apiVersion: operators.coreos.com/v1 kind: OperatorGroup metadata: name: openshift-cert-manager-operator-group namespace: openshift-cert-manager-operator spec: {} EOF Create subscription cat <<EOF | oc apply -f - apiVersion: operators.coreos.com/v1alpha1 kind: Subscription metadata: name: openshift-cert-manager-operator namespace: openshift-cert-manager-operator spec: channel: tech-preview installPlanApproval: Automatic name: openshift-cert-manager-operator source: redhat-operators sourceNamespace: openshift-marketplace startingCSV: openshift-cert-manager.v1.7.1 EOF Wait for cert-manager operator to be up and running Note: this can take a few minutes while [[ $( oc get pods -l app = cert-manager -n openshift-cert-manager -o 'jsonpath={..status.conditions[?(@.type==\"Ready\")].status}' ) ! = \"True\" ]] ; do echo \"waiting for cert-manager pod\" && sleep 10 ; done deploy ASO v2 on the ARO * cluster * helm repo add aso2 https://raw.githubusercontent.com/Azure/azure-service-operator/main/v2/charts helm upgrade --install --devel aso2 aso2/azure-service-operator \\ --create-namespace \\ --namespace = azureserviceoperator-system \\ --set azureSubscriptionID = $AZURE_SUBSCRIPTION_ID \\ --set azureTenantID = $AZURE_TENANT_ID \\ --set azureClientID = $AZURE_CLIENT_ID \\ --set azureClientSecret = $AZURE_CLIENT_SECRET Note: It takes up to 5 min for ASO operator to be up and running. There are pods in the azureserviceoperator-system namespace with two containers, run the following command to check the logs will likely show a string of \u2018TLS handshake error\u2019 messages as the operator waits for a Certificate to be issued, but when they stop, the operator will be ready. Watch the timestamps for the logs, when the logs stop scrolling you are ready. Grab another coffee, mingle a little bit and come back and check if the certificate has been issued. Check ASO operator ASOPODNAME = $( oc get po -n azureserviceoperator-system -o json | jq -r .items [ 0 ] .metadata.name ) oc logs $ASOPODNAME -n azureserviceoperator-system --timestamps -f","title":"Install and run ASO on your ARO cluster"},{"location":"ops/4-1-deploy-acr-aso/","text":"Deploy Azure Container Registry through ASO # Azure Service Operator(ASO) is an open-source project by Microsoft Azure. ASO gives you the ability to provision and manages Azure resources such as compute, databases, resoure group, vnet, subnet,... within the Kubernetes plane by using familiar Kubernetes tooling and primitives. ASO consists of: 1. Custom Resource Definitions (CRDs) for each of the Azure services that a Kubernetes user can provision. A Kubernetes controller that manages the Azure resources represented by the user-specified Custom Resources. The controller attempts to synchronize the desired state in the user-specified Custom Resource with the actual state of that resource in Azure, creating it if it doesn't exist, updating it if it has been changed, or deleting it. In this task, we use ASO to provision Azure Container Registry which we will use to store our images. ResourceGroup note this will not actually creat the resource group, it will simply register the Resource Group you are already using with ASO envsubst <<EOF | oc apply -f - apiVersion: resources.azure.com/v1beta20200601 kind: ResourceGroup metadata: name: $USERID namespace: default spec: location: eastus EOF Create an instace of the Azure Container Registry REGISTRY_NAME = $( echo \" $USERID \" registry | tr -d - ) envsubst <<EOF | oc apply -f - apiVersion: containerregistry.azure.com/v1beta20210901 kind: Registry metadata: name: $REGISTRY_NAME namespace: default spec: location: eastus adminUserEnabled: true owner: name: $USERID publicNetworkAccess: Enabled sku: name: Basic zoneRedundancy: Disabled EOF Check that the Azure Portal that Azure Container Registry resource was created From the Azure Portal, search for container registries, and look for the registry you just created. *Note: this can take a few minutes to show up in the Azure portal","title":"4 1 deploy acr aso"},{"location":"ops/4-1-deploy-acr-aso/#deploy-azure-container-registry-through-aso","text":"Azure Service Operator(ASO) is an open-source project by Microsoft Azure. ASO gives you the ability to provision and manages Azure resources such as compute, databases, resoure group, vnet, subnet,... within the Kubernetes plane by using familiar Kubernetes tooling and primitives. ASO consists of: 1. Custom Resource Definitions (CRDs) for each of the Azure services that a Kubernetes user can provision. A Kubernetes controller that manages the Azure resources represented by the user-specified Custom Resources. The controller attempts to synchronize the desired state in the user-specified Custom Resource with the actual state of that resource in Azure, creating it if it doesn't exist, updating it if it has been changed, or deleting it. In this task, we use ASO to provision Azure Container Registry which we will use to store our images. ResourceGroup note this will not actually creat the resource group, it will simply register the Resource Group you are already using with ASO envsubst <<EOF | oc apply -f - apiVersion: resources.azure.com/v1beta20200601 kind: ResourceGroup metadata: name: $USERID namespace: default spec: location: eastus EOF Create an instace of the Azure Container Registry REGISTRY_NAME = $( echo \" $USERID \" registry | tr -d - ) envsubst <<EOF | oc apply -f - apiVersion: containerregistry.azure.com/v1beta20210901 kind: Registry metadata: name: $REGISTRY_NAME namespace: default spec: location: eastus adminUserEnabled: true owner: name: $USERID publicNetworkAccess: Enabled sku: name: Basic zoneRedundancy: Disabled EOF Check that the Azure Portal that Azure Container Registry resource was created From the Azure Portal, search for container registries, and look for the registry you just created. *Note: this can take a few minutes to show up in the Azure portal","title":"Deploy Azure Container Registry through ASO"},{"location":"ops/5-arc-integration/","text":"Integrating Azure ARC with ARO # In this section of the workshop, we will integrate ARO cluster with Azure Arc-enabled Kubernetes. When you connect a Kubernetes/OpenShift cluster with Azure Arc, it will: Be represented in Azure Resource Manager with a unique ID Be place in an Azure subscription and resource group Receive tags just like any otherAzure resource Azure Arc-enabled Kubernetes supports the following scenarios for connected clusters: Connect Kubernetes running outside of Azure for inventory, grouping, and tagging. Deploy applications and apply configuration using GitOps-based configuration management. View and monitor your clusters using Azure Monitor for containers. Enforce threat protection using Microsoft Defender for Kubernetes. Apply policy definitions using Azure Policy for Kubernetes. Use Azure Active Directory for authentication and authorization checks on your cluster Prerequisites # a public ARO cluster azure cli oc cli An identity (user or service principal) which can be used to log in to Azure CLI and connect your cluster to Azure Arc. Enable Extensions and Plugins # Install the connectedk8s Azure Cli extension of version >= 1.2.0 az extension add --name \"connectedk8s\" az extension add --name \"k8s-configuration\" az extension add --name \"k8s-extension\" Register providers for Azure Arc-enabled Kubernetes. Registration may take up to 5 minutes. az provider register --namespace Microsoft.Kubernetes az provider register --namespace Microsoft.KubernetesConfiguration az provider register --namespace Microsoft.ExtendedLocation Connect an existing ARO cluster # Make sure you are logged into your ARO cluster kubeadmin_password = $( az aro list-credentials --name <<cluster name>> --resource-group <<resource group name>> --query kubeadminPassword --output tsv) apiServer=$(az aro show -g <<resource group name>> -n <<cluster name>> --query apiserverProfile.url -o tsv ) oc login $apiServer -u kubeadmin -p $kubeadmin_password Run the following command: az connectedk8s connect --resource-group $resourceGroupName --name $clusterName --distribution openshift --infrastructure auto After running the commnad. grant the following permissions and restart kube-aad-proxy pod oc project azure-arc oc adm policy add-scc-to-user privileged system:serviceaccount:azure-arc:azure-arc-kube-aad-proxy-sa oc get pod | grep kube-aad-proxy-6d9b66b9cd-g27xr 0/2 ContainerCreating 0 26s oc delete pod kube-aad-proxy-6d9b66b9cd-g27xr Wait for a few mins and you will see all the pods in azure-arc namespace running oc get pods NAME READY STATUS RESTARTS AGE cluster-metadata-operator-7dfd94949c-wtvjw 2/2 Running 0 4m47s clusterconnect-agent-7d78db9859-wzthd 3/3 Running 0 4m47s clusteridentityoperator-7b96bcb448-hzthh 2/2 Running 0 4m47s config-agent-dbf66bbc7-r27qs 2/2 Running 0 4m47s controller-manager-67547546f-cmlb9 2/2 Running 0 4m47s extension-manager-548c9d7d6b-jrrdn 2/2 Running 0 4m47s flux-logs-agent-bb994c74f-m5gdc 1/1 Running 0 4m47s kube-aad-proxy-6d9b66b9cd-g27xr 2/2 Running 0 3m16s metrics-agent-7d794679c6-k4b7g 2/2 Running 0 4m47s resource-sync-agent-bb79c44b8-5brjr 2/2 Running 0 4m47s This commands take about 5 mins to complete. Upon the completion of the command you should see the following output and your cluster under Kubernetes - Azure Arc service in Azure Portal { \"agentPublicKeyCertificate\": \"MIICCgKCAgEArNXWSoWVg7q/W5t7vwY24Y8c+dRxy3we/EIRryXx1Orl8GEX94BsHJqvP0iW6ANZ0qoWE675+NR6V3nDMSkis5/aSYMQ8/yWMcUzieKwFfFmTSfCpkzwxy6PSbdRjMwK5H3DDOOXyRQcJV557F5FjHVYfC/0DkPYdhfepcVade+HgOwOOJH28hSNw58pWo/GNNmcwtzFPVdx/TM574CbNVz4OdrtsMy7FKKC63lYW+W3wkzFOqB+qPaITwqwzkruIoSi5HIatONoCPijdTLm3+RoK/CbTYqzHEEId8gFFJd+J4qfSeCYu6jeDNOpwt8DKDLFLvv04oHyxm+Nr34xPBm3+sjggvkLQ5UWpGZ9h7jWTEP2pWEcXF0KqAqAEFPBOOqDKEaYfLtJSJ/yExS1otydDCJEZ1sRPvsjdH5f0DKVXPHgiDa4SoLXomqkarF3g9i6CEK/XE9JTVa8WBJT6wXdXBa0xh8EnzZ9uyVuY1k/2L7d4BR5+sIjqtcDfRSVtxN+LNxgqpo20ltXM1hWkd8WacK7VY+t2lxbYf01zhXWOpaBGgeAMqxqqcHeQor2vzA9PENYYr5zo8eP1LcySmC4LIFiDfN1NxAiZ5SCnrorNFbmrgEDFnWvZzdu2w4r55fsV9qnozUjn6iRqByhyMoeLn5EZLLK5zsW8sA/CeUCAwEAAQ==\", \"agentVersion\": null, \"connectivityStatus\": \"Connecting\", \"distribution\": \"OpenShift\", \"id\": \"/subscriptions/e7f88b1a-04fc-4d00-ace9-eec077a5d6af/resourceGroups/sazed-aro-cluster/providers/Microsoft.Kubernetes/connectedClusters/sazed-aro-cluster\", \"identity\": { \"principalId\": \"xxxx-xxxx-xxxx-xxxx\", \"tenantId\": \"xxxx-xxxx-xxxx-xxxx\", \"type\": \"SystemAssigned\" }, \"infrastructure\": \"azure\", \"kubernetesVersion\": null, \"lastConnectivityTime\": null, \"location\": \"eastus\", \"managedIdentityCertificateExpirationTime\": null, \"name\": \"sazed-aro-cluster\", \"offering\": null, \"provisioningState\": \"Succeeded\", \"resourceGroup\": \"sazed-aro-cluster\", \"systemData\": { \"createdAt\": \"2022-09-15T19:23:40.540376+00:00\", \"createdBy\": \"sazed@redhat.com\", \"createdByType\": \"User\", \"lastModifiedAt\": \"2022-09-15T19:23:40.540376+00:00\", \"lastModifiedBy\": \"sazed@redhat.com\", \"lastModifiedByType\": \"User\" }, \"tags\": {}, \"totalCoreCount\": null, \"totalNodeCount\": null, \"type\": \"microsoft.kubernetes/connectedclusters\" } To check the status of clusters connected to Azure ARC, run the following command az connectedk8s list --resource-group <<resource group>> --output table Name Location ResourceGroup ------------------- ---------- ------------------- << cluster name >>> eastus << resource group >> Enable observability # In order to see ARO resource inside Azure Arc, you need to create a service account and provide it to Azure Arc. oc project azure-arc oc create serviceaccount azure-arc-observability oc create clusterrolebinding azure-arc-observability-rb --clusterrole cluster-admin --serviceaccount azure-arc:azure-arc-observability apiVersion: v1 kind: Secret metadata: name: azure-arc-observability-secret namespace: azure-arc annotations: kubernetes.io/service-account.name: azure-arc-observability type: kubernetes.io/service-account-token oc apply -f aro-content/assets/azure-arc-secret.yaml TOKEN = $( oc get secret azure-arc-observability-secret -o jsonpath = '{$.data.token}' | base64 -d | sed 's/$/\\\\n/g' ) echo $TOKEN Copy the token, goto Azure portal and select your cluster under \"Kubernetes - Azure Arc\" Select Namespaces from the left side menu and paste the token in \"Service account bearer token\" input field. Now you can see all of your ARO rearouses inside ARC UI. you can see the following resources inside Azure ARC portal: - Namespaces - Workloads - Services and Ingress - Storage - Configurations Access Secrets from Azure Key Vault # The Azure Key Vault Provider for Secrets Store CSI Driver allows for the integration of Azure Key Vault as a secrets store with a Kubernetes cluster via a CSI volume. For Azure Arc-enabled Kubernetes clusters, you can install the Azure Key Vault Secrets Provider extension to fetch secrets. Install extension # az k8s-extension create --cluster-name <<cluster name>> --resource-group <<resource group>> --cluster -type connectedClusters --extension-type Microsoft.AzureKeyVaultSecretsProvider --name akvsecretsprovider { \"aksAssignedIdentity\" : null, \"autoUpgradeMinorVersion\" : true, \"configurationProtectedSettings\" : {} , \"configurationSettings\" : {} , \"customLocationSettings\" : null, \"errorInfo\" : null, \"extensionType\" : \"microsoft.azurekeyvaultsecretsprovider\" , \"id\" : \"/subscriptions/e7f88b1a-04fc-4d00-ace9-eec077a5d6af/resourceGroups/sazed-aro-cluster/providers/Microsoft.Kubernetes/connectedClusters/sazed-aro-cluster-1/providers/Microsoft.KubernetesConfiguration/extensions/akvsecretsprovider\" , \"identity\" : { \"principalId\" : \"xxxx-xxxx-xxxx-xxxx\" , \"tenantId\" : null, \"type\" : \"SystemAssigned\" } , \"installedVersion\" : null, \"name\" : \"akvsecretsprovider\" , \"packageUri\" : null, \"provisioningState\" : \"Succeeded\" , \"releaseTrain\" : \"Stable\" , \"resourceGroup\" : \"sazed-aro-cluster\" , \"scope\" : { \"cluster\" : { \"releaseNamespace\" : \"kube-system\" } , \"namespace\" : null } , \"statuses\" : [] , \"systemData\" : { \"createdAt\" : \"2022-09-15T20:45:47.152390+00:00\" , \"createdBy\" : null, \"createdByType\" : null, \"lastModifiedAt\" : \"2022-09-15T20:45:47.152390+00:00\" , \"lastModifiedBy\" : null, \"lastModifiedByType\" : null } , \"type\" : \"Microsoft.KubernetesConfiguration/extensions\" , \"version\" : \"1.3.0\" } Validate the extension installation az k8s-extension show --cluster-type connectedClusters --cluster-name <<cluster name>> --resource-group <<resource group>> --name akvsecretsprovider { \"aksAssignedIdentity\": null, \"autoUpgradeMinorVersion\": true, \"configurationProtectedSettings\": {}, \"configurationSettings\": {}, \"customLocationSettings\": null, \"errorInfo\": null, \"extensionType\": \"microsoft.azurekeyvaultsecretsprovider\", \"id\": \"/subscriptions/e7f88b1a-04fc-4d00-ace9-eec077a5d6af/resourceGroups/sazed-aro-cluster -1/providers/Microsoft.Kubernetes/connectedClusters/sazed-aro-cluster-1/providers/Microsoft.KubernetesConfiguration/extensions/akvsecretsprovider \", \" identity \": { \" principalId \": \" xxxx-xxxx-xxxx-xxxx \", \" tenantId \": null, \" type \": \" SystemAssigned \" }, \" installedVersion \": null, \" name \": \" akvsecretsprovider \", \" packageUri \": null, \" provisioningState \": \" Succeeded \", \" releaseTrain \": \" Stable \", \" resourceGroup \": \" sazed-aro-cluster \", \" scope \": { \" cluster \": { \" releaseNamespace \": \" kube-system \" }, \" namespace \": null }, \" statuses \": [], \" systemData \": { \" createdAt \": \" 2022 -09-15T20:45:47.152390+00:00 \", \" createdBy \": null, \" createdByType \": null, \" lastModifiedAt \": \" 2022 -09-15T20:45:47.152390+00:00 \", \" lastModifiedBy \": null, \" lastModifiedByType \": null }, \" type \": \" Microsoft.KubernetesConfiguration/extensions \", \" version \": \" 1 .3.0 \" } Create or Select an Azure Key Vault # az keyvault create -n <<cluster name>> -g <<resource group>> -l eastus az keyvault secret set --vault-name <<cluster name>> -n DemoSecret --value MyExampleSecret Provide identity to access Azure Key Vault # Currently, the Secrets Store CSI Driver on Arc-enabled clusters can be accessed through a service principal. Follow the steps below to provide an identity that can access your Key Vault. Use the provided Service Principal credentials provided with the lab and create a secret in ARO cluster oc create secret generic secrets-store-creds --from-literal clientid = \"<client-id>\" --from-literal clientsecret = \"<client-secret>\" oc label secret secrets-store-creds secrets-store.csi.k8s.io/used = true Create a SecretProviderClass with the following YAML, filling in your values for key vault name, tenant ID, and objects to retrieve from your AKV instance apiVersion: secrets-store.csi.x-k8s.io/v1 kind: SecretProviderClass metadata: name: akvprovider-demo spec: provider: azure parameters: usePodIdentity: \"false\" keyvaultName: <key-vault-name> objects: | array: - | objectName: DemoSecret objectType: secret objectVersion: \"\" tenantId: <tenant-Id> oc apply -f aro-content/assets/azure-arc-secretproviderclass.yaml Create a pod with the following YAML, filling in the name of your identity kind: Pod apiVersion: v1 metadata: name: secret-store-pod spec: containers: - name: busybox image: k8s.gcr.io/e2e-test-images/busybox:1.29 command: - \"/bin/sleep\" - \"10000\" volumeMounts: - name: secrets-store-inline mountPath: \"/mnt/secrets-store\" readOnly: true volumes: - name: secrets-store-inline csi: driver: secrets-store.csi.k8s.io readOnly: true volumeAttributes: secretProviderClass: \"akvprovider-demo\" nodePublishSecretRef: name: secrets-store-creds oc apply -f aro-content/assets/azure-arc-pod.yaml Validate the secrets # After the pod starts, the mounted content at the volume path specified in your deployment YAML is available. ## show secrets held in secrets-store oc exec secret-store-pod -- ls /mnt/secrets-store/ DemoSecret ## print a test secret 'DemoSecret' held in secrets-store oc exec secret-store-pod -- cat /mnt/secrets-store/DemoSecret MyExampleSecret Enable log aggregation # In order to collect logs from ARO cluster and store it in Azure ARC. configure azure monitor Create Azure Log Analytics Workspace az monitor log-analytics workspace create --resource-group <<same as above>> --workspace-name loganalyticsworkspace Goto Azure ARC portal and click on logs Click on configure azure monitor button and select the workspace created in last step and click on configure. Now you can go see logs and metrics for your cluster. Monitor ARO cluster against Goverance Policies # Azure Policy extends Gatekeeper v3, an admission controller webhook for Open Policy Agent (OPA), to apply at-scale enforcements and safeguards on your clusters in a centralized, consistent manner. Azure Policy makes it possible to manage and report on the compliance state of your Kubernetes clusters from one place. The add-on enacts the following functions: - Checks with Azure Policy service for policy assignments to the cluster. - Deploys policy definitions into the cluster as constraint template and constraint custom resources. - Reports auditing and compliance details back to Azure Policy service. Azure policy plugin is enabled when you connect your ARO cluster with Azure ARC. you can click on go to Azure Policies to look at the policies assigned to your cluster, check their status and attach more policies.","title":"Integrating Azure ARC with ARO"},{"location":"ops/5-arc-integration/#integrating-azure-arc-with-aro","text":"In this section of the workshop, we will integrate ARO cluster with Azure Arc-enabled Kubernetes. When you connect a Kubernetes/OpenShift cluster with Azure Arc, it will: Be represented in Azure Resource Manager with a unique ID Be place in an Azure subscription and resource group Receive tags just like any otherAzure resource Azure Arc-enabled Kubernetes supports the following scenarios for connected clusters: Connect Kubernetes running outside of Azure for inventory, grouping, and tagging. Deploy applications and apply configuration using GitOps-based configuration management. View and monitor your clusters using Azure Monitor for containers. Enforce threat protection using Microsoft Defender for Kubernetes. Apply policy definitions using Azure Policy for Kubernetes. Use Azure Active Directory for authentication and authorization checks on your cluster","title":"Integrating Azure ARC with ARO"},{"location":"ops/5-arc-integration/#prerequisites","text":"a public ARO cluster azure cli oc cli An identity (user or service principal) which can be used to log in to Azure CLI and connect your cluster to Azure Arc.","title":"Prerequisites"},{"location":"ops/5-arc-integration/#enable-extensions-and-plugins","text":"Install the connectedk8s Azure Cli extension of version >= 1.2.0 az extension add --name \"connectedk8s\" az extension add --name \"k8s-configuration\" az extension add --name \"k8s-extension\" Register providers for Azure Arc-enabled Kubernetes. Registration may take up to 5 minutes. az provider register --namespace Microsoft.Kubernetes az provider register --namespace Microsoft.KubernetesConfiguration az provider register --namespace Microsoft.ExtendedLocation","title":"Enable Extensions and Plugins"},{"location":"ops/5-arc-integration/#connect-an-existing-aro-cluster","text":"Make sure you are logged into your ARO cluster kubeadmin_password = $( az aro list-credentials --name <<cluster name>> --resource-group <<resource group name>> --query kubeadminPassword --output tsv) apiServer=$(az aro show -g <<resource group name>> -n <<cluster name>> --query apiserverProfile.url -o tsv ) oc login $apiServer -u kubeadmin -p $kubeadmin_password Run the following command: az connectedk8s connect --resource-group $resourceGroupName --name $clusterName --distribution openshift --infrastructure auto After running the commnad. grant the following permissions and restart kube-aad-proxy pod oc project azure-arc oc adm policy add-scc-to-user privileged system:serviceaccount:azure-arc:azure-arc-kube-aad-proxy-sa oc get pod | grep kube-aad-proxy-6d9b66b9cd-g27xr 0/2 ContainerCreating 0 26s oc delete pod kube-aad-proxy-6d9b66b9cd-g27xr Wait for a few mins and you will see all the pods in azure-arc namespace running oc get pods NAME READY STATUS RESTARTS AGE cluster-metadata-operator-7dfd94949c-wtvjw 2/2 Running 0 4m47s clusterconnect-agent-7d78db9859-wzthd 3/3 Running 0 4m47s clusteridentityoperator-7b96bcb448-hzthh 2/2 Running 0 4m47s config-agent-dbf66bbc7-r27qs 2/2 Running 0 4m47s controller-manager-67547546f-cmlb9 2/2 Running 0 4m47s extension-manager-548c9d7d6b-jrrdn 2/2 Running 0 4m47s flux-logs-agent-bb994c74f-m5gdc 1/1 Running 0 4m47s kube-aad-proxy-6d9b66b9cd-g27xr 2/2 Running 0 3m16s metrics-agent-7d794679c6-k4b7g 2/2 Running 0 4m47s resource-sync-agent-bb79c44b8-5brjr 2/2 Running 0 4m47s This commands take about 5 mins to complete. Upon the completion of the command you should see the following output and your cluster under Kubernetes - Azure Arc service in Azure Portal { \"agentPublicKeyCertificate\": \"MIICCgKCAgEArNXWSoWVg7q/W5t7vwY24Y8c+dRxy3we/EIRryXx1Orl8GEX94BsHJqvP0iW6ANZ0qoWE675+NR6V3nDMSkis5/aSYMQ8/yWMcUzieKwFfFmTSfCpkzwxy6PSbdRjMwK5H3DDOOXyRQcJV557F5FjHVYfC/0DkPYdhfepcVade+HgOwOOJH28hSNw58pWo/GNNmcwtzFPVdx/TM574CbNVz4OdrtsMy7FKKC63lYW+W3wkzFOqB+qPaITwqwzkruIoSi5HIatONoCPijdTLm3+RoK/CbTYqzHEEId8gFFJd+J4qfSeCYu6jeDNOpwt8DKDLFLvv04oHyxm+Nr34xPBm3+sjggvkLQ5UWpGZ9h7jWTEP2pWEcXF0KqAqAEFPBOOqDKEaYfLtJSJ/yExS1otydDCJEZ1sRPvsjdH5f0DKVXPHgiDa4SoLXomqkarF3g9i6CEK/XE9JTVa8WBJT6wXdXBa0xh8EnzZ9uyVuY1k/2L7d4BR5+sIjqtcDfRSVtxN+LNxgqpo20ltXM1hWkd8WacK7VY+t2lxbYf01zhXWOpaBGgeAMqxqqcHeQor2vzA9PENYYr5zo8eP1LcySmC4LIFiDfN1NxAiZ5SCnrorNFbmrgEDFnWvZzdu2w4r55fsV9qnozUjn6iRqByhyMoeLn5EZLLK5zsW8sA/CeUCAwEAAQ==\", \"agentVersion\": null, \"connectivityStatus\": \"Connecting\", \"distribution\": \"OpenShift\", \"id\": \"/subscriptions/e7f88b1a-04fc-4d00-ace9-eec077a5d6af/resourceGroups/sazed-aro-cluster/providers/Microsoft.Kubernetes/connectedClusters/sazed-aro-cluster\", \"identity\": { \"principalId\": \"xxxx-xxxx-xxxx-xxxx\", \"tenantId\": \"xxxx-xxxx-xxxx-xxxx\", \"type\": \"SystemAssigned\" }, \"infrastructure\": \"azure\", \"kubernetesVersion\": null, \"lastConnectivityTime\": null, \"location\": \"eastus\", \"managedIdentityCertificateExpirationTime\": null, \"name\": \"sazed-aro-cluster\", \"offering\": null, \"provisioningState\": \"Succeeded\", \"resourceGroup\": \"sazed-aro-cluster\", \"systemData\": { \"createdAt\": \"2022-09-15T19:23:40.540376+00:00\", \"createdBy\": \"sazed@redhat.com\", \"createdByType\": \"User\", \"lastModifiedAt\": \"2022-09-15T19:23:40.540376+00:00\", \"lastModifiedBy\": \"sazed@redhat.com\", \"lastModifiedByType\": \"User\" }, \"tags\": {}, \"totalCoreCount\": null, \"totalNodeCount\": null, \"type\": \"microsoft.kubernetes/connectedclusters\" } To check the status of clusters connected to Azure ARC, run the following command az connectedk8s list --resource-group <<resource group>> --output table Name Location ResourceGroup ------------------- ---------- ------------------- << cluster name >>> eastus << resource group >>","title":"Connect an existing ARO cluster"},{"location":"ops/5-arc-integration/#enable-observability","text":"In order to see ARO resource inside Azure Arc, you need to create a service account and provide it to Azure Arc. oc project azure-arc oc create serviceaccount azure-arc-observability oc create clusterrolebinding azure-arc-observability-rb --clusterrole cluster-admin --serviceaccount azure-arc:azure-arc-observability apiVersion: v1 kind: Secret metadata: name: azure-arc-observability-secret namespace: azure-arc annotations: kubernetes.io/service-account.name: azure-arc-observability type: kubernetes.io/service-account-token oc apply -f aro-content/assets/azure-arc-secret.yaml TOKEN = $( oc get secret azure-arc-observability-secret -o jsonpath = '{$.data.token}' | base64 -d | sed 's/$/\\\\n/g' ) echo $TOKEN Copy the token, goto Azure portal and select your cluster under \"Kubernetes - Azure Arc\" Select Namespaces from the left side menu and paste the token in \"Service account bearer token\" input field. Now you can see all of your ARO rearouses inside ARC UI. you can see the following resources inside Azure ARC portal: - Namespaces - Workloads - Services and Ingress - Storage - Configurations","title":"Enable observability"},{"location":"ops/5-arc-integration/#access-secrets-from-azure-key-vault","text":"The Azure Key Vault Provider for Secrets Store CSI Driver allows for the integration of Azure Key Vault as a secrets store with a Kubernetes cluster via a CSI volume. For Azure Arc-enabled Kubernetes clusters, you can install the Azure Key Vault Secrets Provider extension to fetch secrets.","title":"Access Secrets from Azure Key Vault"},{"location":"ops/5-arc-integration/#install-extension","text":"az k8s-extension create --cluster-name <<cluster name>> --resource-group <<resource group>> --cluster -type connectedClusters --extension-type Microsoft.AzureKeyVaultSecretsProvider --name akvsecretsprovider { \"aksAssignedIdentity\" : null, \"autoUpgradeMinorVersion\" : true, \"configurationProtectedSettings\" : {} , \"configurationSettings\" : {} , \"customLocationSettings\" : null, \"errorInfo\" : null, \"extensionType\" : \"microsoft.azurekeyvaultsecretsprovider\" , \"id\" : \"/subscriptions/e7f88b1a-04fc-4d00-ace9-eec077a5d6af/resourceGroups/sazed-aro-cluster/providers/Microsoft.Kubernetes/connectedClusters/sazed-aro-cluster-1/providers/Microsoft.KubernetesConfiguration/extensions/akvsecretsprovider\" , \"identity\" : { \"principalId\" : \"xxxx-xxxx-xxxx-xxxx\" , \"tenantId\" : null, \"type\" : \"SystemAssigned\" } , \"installedVersion\" : null, \"name\" : \"akvsecretsprovider\" , \"packageUri\" : null, \"provisioningState\" : \"Succeeded\" , \"releaseTrain\" : \"Stable\" , \"resourceGroup\" : \"sazed-aro-cluster\" , \"scope\" : { \"cluster\" : { \"releaseNamespace\" : \"kube-system\" } , \"namespace\" : null } , \"statuses\" : [] , \"systemData\" : { \"createdAt\" : \"2022-09-15T20:45:47.152390+00:00\" , \"createdBy\" : null, \"createdByType\" : null, \"lastModifiedAt\" : \"2022-09-15T20:45:47.152390+00:00\" , \"lastModifiedBy\" : null, \"lastModifiedByType\" : null } , \"type\" : \"Microsoft.KubernetesConfiguration/extensions\" , \"version\" : \"1.3.0\" } Validate the extension installation az k8s-extension show --cluster-type connectedClusters --cluster-name <<cluster name>> --resource-group <<resource group>> --name akvsecretsprovider { \"aksAssignedIdentity\": null, \"autoUpgradeMinorVersion\": true, \"configurationProtectedSettings\": {}, \"configurationSettings\": {}, \"customLocationSettings\": null, \"errorInfo\": null, \"extensionType\": \"microsoft.azurekeyvaultsecretsprovider\", \"id\": \"/subscriptions/e7f88b1a-04fc-4d00-ace9-eec077a5d6af/resourceGroups/sazed-aro-cluster -1/providers/Microsoft.Kubernetes/connectedClusters/sazed-aro-cluster-1/providers/Microsoft.KubernetesConfiguration/extensions/akvsecretsprovider \", \" identity \": { \" principalId \": \" xxxx-xxxx-xxxx-xxxx \", \" tenantId \": null, \" type \": \" SystemAssigned \" }, \" installedVersion \": null, \" name \": \" akvsecretsprovider \", \" packageUri \": null, \" provisioningState \": \" Succeeded \", \" releaseTrain \": \" Stable \", \" resourceGroup \": \" sazed-aro-cluster \", \" scope \": { \" cluster \": { \" releaseNamespace \": \" kube-system \" }, \" namespace \": null }, \" statuses \": [], \" systemData \": { \" createdAt \": \" 2022 -09-15T20:45:47.152390+00:00 \", \" createdBy \": null, \" createdByType \": null, \" lastModifiedAt \": \" 2022 -09-15T20:45:47.152390+00:00 \", \" lastModifiedBy \": null, \" lastModifiedByType \": null }, \" type \": \" Microsoft.KubernetesConfiguration/extensions \", \" version \": \" 1 .3.0 \" }","title":"Install extension"},{"location":"ops/5-arc-integration/#create-or-select-an-azure-key-vault","text":"az keyvault create -n <<cluster name>> -g <<resource group>> -l eastus az keyvault secret set --vault-name <<cluster name>> -n DemoSecret --value MyExampleSecret","title":"Create or Select an Azure Key Vault"},{"location":"ops/5-arc-integration/#provide-identity-to-access-azure-key-vault","text":"Currently, the Secrets Store CSI Driver on Arc-enabled clusters can be accessed through a service principal. Follow the steps below to provide an identity that can access your Key Vault. Use the provided Service Principal credentials provided with the lab and create a secret in ARO cluster oc create secret generic secrets-store-creds --from-literal clientid = \"<client-id>\" --from-literal clientsecret = \"<client-secret>\" oc label secret secrets-store-creds secrets-store.csi.k8s.io/used = true Create a SecretProviderClass with the following YAML, filling in your values for key vault name, tenant ID, and objects to retrieve from your AKV instance apiVersion: secrets-store.csi.x-k8s.io/v1 kind: SecretProviderClass metadata: name: akvprovider-demo spec: provider: azure parameters: usePodIdentity: \"false\" keyvaultName: <key-vault-name> objects: | array: - | objectName: DemoSecret objectType: secret objectVersion: \"\" tenantId: <tenant-Id> oc apply -f aro-content/assets/azure-arc-secretproviderclass.yaml Create a pod with the following YAML, filling in the name of your identity kind: Pod apiVersion: v1 metadata: name: secret-store-pod spec: containers: - name: busybox image: k8s.gcr.io/e2e-test-images/busybox:1.29 command: - \"/bin/sleep\" - \"10000\" volumeMounts: - name: secrets-store-inline mountPath: \"/mnt/secrets-store\" readOnly: true volumes: - name: secrets-store-inline csi: driver: secrets-store.csi.k8s.io readOnly: true volumeAttributes: secretProviderClass: \"akvprovider-demo\" nodePublishSecretRef: name: secrets-store-creds oc apply -f aro-content/assets/azure-arc-pod.yaml","title":"Provide identity to access Azure Key Vault"},{"location":"ops/5-arc-integration/#validate-the-secrets","text":"After the pod starts, the mounted content at the volume path specified in your deployment YAML is available. ## show secrets held in secrets-store oc exec secret-store-pod -- ls /mnt/secrets-store/ DemoSecret ## print a test secret 'DemoSecret' held in secrets-store oc exec secret-store-pod -- cat /mnt/secrets-store/DemoSecret MyExampleSecret","title":"Validate the secrets"},{"location":"ops/5-arc-integration/#enable-log-aggregation","text":"In order to collect logs from ARO cluster and store it in Azure ARC. configure azure monitor Create Azure Log Analytics Workspace az monitor log-analytics workspace create --resource-group <<same as above>> --workspace-name loganalyticsworkspace Goto Azure ARC portal and click on logs Click on configure azure monitor button and select the workspace created in last step and click on configure. Now you can go see logs and metrics for your cluster.","title":"Enable log aggregation"},{"location":"ops/5-arc-integration/#monitor-aro-cluster-against-goverance-policies","text":"Azure Policy extends Gatekeeper v3, an admission controller webhook for Open Policy Agent (OPA), to apply at-scale enforcements and safeguards on your clusters in a centralized, consistent manner. Azure Policy makes it possible to manage and report on the compliance state of your Kubernetes clusters from one place. The add-on enacts the following functions: - Checks with Azure Policy service for policy assignments to the cluster. - Deploys policy definitions into the cluster as constraint template and constraint custom resources. - Reports auditing and compliance details back to Azure Policy service. Azure policy plugin is enabled when you connect your ARO cluster with Azure ARC. you can click on go to Azure Policies to look at the policies assigned to your cluster, check their status and attach more policies.","title":"Monitor ARO cluster against Goverance Policies"},{"location":"ops/6-front-door/","text":"Install and Configure Azure Front Door for our Application # The first step is to export three environment variables for the Resource Group ARO is in, the ARO Cluster name, both of which are the same as the USERID. We will set these variables for readability purposes. echo 'export ARORG=$USERID' >> ~/.bashrc && source ~/.bashrc echo 'export AROCLUSTER=$USERID' >> ~/.bashrc && source ~/.bashrc Next we, need to get the name of the VNET ARO is in echo \"export VNET_NAME= $( az network vnet list -g $ARORG --query '[0].name' -o tsv ) \" >> ~/.bashrc && source ~/.bashrc Provide a subnet prefix for the private link subnet. This subnet will contain the private link service we will use to connect Front Door with ARO. echo \"export PRIVATEENDPOINTSUBNET_PREFIX=10.0.5.0/24\" >> ~/.bashrc && source ~/.bashrc Give the private link subnet a meaningful name echo \"export PRIVATEENDPOINTSUBNET_NAME=PrivateEndpoint-subnet\" >> ~/.bashrc && source ~/.bashrc Create a unique random number so we don't create services with the same name echo \"export UNIQUE= $RANDOM \" >> ~/.bashrc && source ~/.bashrc Provide a unique name for the Azure Front Door Service we will create echo \"export AFD_NAME= $UNIQUE -afd\" >> ~/.bashrc && source ~/.bashrc Get the ARO Cluster Resource Group name. Note this the name of the resource group that the ARO service creates and manages. This is the resource group that contains all the VMs, Storage, Load Balancers, etc that ARO manages. echo \"export ARO_RGNAME= $( az aro show -n $AROCLUSTER -g $ARORG --query 'clusterProfile.resourceGroupId' -o tsv | sed 's/.*\\///' ) \" >> ~/.bashrc && source ~/.bashrc Get the Azure location of the ARO cluster echo \"export LOCATION= $( az aro show --name $AROCLUSTER --resource-group $ARORG --query location -o tsv ) \" >> ~/.bashrc && source ~/.bashrc Get the workers nodes subnet name and IDs so we can connect the Azure Front Door to the workers nodes using a private link service. echo \"export WORKER_SUBNET_NAME= $( az aro show --name $AROCLUSTER --resource-group $ARORG --query 'workerProfiles[0].subnetId' -o tsv | sed 's/.*\\///' ) \" >> ~/.bashrc && source ~/.bashrc echo \"export WORKER_SUBNET_ID= $( az aro show --name $AROCLUSTER --resource-group $ARORG --query 'workerProfiles[0].subnetId' -o tsv ) \" >> ~/.bashrc && source ~/.bashrc # privatelink_id=$(az network private-link-service show -n $AROCLUSTER-pls -g $ARORG --query 'id' -o tsv) Get the internal load balancer name, id and ip that the private link service will be connected to. echo \"export INTERNAL_LBNAME= $( az network lb list --resource-group $ARO_RGNAME --query \"[? contains(name, 'internal')].name\" -o tsv ) \" >> ~/.bashrc && source ~/.bashrc export LBCONFIG_ID = $( az network lb frontend-ip list -g $ARO_RGNAME --lb-name $INTERNAL_LBNAME --query \"[? contains(subnet.id,' $WORKER_SUBNET_ID ')].id\" -o tsv ) export LBCONFIG_IP = $( az network lb frontend-ip list -g $ARO_RGNAME --lb-name $INTERNAL_LBNAME --query \"[? contains(subnet.id,' $WORKER_SUBNET_ID ')].privateIpAddress\" -o tsv ) Set the following DNS variables for the workshop so we can add DNS records to the azure.mobb.cloud domain DNS_RG = shared-services TOP_DOMAIN = ws.mobb.cloud Set user specific domain settings. We will be creating a new DNS zone with the DOMAIN variable. ARO_APP_FQDN is the fully qualified url for your ratingsapp application ARO_MINE_CUSTOM_DOMAIN_NAME is the name of the DNS entry. DOMAIN = $USERID .ws.mobb.cloud echo \"export ARO_APP_FQDN=ratingsapp. $USERID .ws.mobb.cloud\" >> ~/.bashrc && source ~/.bashrc AFD_RATINGS_CUSTOM_DOMAIN_NAME = ratingsapp- $USERID -ws-mobb-cloud Now that we have all the required variables set, we can start creating the Front Door service and everything it needs. Create a private link service targeting the worker subnets # The first thing we will create is the private link service, that again is what will provide private connectivty from Front Door to your cluster. az network private-link-service create \\ --name $AROCLUSTER -pls \\ --resource-group $ARORG \\ --private-ip-address-version IPv4 \\ --private-ip-allocation-method Dynamic \\ --vnet-name $VNET_NAME \\ --subnet $WORKER_SUBNET_NAME \\ --lb-frontend-ip-configs $LBCONFIG_ID privatelink_id = $( az network private-link-service show -n $AROCLUSTER -pls -g $ARORG --query 'id' -o tsv ) Create an instance of Azure Front Door and get the Front Door ID. az afd profile create \\ --resource-group $ARORG \\ --profile-name $AFD_NAME \\ --sku Premium_AzureFrontDoor afd_id = $( az afd profile show -g $ARORG --profile-name $AFD_NAME --query 'id' -o tsv ) Create a Front Door endpoint for the ARO Internal Load Balancer. This will allow Front Door to send traffic to the ARO Load Balancer. az afd endpoint create \\ --resource-group $ARORG \\ --enabled-state Enabled \\ --endpoint-name 'aro-ilb' $UNIQUEID \\ --profile-name $AFD_NAME Create a Front Door Origin Group that will point to the ARO Internal Loadbalancer az afd origin-group create \\ --origin-group-name 'afdorigin' \\ --probe-path '/' \\ --probe-protocol Http \\ --probe-request-type GET \\ --probe-interval-in-seconds 100 \\ --profile-name $AFD_NAME \\ --resource-group $ARORG \\ --probe-interval-in-seconds 120 \\ --sample-size 4 \\ --successful-samples-required 3 \\ --additional-latency-in-milliseconds 50 Create a Front Door Origin with the above Origin Group that will point to the ARO Internal Loadbalancer. Click here to read more about Front Door Origins and Origin Groups. az afd origin create \\ --enable-private-link true \\ --private-link-resource $privatelink_id \\ --private-link-location $LOCATION \\ --private-link-request-message 'Private link service from AFD' \\ --weight 1000 \\ --priority 1 \\ --http-port 80 \\ --https-port 443 \\ --origin-group-name 'afdorigin' \\ --enabled-state Enabled \\ --host-name $LBCONFIG_IP \\ --origin-name 'afdorigin' \\ --profile-name $AFD_NAME \\ --resource-group $ARORG Approve the private link connection privatelink_pe_id = $( az network private-link-service show -n $AROCLUSTER -pls -g $ARORG --query 'privateEndpointConnections[0].id' -o tsv ) az network private-endpoint-connection approve \\ --description 'Approved' \\ --id $privatelink_pe_id Add your custom domain to Azure Front Door az afd custom-domain create \\ --certificate-type ManagedCertificate \\ --custom-domain-name $AFD_RATINGS_CUSTOM_DOMAIN_NAME \\ --host-name $ARO_APP_FQDN \\ --minimum-tls-version TLS12 \\ --profile-name $AFD_NAME \\ --resource-group $ARORG *Note: This takes about 5 minutes Add an Azure Front Door route for your custom domain az afd route create \\ --endpoint-name 'aro-ilb' $UNIQUEID \\ --forwarding-protocol HttpOnly \\ --https-redirect Enabled \\ --origin-group 'afdorigin' \\ --profile-name $AFD_NAME \\ --resource-group $ARORG \\ --route-name 'aro-ratings-route' \\ --supported-protocols Http Https \\ --patterns-to-match '/*' \\ --custom-domains $AFD_RATINGS_CUSTOM_DOMAIN_NAME Update DNS # Now that we have Front Door setup and configured, we need to setup DNS to work with the front door endpoint. Get a validation token from Front Door so Front Door can validate your domain afdToken = $( az afd custom-domain show \\ --resource-group $ARORG \\ --profile-name $AFD_NAME \\ --custom-domain-name $AFD_RATINGS_CUSTOM_DOMAIN_NAME \\ --query \"validationProperties.validationToken\" ) Update Azure nameservers to match the top level domain with the new workshop user domain for i in $( az network dns zone show -g $DNS_RG -n $TOP_DOMAIN --query \"nameServers\" -o tsv ) do az network dns record-set ns add-record -g $USERID -z $DOMAIN -d $i -n @ done Create a new text record in your DNS server az network dns record-set txt add-record -g $USERID -z $DOMAIN -n _dnsauth. $( echo $ARO_APP_FQDN | sed 's/\\..*//' ) --value $afdToken --record-set-name _dnsauth. $( echo $ARO_APP_FQDN | sed 's/\\..*//' ) Check if the domain has been validated: *Note this would be a great time to take a break and grab a coffee ... it can take several minutes for Azure Front Door to validate your domain. az afd custom-domain list -g $ARORG --profile-name $AFD_NAME --query \"[? contains(hostName, '$ARO_APP_FQDN')].domainValidationState\" Get the Azure Front Door endpoint: afdEndpoint = $( az afd endpoint show -g $ARORG --profile-name $AFD_NAME --endpoint-name aro-ilb $UNIQUEID --query \"hostName\" -o tsv ) Create a cname record for the application az network dns record-set cname set-record -g $USERID -z $DOMAIN \\ -n $( echo $ARO_APP_FQDN | sed 's/\\..*//' ) -z $DOMAIN -c $afdEndpoint Congratations!! # If you made it this far and setup Front Door yourself, pat yourself on the back.","title":"6 front door"},{"location":"ops/6-front-door/#install-and-configure-azure-front-door-for-our-application","text":"The first step is to export three environment variables for the Resource Group ARO is in, the ARO Cluster name, both of which are the same as the USERID. We will set these variables for readability purposes. echo 'export ARORG=$USERID' >> ~/.bashrc && source ~/.bashrc echo 'export AROCLUSTER=$USERID' >> ~/.bashrc && source ~/.bashrc Next we, need to get the name of the VNET ARO is in echo \"export VNET_NAME= $( az network vnet list -g $ARORG --query '[0].name' -o tsv ) \" >> ~/.bashrc && source ~/.bashrc Provide a subnet prefix for the private link subnet. This subnet will contain the private link service we will use to connect Front Door with ARO. echo \"export PRIVATEENDPOINTSUBNET_PREFIX=10.0.5.0/24\" >> ~/.bashrc && source ~/.bashrc Give the private link subnet a meaningful name echo \"export PRIVATEENDPOINTSUBNET_NAME=PrivateEndpoint-subnet\" >> ~/.bashrc && source ~/.bashrc Create a unique random number so we don't create services with the same name echo \"export UNIQUE= $RANDOM \" >> ~/.bashrc && source ~/.bashrc Provide a unique name for the Azure Front Door Service we will create echo \"export AFD_NAME= $UNIQUE -afd\" >> ~/.bashrc && source ~/.bashrc Get the ARO Cluster Resource Group name. Note this the name of the resource group that the ARO service creates and manages. This is the resource group that contains all the VMs, Storage, Load Balancers, etc that ARO manages. echo \"export ARO_RGNAME= $( az aro show -n $AROCLUSTER -g $ARORG --query 'clusterProfile.resourceGroupId' -o tsv | sed 's/.*\\///' ) \" >> ~/.bashrc && source ~/.bashrc Get the Azure location of the ARO cluster echo \"export LOCATION= $( az aro show --name $AROCLUSTER --resource-group $ARORG --query location -o tsv ) \" >> ~/.bashrc && source ~/.bashrc Get the workers nodes subnet name and IDs so we can connect the Azure Front Door to the workers nodes using a private link service. echo \"export WORKER_SUBNET_NAME= $( az aro show --name $AROCLUSTER --resource-group $ARORG --query 'workerProfiles[0].subnetId' -o tsv | sed 's/.*\\///' ) \" >> ~/.bashrc && source ~/.bashrc echo \"export WORKER_SUBNET_ID= $( az aro show --name $AROCLUSTER --resource-group $ARORG --query 'workerProfiles[0].subnetId' -o tsv ) \" >> ~/.bashrc && source ~/.bashrc # privatelink_id=$(az network private-link-service show -n $AROCLUSTER-pls -g $ARORG --query 'id' -o tsv) Get the internal load balancer name, id and ip that the private link service will be connected to. echo \"export INTERNAL_LBNAME= $( az network lb list --resource-group $ARO_RGNAME --query \"[? contains(name, 'internal')].name\" -o tsv ) \" >> ~/.bashrc && source ~/.bashrc export LBCONFIG_ID = $( az network lb frontend-ip list -g $ARO_RGNAME --lb-name $INTERNAL_LBNAME --query \"[? contains(subnet.id,' $WORKER_SUBNET_ID ')].id\" -o tsv ) export LBCONFIG_IP = $( az network lb frontend-ip list -g $ARO_RGNAME --lb-name $INTERNAL_LBNAME --query \"[? contains(subnet.id,' $WORKER_SUBNET_ID ')].privateIpAddress\" -o tsv ) Set the following DNS variables for the workshop so we can add DNS records to the azure.mobb.cloud domain DNS_RG = shared-services TOP_DOMAIN = ws.mobb.cloud Set user specific domain settings. We will be creating a new DNS zone with the DOMAIN variable. ARO_APP_FQDN is the fully qualified url for your ratingsapp application ARO_MINE_CUSTOM_DOMAIN_NAME is the name of the DNS entry. DOMAIN = $USERID .ws.mobb.cloud echo \"export ARO_APP_FQDN=ratingsapp. $USERID .ws.mobb.cloud\" >> ~/.bashrc && source ~/.bashrc AFD_RATINGS_CUSTOM_DOMAIN_NAME = ratingsapp- $USERID -ws-mobb-cloud Now that we have all the required variables set, we can start creating the Front Door service and everything it needs.","title":"Install and Configure Azure Front Door for our Application"},{"location":"ops/6-front-door/#create-a-private-link-service-targeting-the-worker-subnets","text":"The first thing we will create is the private link service, that again is what will provide private connectivty from Front Door to your cluster. az network private-link-service create \\ --name $AROCLUSTER -pls \\ --resource-group $ARORG \\ --private-ip-address-version IPv4 \\ --private-ip-allocation-method Dynamic \\ --vnet-name $VNET_NAME \\ --subnet $WORKER_SUBNET_NAME \\ --lb-frontend-ip-configs $LBCONFIG_ID privatelink_id = $( az network private-link-service show -n $AROCLUSTER -pls -g $ARORG --query 'id' -o tsv ) Create an instance of Azure Front Door and get the Front Door ID. az afd profile create \\ --resource-group $ARORG \\ --profile-name $AFD_NAME \\ --sku Premium_AzureFrontDoor afd_id = $( az afd profile show -g $ARORG --profile-name $AFD_NAME --query 'id' -o tsv ) Create a Front Door endpoint for the ARO Internal Load Balancer. This will allow Front Door to send traffic to the ARO Load Balancer. az afd endpoint create \\ --resource-group $ARORG \\ --enabled-state Enabled \\ --endpoint-name 'aro-ilb' $UNIQUEID \\ --profile-name $AFD_NAME Create a Front Door Origin Group that will point to the ARO Internal Loadbalancer az afd origin-group create \\ --origin-group-name 'afdorigin' \\ --probe-path '/' \\ --probe-protocol Http \\ --probe-request-type GET \\ --probe-interval-in-seconds 100 \\ --profile-name $AFD_NAME \\ --resource-group $ARORG \\ --probe-interval-in-seconds 120 \\ --sample-size 4 \\ --successful-samples-required 3 \\ --additional-latency-in-milliseconds 50 Create a Front Door Origin with the above Origin Group that will point to the ARO Internal Loadbalancer. Click here to read more about Front Door Origins and Origin Groups. az afd origin create \\ --enable-private-link true \\ --private-link-resource $privatelink_id \\ --private-link-location $LOCATION \\ --private-link-request-message 'Private link service from AFD' \\ --weight 1000 \\ --priority 1 \\ --http-port 80 \\ --https-port 443 \\ --origin-group-name 'afdorigin' \\ --enabled-state Enabled \\ --host-name $LBCONFIG_IP \\ --origin-name 'afdorigin' \\ --profile-name $AFD_NAME \\ --resource-group $ARORG Approve the private link connection privatelink_pe_id = $( az network private-link-service show -n $AROCLUSTER -pls -g $ARORG --query 'privateEndpointConnections[0].id' -o tsv ) az network private-endpoint-connection approve \\ --description 'Approved' \\ --id $privatelink_pe_id Add your custom domain to Azure Front Door az afd custom-domain create \\ --certificate-type ManagedCertificate \\ --custom-domain-name $AFD_RATINGS_CUSTOM_DOMAIN_NAME \\ --host-name $ARO_APP_FQDN \\ --minimum-tls-version TLS12 \\ --profile-name $AFD_NAME \\ --resource-group $ARORG *Note: This takes about 5 minutes Add an Azure Front Door route for your custom domain az afd route create \\ --endpoint-name 'aro-ilb' $UNIQUEID \\ --forwarding-protocol HttpOnly \\ --https-redirect Enabled \\ --origin-group 'afdorigin' \\ --profile-name $AFD_NAME \\ --resource-group $ARORG \\ --route-name 'aro-ratings-route' \\ --supported-protocols Http Https \\ --patterns-to-match '/*' \\ --custom-domains $AFD_RATINGS_CUSTOM_DOMAIN_NAME","title":"Create a private link service targeting the worker subnets"},{"location":"ops/6-front-door/#update-dns","text":"Now that we have Front Door setup and configured, we need to setup DNS to work with the front door endpoint. Get a validation token from Front Door so Front Door can validate your domain afdToken = $( az afd custom-domain show \\ --resource-group $ARORG \\ --profile-name $AFD_NAME \\ --custom-domain-name $AFD_RATINGS_CUSTOM_DOMAIN_NAME \\ --query \"validationProperties.validationToken\" ) Update Azure nameservers to match the top level domain with the new workshop user domain for i in $( az network dns zone show -g $DNS_RG -n $TOP_DOMAIN --query \"nameServers\" -o tsv ) do az network dns record-set ns add-record -g $USERID -z $DOMAIN -d $i -n @ done Create a new text record in your DNS server az network dns record-set txt add-record -g $USERID -z $DOMAIN -n _dnsauth. $( echo $ARO_APP_FQDN | sed 's/\\..*//' ) --value $afdToken --record-set-name _dnsauth. $( echo $ARO_APP_FQDN | sed 's/\\..*//' ) Check if the domain has been validated: *Note this would be a great time to take a break and grab a coffee ... it can take several minutes for Azure Front Door to validate your domain. az afd custom-domain list -g $ARORG --profile-name $AFD_NAME --query \"[? contains(hostName, '$ARO_APP_FQDN')].domainValidationState\" Get the Azure Front Door endpoint: afdEndpoint = $( az afd endpoint show -g $ARORG --profile-name $AFD_NAME --endpoint-name aro-ilb $UNIQUEID --query \"hostName\" -o tsv ) Create a cname record for the application az network dns record-set cname set-record -g $USERID -z $DOMAIN \\ -n $( echo $ARO_APP_FQDN | sed 's/\\..*//' ) -z $DOMAIN -c $afdEndpoint","title":"Update DNS"},{"location":"ops/6-front-door/#congratations","text":"If you made it this far and setup Front Door yourself, pat yourself on the back.","title":"Congratations!!"},{"location":"ops/7-private-ingress/","text":"Create a private Ingress Controller # As you will remember, when we create a cluster for this workshop, we use a public cluster where the API and default Applications endpoints are exposed to the Internet. This was to elminate the need to VPN into our Azure environment. To similate a private environment for the applications endpoint, we will craete a second Ingress Controller only exposed to the private network of our cluster. Start by gathering a couple envionment variables from the default IngressController. export INGRESSCERT = $( oc get IngressController default -n openshift-ingress-operator -o jsonpath = '{.spec.defaultCertificate.name}' ) export SELECTOR = ingresscontroller.operator.openshift.io/deployment-ingresscontroller = private export DOMAIN = $( oc get IngressController default -n openshift-ingress-operator -o jsonpath = '{.status.domain}' | sed \"s/apps/apps2/g\" ) Now apply the following yaml file that will create a 2nd 'private' Ingress Controller. envsubst << EOF | oc apply -f - apiVersion: v1 items: - apiVersion: operator.openshift.io/v1 kind: IngressController metadata: finalizers: - ingresscontroller.operator.openshift.io/finalizer-ingresscontroller generation: 2 name: private namespace: openshift-ingress-operator spec: clientTLS: clientCA: name: \"\" clientCertificatePolicy: \"\" defaultCertificate: name: $INGRESSCERT httpCompression: {} httpEmptyRequestsPolicy: Respond httpErrorCodePages: name: \"\" replicas: 2 tuningOptions: {} domain: $DOMAIN endpointPublishingStrategy: loadBalancer: scope: Internal type: LoadBalancerService observedGeneration: 2 selector: $SELECTOR tlsProfile: ciphers: - ECDHE-ECDSA-AES128-GCM-SHA256 - ECDHE-RSA-AES128-GCM-SHA256 - ECDHE-ECDSA-AES256-GCM-SHA384 - ECDHE-RSA-AES256-GCM-SHA384 - ECDHE-ECDSA-CHACHA20-POLY1305 - ECDHE-RSA-CHACHA20-POLY1305 - DHE-RSA-AES128-GCM-SHA256 - DHE-RSA-AES256-GCM-SHA384 - TLS_AES_128_GCM_SHA256 - TLS_AES_256_GCM_SHA384 - TLS_CHACHA20_POLY1305_SHA256 minTLSVersion: VersionTLS12 kind: List EOF Check to make sure the private ingress controller was created. # oc get IngressController -n openshift-ingress-operator Expected Output:","title":"7 private ingress"},{"location":"ops/7-private-ingress/#create-a-private-ingress-controller","text":"As you will remember, when we create a cluster for this workshop, we use a public cluster where the API and default Applications endpoints are exposed to the Internet. This was to elminate the need to VPN into our Azure environment. To similate a private environment for the applications endpoint, we will craete a second Ingress Controller only exposed to the private network of our cluster. Start by gathering a couple envionment variables from the default IngressController. export INGRESSCERT = $( oc get IngressController default -n openshift-ingress-operator -o jsonpath = '{.spec.defaultCertificate.name}' ) export SELECTOR = ingresscontroller.operator.openshift.io/deployment-ingresscontroller = private export DOMAIN = $( oc get IngressController default -n openshift-ingress-operator -o jsonpath = '{.status.domain}' | sed \"s/apps/apps2/g\" ) Now apply the following yaml file that will create a 2nd 'private' Ingress Controller. envsubst << EOF | oc apply -f - apiVersion: v1 items: - apiVersion: operator.openshift.io/v1 kind: IngressController metadata: finalizers: - ingresscontroller.operator.openshift.io/finalizer-ingresscontroller generation: 2 name: private namespace: openshift-ingress-operator spec: clientTLS: clientCA: name: \"\" clientCertificatePolicy: \"\" defaultCertificate: name: $INGRESSCERT httpCompression: {} httpEmptyRequestsPolicy: Respond httpErrorCodePages: name: \"\" replicas: 2 tuningOptions: {} domain: $DOMAIN endpointPublishingStrategy: loadBalancer: scope: Internal type: LoadBalancerService observedGeneration: 2 selector: $SELECTOR tlsProfile: ciphers: - ECDHE-ECDSA-AES128-GCM-SHA256 - ECDHE-RSA-AES128-GCM-SHA256 - ECDHE-ECDSA-AES256-GCM-SHA384 - ECDHE-RSA-AES256-GCM-SHA384 - ECDHE-ECDSA-CHACHA20-POLY1305 - ECDHE-RSA-CHACHA20-POLY1305 - DHE-RSA-AES128-GCM-SHA256 - DHE-RSA-AES256-GCM-SHA384 - TLS_AES_128_GCM_SHA256 - TLS_AES_256_GCM_SHA384 - TLS_CHACHA20_POLY1305_SHA256 minTLSVersion: VersionTLS12 kind: List EOF","title":"Create a private Ingress Controller"},{"location":"ops/7-private-ingress/#check-to-make-sure-the-private-ingress-controller-was-created","text":"oc get IngressController -n openshift-ingress-operator Expected Output:","title":"Check to make sure the private ingress controller was created."},{"location":"ops/afd/configure/","text":"Configure Azure Front Door # Azure Front Door is Microsoft\u2019s Content Delivery Network (CDN) which provides a fast, reliable, and secure connection between your users and your applications\u2019 content. Azure Front Door delivers your content using the Microsoft\u2019s global edge network with hundreds of global and local POPs distributed around the world. Azure Front Door allows you to privately connect to your Azure Red Hat OpenShift (ARO) cluster using Azure Private Link. This helps to protect your apps from malicious actors and allows you to embrace a zero-trust access model. To begin, we first need to get the name of the vNet that ARO is in. To do so, run the following command: export VNET_NAME = $( az network vnet list \\ -g ${ AZ_RG } --query '[0].name' -o tsv ) While we have a resource group that contains the Azure Red Hat OpenShift (ARO) cluster object, the ARO service itself creates a separate resource group that is fully controlled by the ARO service. This resource group contains all the virtual machines, storage accounts, load balancers, and more that ARO needs to function. To identify that resource group, run the following command: export CLUSTER_RG = $( az aro show -n ${ AZ_ARO } \\ -g ${ AZ_RG } --query 'clusterProfile.resourceGroupId' -o tsv | cut -d/ -f5 ) echo \"ARO Cluster RG: ${ CLUSTER_RG } \" Since Azure Front Door connects to your Azure Red Hat OpenShift (ARO) cluster via Azure Private Link, we need to get a few pieces of information so we can configure the Private Link. To do so, run the following commands: export WORKER_SUBNET_ID = $( az aro show -n ${ AZ_ARO } \\ -g ${ AZ_RG } --query 'workerProfiles[0].subnetId' -o tsv ) echo \"Worker Subnet ID: ${ WORKER_SUBNET_ID } \" export INTERNAL_LBNAME = $( az network lb list -g ${ CLUSTER_RG } \\ --query \"[? contains(name, 'internal')].name\" -o tsv ) echo \"LB Name: ${ INTERNAL_LBNAME } \" export LBCONFIG_ID = $( az network lb frontend-ip list -g ${ CLUSTER_RG } \\ --lb-name ${ INTERNAL_LBNAME } --query \\ \"[? contains(subnet.id,' ${ WORKER_SUBNET_ID } ')].id\" -o tsv ) echo \"LB ID: ${ LBCONFIG_ID } \" export LBCONFIG_IP = $( az network lb frontend-ip list -g ${ CLUSTER_RG } \\ --lb-name ${ INTERNAL_LBNAME } --query \\ \"[? contains(subnet.id,' ${ WORKER_SUBNET_ID } ')].privateIpAddress\" \\ -o tsv ) echo \"LB IP: ${ LBCONFIG_IP } \" Now that we have all the required information stored in our environment variables, we can begin the process of creating the Azure Front Door service and its associated dependencies. First, we will create an Azure Private Link service that will allow Azure Front Door to connect to your Azure Red Hat OpenShift cluster. To do so, run the following command: az network private-link-service create \\ --name ${ AZ_USER } -pls \\ --resource-group ${ AZ_RG } \\ --private-ip-address-version IPv4 \\ --private-ip-allocation-method Dynamic \\ --vnet-name ${ AZ_USER } -vnet \\ --subnet $( echo ${ WORKER_SUBNET_ID } | sed 's/.*\\///' ) \\ --lb-frontend-ip-configs ${ LBCONFIG_ID } Once the Private Link service has been created, let's grab the ID and store it for future use. To do so, run the following command: PL_ID = $( az network private-link-service show \\ -n ${ AZ_USER } -pls -g ${ AZ_RG } --query 'id' -o tsv ) echo \"PrivateLink ID: ${ PL_ID } \" Next, let's create an instance of Azure Front Door. To do so, run the following command: az afd profile create \\ --resource-group ${ AZ_RG } \\ --profile-name ${ AZ_USER } -afd- ${ UNIQUE } \\ --sku Premium_AzureFrontDoor Once the Front Door instance has been created, let's grab the ID and storage it for future use. To do so, run the following command: export AFD_ID = $( az afd profile show -g ${ AZ_RG } \\ --profile-name ${ AZ_USER } -afd- ${ UNIQUE } --query 'id' -o tsv ) echo \"Front Door ID: ${ AFD_ID } \" Next, we need to create an Azure Front Door endpoint for the ARO internal load balancer. This will allow Azure Front Door to send traffic directly to the ARO Load Balancer. To do so, run the following command: az afd endpoint create \\ --resource-group ${ AZ_RG } \\ --enabled-state Enabled \\ --endpoint-name ${ AZ_USER } -ilb- ${ UNIQUE } \\ --profile-name ${ AZ_USER } -afd- ${ UNIQUE } Now we need to create an Azure Front Door origin group that will point to the ARO internal load balancer. An origin group in Azure Front Door refers to a set of origins, which we'll create in just a moment. To do so, run the following command: az afd origin-group create \\ --origin-group-name ${ AZ_USER } -afd-og \\ --probe-path '/' \\ --probe-protocol HTTP \\ --probe-request-type HEAD \\ --profile-name ${ AZ_USER } -afd- ${ UNIQUE } \\ --resource-group ${ AZ_RG } \\ --probe-interval-in-seconds 120 \\ --sample-size 4 \\ --successful-samples-required 3 \\ --additional-latency-in-milliseconds 50 Now that we have an origin group, we'll create an Azure Front Door origin in the origin group that will point to the ARO internal load balancer. To do so, run the following command: az afd origin create \\ --enable-private-link true \\ --private-link-resource ${ PL_ID } \\ --private-link-location ${ AZ_LOCATION } \\ --private-link-request-message 'Private link service from AFD' \\ --weight 1000 \\ --priority 1 \\ --http-port 80 \\ --https-port 443 \\ --origin-group-name ${ AZ_USER } -afd-og \\ --enabled-state Enabled \\ --host-name ${ LBCONFIG_IP } \\ --origin-name ${ AZ_USER } -afd-origin \\ --profile-name ${ AZ_USER } -afd- ${ UNIQUE } \\ --resource-group ${ AZ_RG } \\ --origin-host-header app. ${ AZ_USER } .ws.mobb.cloud Interested in learning more about Azure Front Door origins and origin groups, click here to read the Azure documentation . Next, we need to approve the Private Link connection between Azure Front Door and your Azure Red Hat OpenShift (ARO). To do so, run the following command: az network private-endpoint-connection approve \\ --description 'Approved' \\ --id $( az network private-link-service show \\ -n ${ AZ_USER } -pls -g ${ AZ_RG } --query \\ 'privateEndpointConnections[0].id' -o tsv ) Now, we need to add your custom domain to Azure Front Door. For this workshop, your custom domain will be your username.ws.mobb.cloud (for example, user0 will use user0.ws.mobb.cloud). To do so, run the following command: az afd custom-domain create \\ --certificate-type ManagedCertificate \\ --custom-domain-name \"app\" \\ --host-name \"app. ${ AZ_USER } .ws.mobb.cloud\" \\ --minimum-tls-version TLS12 \\ --profile-name ${ AZ_USER } -afd- ${ UNIQUE } \\ --resource-group ${ AZ_RG } Do note, this step takes about 5 minutes to propagate to the various global Azure endpoints. Once we've added our custom domain to Azure Front Door, we now need to validate that we control it. To do so, we'll add a validation token to the domain in the form of a TXT record. To do so, run the following command: az network dns record-set txt add-record \\ -g ${ AZ_RG } \\ -z ${ AZ_USER } .ws.mobb.cloud \\ -n _dnsauth.app \\ --value $( az afd custom-domain show -g ${ AZ_RG } \\ --profile-name ${ AZ_USER } -afd- ${ UNIQUE } \\ --custom-domain-name \"app\" \\ --query \"validationProperties.validationToken\" ) \\ --record-set-name _dnsauth.app Now, we can check if the domain has been validated by Azure Front Door by running the following command, but do note it can take several minutes for Azure Front Door to validate your domain. To do so, run the following watch command: watch \"az afd custom-domain list -g ${ AZ_RG } \\ --profile-name ${ AZ_USER } -afd- ${ UNIQUE } \\ --query '[? contains(hostName, \\`app. ${ AZ_USER } .ws.mobb.cloud\\`)].domainValidationState'\" Info Watch will refresh the output of a command every second. Hit CTRL and c on your keyboard to exit the watch command when you're ready to move on to the next part of the workshop. When the output of watch returns Approved , you are safe to proceed to the next step. Next, we need to create a route to connect our endpoint to our origin group. To do so, run the following command: az afd route create \\ --endpoint-name ${ AZ_USER } -ilb- ${ UNIQUE } \\ --forwarding-protocol HttpOnly \\ --https-redirect Enabled \\ --origin-group ${ AZ_USER } -afd-og \\ --route-name ${ AZ_USER } -afd-route \\ --supported-protocols Https \\ --custom-domains app \\ --profile-name ${ AZ_USER } -afd- ${ UNIQUE } \\ --resource-group ${ AZ_RG } Once your domain has been successfully validated and your route has been created, you'll need to create a CNAME record in your custom domain that points to the Azure Front Door endpoint. To do so, run the following command: az network dns record-set cname set-record \\ -g ${ AZ_RG } \\ -z ${ AZ_USER } .ws.mobb.cloud \\ -n \"app\" \\ -c $( az afd endpoint show -g ${ AZ_RG } \\ --profile-name ${ AZ_USER } -afd- ${ UNIQUE } \\ --endpoint-name ${ AZ_USER } -ilb- ${ UNIQUE } \\ --query \"hostName\" -o tsv ) Congratulations! You've successfully configured Azure Front Door!","title":"Configure"},{"location":"ops/afd/configure/#configure-azure-front-door","text":"Azure Front Door is Microsoft\u2019s Content Delivery Network (CDN) which provides a fast, reliable, and secure connection between your users and your applications\u2019 content. Azure Front Door delivers your content using the Microsoft\u2019s global edge network with hundreds of global and local POPs distributed around the world. Azure Front Door allows you to privately connect to your Azure Red Hat OpenShift (ARO) cluster using Azure Private Link. This helps to protect your apps from malicious actors and allows you to embrace a zero-trust access model. To begin, we first need to get the name of the vNet that ARO is in. To do so, run the following command: export VNET_NAME = $( az network vnet list \\ -g ${ AZ_RG } --query '[0].name' -o tsv ) While we have a resource group that contains the Azure Red Hat OpenShift (ARO) cluster object, the ARO service itself creates a separate resource group that is fully controlled by the ARO service. This resource group contains all the virtual machines, storage accounts, load balancers, and more that ARO needs to function. To identify that resource group, run the following command: export CLUSTER_RG = $( az aro show -n ${ AZ_ARO } \\ -g ${ AZ_RG } --query 'clusterProfile.resourceGroupId' -o tsv | cut -d/ -f5 ) echo \"ARO Cluster RG: ${ CLUSTER_RG } \" Since Azure Front Door connects to your Azure Red Hat OpenShift (ARO) cluster via Azure Private Link, we need to get a few pieces of information so we can configure the Private Link. To do so, run the following commands: export WORKER_SUBNET_ID = $( az aro show -n ${ AZ_ARO } \\ -g ${ AZ_RG } --query 'workerProfiles[0].subnetId' -o tsv ) echo \"Worker Subnet ID: ${ WORKER_SUBNET_ID } \" export INTERNAL_LBNAME = $( az network lb list -g ${ CLUSTER_RG } \\ --query \"[? contains(name, 'internal')].name\" -o tsv ) echo \"LB Name: ${ INTERNAL_LBNAME } \" export LBCONFIG_ID = $( az network lb frontend-ip list -g ${ CLUSTER_RG } \\ --lb-name ${ INTERNAL_LBNAME } --query \\ \"[? contains(subnet.id,' ${ WORKER_SUBNET_ID } ')].id\" -o tsv ) echo \"LB ID: ${ LBCONFIG_ID } \" export LBCONFIG_IP = $( az network lb frontend-ip list -g ${ CLUSTER_RG } \\ --lb-name ${ INTERNAL_LBNAME } --query \\ \"[? contains(subnet.id,' ${ WORKER_SUBNET_ID } ')].privateIpAddress\" \\ -o tsv ) echo \"LB IP: ${ LBCONFIG_IP } \" Now that we have all the required information stored in our environment variables, we can begin the process of creating the Azure Front Door service and its associated dependencies. First, we will create an Azure Private Link service that will allow Azure Front Door to connect to your Azure Red Hat OpenShift cluster. To do so, run the following command: az network private-link-service create \\ --name ${ AZ_USER } -pls \\ --resource-group ${ AZ_RG } \\ --private-ip-address-version IPv4 \\ --private-ip-allocation-method Dynamic \\ --vnet-name ${ AZ_USER } -vnet \\ --subnet $( echo ${ WORKER_SUBNET_ID } | sed 's/.*\\///' ) \\ --lb-frontend-ip-configs ${ LBCONFIG_ID } Once the Private Link service has been created, let's grab the ID and store it for future use. To do so, run the following command: PL_ID = $( az network private-link-service show \\ -n ${ AZ_USER } -pls -g ${ AZ_RG } --query 'id' -o tsv ) echo \"PrivateLink ID: ${ PL_ID } \" Next, let's create an instance of Azure Front Door. To do so, run the following command: az afd profile create \\ --resource-group ${ AZ_RG } \\ --profile-name ${ AZ_USER } -afd- ${ UNIQUE } \\ --sku Premium_AzureFrontDoor Once the Front Door instance has been created, let's grab the ID and storage it for future use. To do so, run the following command: export AFD_ID = $( az afd profile show -g ${ AZ_RG } \\ --profile-name ${ AZ_USER } -afd- ${ UNIQUE } --query 'id' -o tsv ) echo \"Front Door ID: ${ AFD_ID } \" Next, we need to create an Azure Front Door endpoint for the ARO internal load balancer. This will allow Azure Front Door to send traffic directly to the ARO Load Balancer. To do so, run the following command: az afd endpoint create \\ --resource-group ${ AZ_RG } \\ --enabled-state Enabled \\ --endpoint-name ${ AZ_USER } -ilb- ${ UNIQUE } \\ --profile-name ${ AZ_USER } -afd- ${ UNIQUE } Now we need to create an Azure Front Door origin group that will point to the ARO internal load balancer. An origin group in Azure Front Door refers to a set of origins, which we'll create in just a moment. To do so, run the following command: az afd origin-group create \\ --origin-group-name ${ AZ_USER } -afd-og \\ --probe-path '/' \\ --probe-protocol HTTP \\ --probe-request-type HEAD \\ --profile-name ${ AZ_USER } -afd- ${ UNIQUE } \\ --resource-group ${ AZ_RG } \\ --probe-interval-in-seconds 120 \\ --sample-size 4 \\ --successful-samples-required 3 \\ --additional-latency-in-milliseconds 50 Now that we have an origin group, we'll create an Azure Front Door origin in the origin group that will point to the ARO internal load balancer. To do so, run the following command: az afd origin create \\ --enable-private-link true \\ --private-link-resource ${ PL_ID } \\ --private-link-location ${ AZ_LOCATION } \\ --private-link-request-message 'Private link service from AFD' \\ --weight 1000 \\ --priority 1 \\ --http-port 80 \\ --https-port 443 \\ --origin-group-name ${ AZ_USER } -afd-og \\ --enabled-state Enabled \\ --host-name ${ LBCONFIG_IP } \\ --origin-name ${ AZ_USER } -afd-origin \\ --profile-name ${ AZ_USER } -afd- ${ UNIQUE } \\ --resource-group ${ AZ_RG } \\ --origin-host-header app. ${ AZ_USER } .ws.mobb.cloud Interested in learning more about Azure Front Door origins and origin groups, click here to read the Azure documentation . Next, we need to approve the Private Link connection between Azure Front Door and your Azure Red Hat OpenShift (ARO). To do so, run the following command: az network private-endpoint-connection approve \\ --description 'Approved' \\ --id $( az network private-link-service show \\ -n ${ AZ_USER } -pls -g ${ AZ_RG } --query \\ 'privateEndpointConnections[0].id' -o tsv ) Now, we need to add your custom domain to Azure Front Door. For this workshop, your custom domain will be your username.ws.mobb.cloud (for example, user0 will use user0.ws.mobb.cloud). To do so, run the following command: az afd custom-domain create \\ --certificate-type ManagedCertificate \\ --custom-domain-name \"app\" \\ --host-name \"app. ${ AZ_USER } .ws.mobb.cloud\" \\ --minimum-tls-version TLS12 \\ --profile-name ${ AZ_USER } -afd- ${ UNIQUE } \\ --resource-group ${ AZ_RG } Do note, this step takes about 5 minutes to propagate to the various global Azure endpoints. Once we've added our custom domain to Azure Front Door, we now need to validate that we control it. To do so, we'll add a validation token to the domain in the form of a TXT record. To do so, run the following command: az network dns record-set txt add-record \\ -g ${ AZ_RG } \\ -z ${ AZ_USER } .ws.mobb.cloud \\ -n _dnsauth.app \\ --value $( az afd custom-domain show -g ${ AZ_RG } \\ --profile-name ${ AZ_USER } -afd- ${ UNIQUE } \\ --custom-domain-name \"app\" \\ --query \"validationProperties.validationToken\" ) \\ --record-set-name _dnsauth.app Now, we can check if the domain has been validated by Azure Front Door by running the following command, but do note it can take several minutes for Azure Front Door to validate your domain. To do so, run the following watch command: watch \"az afd custom-domain list -g ${ AZ_RG } \\ --profile-name ${ AZ_USER } -afd- ${ UNIQUE } \\ --query '[? contains(hostName, \\`app. ${ AZ_USER } .ws.mobb.cloud\\`)].domainValidationState'\" Info Watch will refresh the output of a command every second. Hit CTRL and c on your keyboard to exit the watch command when you're ready to move on to the next part of the workshop. When the output of watch returns Approved , you are safe to proceed to the next step. Next, we need to create a route to connect our endpoint to our origin group. To do so, run the following command: az afd route create \\ --endpoint-name ${ AZ_USER } -ilb- ${ UNIQUE } \\ --forwarding-protocol HttpOnly \\ --https-redirect Enabled \\ --origin-group ${ AZ_USER } -afd-og \\ --route-name ${ AZ_USER } -afd-route \\ --supported-protocols Https \\ --custom-domains app \\ --profile-name ${ AZ_USER } -afd- ${ UNIQUE } \\ --resource-group ${ AZ_RG } Once your domain has been successfully validated and your route has been created, you'll need to create a CNAME record in your custom domain that points to the Azure Front Door endpoint. To do so, run the following command: az network dns record-set cname set-record \\ -g ${ AZ_RG } \\ -z ${ AZ_USER } .ws.mobb.cloud \\ -n \"app\" \\ -c $( az afd endpoint show -g ${ AZ_RG } \\ --profile-name ${ AZ_USER } -afd- ${ UNIQUE } \\ --endpoint-name ${ AZ_USER } -ilb- ${ UNIQUE } \\ --query \"hostName\" -o tsv ) Congratulations! You've successfully configured Azure Front Door!","title":"Configure Azure Front Door"},{"location":"ops/afd/private-ingress/","text":"Create a Private Ingress Controller # As you may notice, the clusters that we have provisioned for this workshop are internet accessible. We refer to this as a \"public\" cluster, where the cluster API and default ingress controller are exposed to the Internet. We do this to eliminate complex networking in our workshop environments. To simulate a private environment for our applications though, we need to create a second ingress controller that is only exposed to the private network of our cluster. To begin, we'll need to gather a few pieces of information from the existing default ingress controller. To do so, run the following commands: export CERT = $( oc get IngressController default -n openshift-ingress-operator -o jsonpath = '{.spec.defaultCertificate.name}' ) export DOMAIN = $( oc get IngressController default -n openshift-ingress-operator -o jsonpath = '{.status.domain}' | sed \"s/apps/apps-private/g\" ) Next, we'll apply the following YAML file to our cluster to create a second ingress controller by running the following command: cat << EOF | oc apply -f - apiVersion: v1 items: - apiVersion: operator.openshift.io/v1 kind: IngressController metadata: finalizers: - ingresscontroller.operator.openshift.io/finalizer-ingresscontroller generation: 2 name: private namespace: openshift-ingress-operator spec: clientTLS: clientCA: name: \"\" clientCertificatePolicy: \"\" defaultCertificate: name: ${CERT} httpCompression: {} httpEmptyRequestsPolicy: Respond httpErrorCodePages: name: \"\" replicas: 2 tuningOptions: {} domain: ${DOMAIN} endpointPublishingStrategy: loadBalancer: scope: Internal type: LoadBalancerService observedGeneration: 2 selector: ingresscontroller.operator.openshift.io/deployment-ingresscontroller=private tlsProfile: ciphers: - ECDHE-ECDSA-AES128-GCM-SHA256 - ECDHE-RSA-AES128-GCM-SHA256 - ECDHE-ECDSA-AES256-GCM-SHA384 - ECDHE-RSA-AES256-GCM-SHA384 - ECDHE-ECDSA-CHACHA20-POLY1305 - ECDHE-RSA-CHACHA20-POLY1305 - DHE-RSA-AES128-GCM-SHA256 - DHE-RSA-AES256-GCM-SHA384 - TLS_AES_128_GCM_SHA256 - TLS_AES_256_GCM_SHA384 - TLS_CHACHA20_POLY1305_SHA256 minTLSVersion: VersionTLS12 kind: List EOF Once this has been done, we need to check to make sure the private ingress controller was created. To do so, run the following command: oc get IngressController private -n openshift-ingress-operator -o jsonpath = '{.status.conditions}' | jq You'll see a lot of output, but the main thing you're looking for is that the deployment is available: [ ... ] { \"lastTransitionTime\" : \"2022-11-15T04:02:05Z\" , \"message\" : \"The deployment has Available status condition set to True\" , \"reason\" : \"DeploymentAvailable\" , \"status\" : \"True\" , \"type\" : \"DeploymentAvailable\" }, [ ... ]","title":"Private ingress"},{"location":"ops/afd/private-ingress/#create-a-private-ingress-controller","text":"As you may notice, the clusters that we have provisioned for this workshop are internet accessible. We refer to this as a \"public\" cluster, where the cluster API and default ingress controller are exposed to the Internet. We do this to eliminate complex networking in our workshop environments. To simulate a private environment for our applications though, we need to create a second ingress controller that is only exposed to the private network of our cluster. To begin, we'll need to gather a few pieces of information from the existing default ingress controller. To do so, run the following commands: export CERT = $( oc get IngressController default -n openshift-ingress-operator -o jsonpath = '{.spec.defaultCertificate.name}' ) export DOMAIN = $( oc get IngressController default -n openshift-ingress-operator -o jsonpath = '{.status.domain}' | sed \"s/apps/apps-private/g\" ) Next, we'll apply the following YAML file to our cluster to create a second ingress controller by running the following command: cat << EOF | oc apply -f - apiVersion: v1 items: - apiVersion: operator.openshift.io/v1 kind: IngressController metadata: finalizers: - ingresscontroller.operator.openshift.io/finalizer-ingresscontroller generation: 2 name: private namespace: openshift-ingress-operator spec: clientTLS: clientCA: name: \"\" clientCertificatePolicy: \"\" defaultCertificate: name: ${CERT} httpCompression: {} httpEmptyRequestsPolicy: Respond httpErrorCodePages: name: \"\" replicas: 2 tuningOptions: {} domain: ${DOMAIN} endpointPublishingStrategy: loadBalancer: scope: Internal type: LoadBalancerService observedGeneration: 2 selector: ingresscontroller.operator.openshift.io/deployment-ingresscontroller=private tlsProfile: ciphers: - ECDHE-ECDSA-AES128-GCM-SHA256 - ECDHE-RSA-AES128-GCM-SHA256 - ECDHE-ECDSA-AES256-GCM-SHA384 - ECDHE-RSA-AES256-GCM-SHA384 - ECDHE-ECDSA-CHACHA20-POLY1305 - ECDHE-RSA-CHACHA20-POLY1305 - DHE-RSA-AES128-GCM-SHA256 - DHE-RSA-AES256-GCM-SHA384 - TLS_AES_128_GCM_SHA256 - TLS_AES_256_GCM_SHA384 - TLS_CHACHA20_POLY1305_SHA256 minTLSVersion: VersionTLS12 kind: List EOF Once this has been done, we need to check to make sure the private ingress controller was created. To do so, run the following command: oc get IngressController private -n openshift-ingress-operator -o jsonpath = '{.status.conditions}' | jq You'll see a lot of output, but the main thing you're looking for is that the deployment is available: [ ... ] { \"lastTransitionTime\" : \"2022-11-15T04:02:05Z\" , \"message\" : \"The deployment has Available status condition set to True\" , \"reason\" : \"DeploymentAvailable\" , \"status\" : \"True\" , \"type\" : \"DeploymentAvailable\" }, [ ... ]","title":"Create a Private Ingress Controller"},{"location":"ops/arc/integration/","text":"Introduction # Azure Arc is a bridge that extends the Azure platform to help you build applications and services on top of Azure Red Hat OpenShift. In this section of the workshop, we will integrate our ARO cluster with Azure Arc. When you connect an OpenShift cluster with Azure Arc, it will: Be represented in Azure Resource Manager with a unique ID Receive tags just like any other Azure resource Azure Arc for OpenShift supports the following use cases for connected clusters: Deploy applications and apply configuration using GitOps-based configuration management. View and monitor your clusters using Azure Monitor for containers. Enforce threat protection using Microsoft Defender for Kubernetes. Apply policy definitions using Azure Policy for Kubernetes. Connect Azure Arc with your ARO cluster # First, we need to connect our ARO cluster to Azure Arc. To do so, run the following command. az connectedk8s connect --resource-group \" ${ AZ_RG } \" --name \" ${ AZ_ARO } \" \\ --distribution openshift --infrastructure auto This command takes about 5 minutes to complete. Once completed, your output will look something like this: [ ... ] \"infrastructure\" : \"azure\" , \"kubernetesVersion\" : null , \"lastConnectivityTime\" : null , \"location\" : \"eastus\" , \"managedIdentityCertificateExpirationTime\" : null , \"name\" : \"user1-cluster\" , \"offering\" : null , \"provisioningState\" : \"Succeeded\" , \"resourceGroup\" : \"user1-rg\" , [ ... ] Your cluster will also be visible in the Azure Portal under the Kubernetes - Azure Arc blade. Next, we need to grant elevated permissions to the Azure Arc service account. To do so, run the following command: oc adm policy add-scc-to-user privileged \\ system:serviceaccount:azure-arc:azure-arc-kube-aad-proxy-sa In order for the permissions to take effect we need to restart the kube-aad-proxy deployment. To do so, run the following command: oc -n azure-arc rollout restart deployment kube-aad-proxy After a few moments, run the following command to see the various Azure Arc pods running: oc -n azure-arc get pods Your output will look very similar to: NAME READY STATUS RESTARTS AGE cluster-metadata-operator-77895ddcd7-56v5h 2 /2 Running 0 8m18s clusterconnect-agent-84dff79cd9-zpwd2 3 /3 Running 0 8m18s clusteridentityoperator-67c69db6db-h2wgb 2 /2 Running 0 8m18s config-agent-5f4b45884c-b9gv7 2 /2 Running 0 8m18s controller-manager-8565bfd849-bk58z 2 /2 Running 0 8m18s extension-manager-5bddf75868-rqlxx 2 /2 Running 0 8m18s flux-logs-agent-576bfc88c6-t56ht 1 /1 Running 0 8m18s kube-aad-proxy-6457f7966-jbzz2 2 /2 Running 0 8m18s kube-aad-proxy-69869fd7f6-6x9xq 1 /2 Running 0 10s metrics-agent-5467b679bf-l2r8c 2 /2 Running 0 8m18s resource-sync-agent-6c67b5d58-bzbxt 2 /2 Running 0 8m18s Next, let's check the status of the cluster from Azure Arc. To do so, run the following command: az connectedk8s list --resource-group ${ AZ_RG } --output table Your output will look very similar to: Name Location ResourceGroup ------------- ---------- --------------- user1-cluster eastus user1-rg","title":"Introduction"},{"location":"ops/arc/integration/#introduction","text":"Azure Arc is a bridge that extends the Azure platform to help you build applications and services on top of Azure Red Hat OpenShift. In this section of the workshop, we will integrate our ARO cluster with Azure Arc. When you connect an OpenShift cluster with Azure Arc, it will: Be represented in Azure Resource Manager with a unique ID Receive tags just like any other Azure resource Azure Arc for OpenShift supports the following use cases for connected clusters: Deploy applications and apply configuration using GitOps-based configuration management. View and monitor your clusters using Azure Monitor for containers. Enforce threat protection using Microsoft Defender for Kubernetes. Apply policy definitions using Azure Policy for Kubernetes.","title":"Introduction"},{"location":"ops/arc/integration/#connect-azure-arc-with-your-aro-cluster","text":"First, we need to connect our ARO cluster to Azure Arc. To do so, run the following command. az connectedk8s connect --resource-group \" ${ AZ_RG } \" --name \" ${ AZ_ARO } \" \\ --distribution openshift --infrastructure auto This command takes about 5 minutes to complete. Once completed, your output will look something like this: [ ... ] \"infrastructure\" : \"azure\" , \"kubernetesVersion\" : null , \"lastConnectivityTime\" : null , \"location\" : \"eastus\" , \"managedIdentityCertificateExpirationTime\" : null , \"name\" : \"user1-cluster\" , \"offering\" : null , \"provisioningState\" : \"Succeeded\" , \"resourceGroup\" : \"user1-rg\" , [ ... ] Your cluster will also be visible in the Azure Portal under the Kubernetes - Azure Arc blade. Next, we need to grant elevated permissions to the Azure Arc service account. To do so, run the following command: oc adm policy add-scc-to-user privileged \\ system:serviceaccount:azure-arc:azure-arc-kube-aad-proxy-sa In order for the permissions to take effect we need to restart the kube-aad-proxy deployment. To do so, run the following command: oc -n azure-arc rollout restart deployment kube-aad-proxy After a few moments, run the following command to see the various Azure Arc pods running: oc -n azure-arc get pods Your output will look very similar to: NAME READY STATUS RESTARTS AGE cluster-metadata-operator-77895ddcd7-56v5h 2 /2 Running 0 8m18s clusterconnect-agent-84dff79cd9-zpwd2 3 /3 Running 0 8m18s clusteridentityoperator-67c69db6db-h2wgb 2 /2 Running 0 8m18s config-agent-5f4b45884c-b9gv7 2 /2 Running 0 8m18s controller-manager-8565bfd849-bk58z 2 /2 Running 0 8m18s extension-manager-5bddf75868-rqlxx 2 /2 Running 0 8m18s flux-logs-agent-576bfc88c6-t56ht 1 /1 Running 0 8m18s kube-aad-proxy-6457f7966-jbzz2 2 /2 Running 0 8m18s kube-aad-proxy-69869fd7f6-6x9xq 1 /2 Running 0 10s metrics-agent-5467b679bf-l2r8c 2 /2 Running 0 8m18s resource-sync-agent-6c67b5d58-bzbxt 2 /2 Running 0 8m18s Next, let's check the status of the cluster from Azure Arc. To do so, run the following command: az connectedk8s list --resource-group ${ AZ_RG } --output table Your output will look very similar to: Name Location ResourceGroup ------------- ---------- --------------- user1-cluster eastus user1-rg","title":"Connect Azure Arc with your ARO cluster"},{"location":"ops/arc/key-vault/","text":"The Azure Key Vault Provider for Secrets Store CSI Driver allows for the integration of Azure Key Vault as a secrets store with an Azure Red Hat OpenShift cluster via a CSI volume. For Azure Arc-enabled ARO clusters, you can install the Azure Key Vault Secrets Provider extension to fetch secrets. First, install the required Azure CLI extension. To do so, run the following command: az k8s-extension create --cluster-name \" ${ AZ_ARO } \" --resource-group \" ${ AZ_RG } \" \\ --cluster-type connectedClusters --name akvsecretsprovider \\ --extension-type Microsoft.AzureKeyVaultSecretsProvider This command takes about 5 minutes to complete. Once completed, your output will look something like this: [ ... ] \"installedVersion\" : null , \"name\" : \"akvsecretsprovider\" , \"packageUri\" : null , \"provisioningState\" : \"Succeeded\" , \"releaseTrain\" : \"Stable\" , \"resourceGroup\" : \"user1-rg\" , [ ... ] Next, let's create a namespace (also known as a project in OpenShift). To do so, run the following command: oc new-project keyvault-ex In order to use Azure Key Vault, we will need to create a vault and a secret in the cooresponding vault. To do so, run the following command: az keyvault create -n \" ${ AZ_USER } -vault\" \\ --resource-group \" ${ AZ_RG } \" -l eastus az keyvault secret set --vault-name \" ${ AZ_USER } -vault\" \\ -n DemoSecret --value MyExampleSecret Next, let's get the necessary information for the Azure Key Vault CSI Driver to authenticate against Azure. To do so, run the following command: export AZURE_TENANT_ID = \" $( az account show -o tsv --query tenantId ) \" echo \"Tenant ID: ${ AZURE_TENANT_ID } \" export AZURE_CLIENT_ID = \" $( oc get secret azure-credentials -n kube-system -o json | jq -r .data.azure_client_id | base64 --decode ) \" echo \"Client ID: ${ AZURE_CLIENT_ID } \" export AZURE_CLIENT_SECRET = \" $( oc get secret azure-credentials -n kube-system -o json | jq -r .data.azure_client_secret | base64 --decode ) \" echo \"Secret (Sensitive Information): ${ AZURE_CLIENT_SECRET } \" Next, let's grant our cluster the ability to access the key vault. To do so, run the following command: OID = \" $( az ad sp show --id ${ AZURE_CLIENT_ID } --query '{id:id}' -o tsv ) \" az keyvault set-policy --name \" ${ AZ_USER } -vault\" \\ --object-id \" ${ OID } \" \\ --secret-permissions get Next, create a secret for the Azure Key Vault CSI Driver to use to authenticate against Azure. To do so, run the following command: oc -n keyvault-ex create secret generic secrets-store-creds \\ --from-literal clientid = \" ${ AZURE_CLIENT_ID } \" \\ --from-literal clientsecret = \" ${ AZURE_CLIENT_SECRET } \" oc -n keyvault-ex label secret secrets-store-creds secrets-store.csi.k8s.io/used = true Next, create a SecretProviderClass for your Key Vault resource inside the cluster. cat << EOF | oc apply -f - apiVersion: secrets-store.csi.x-k8s.io/v1 kind: SecretProviderClass metadata: name: akvprovider-demo namespace: keyvault-ex spec: provider: azure parameters: usePodIdentity: \"false\" keyvaultName: \"${AZ_USER}-vault\" objects: | array: - | objectName: DemoSecret objectType: secret objectVersion: \"\" tenantId: \"${AZURE_TENANT_ID}\" EOF Now, let's create a pod that can access the secret from Azure Key Vault. To do so, run the following command: cat << EOF | oc apply -f - kind : Pod apiVersion : v1 metadata : name : secret-store-pod namespace : keyvault-ex spec : containers : - name : busybox image : k8s.gcr.io/e2e-test-images/busybox:1.29 command : - \"/bin/sleep\" - \"10000\" volumeMounts : - name : secrets-store-inline mountPath : \"/mnt/secrets-store\" readOnly : true volumes : - name : secrets-store-inline csi : driver : secrets-store.csi.k8s.io readOnly : true volumeAttributes : secretProviderClass : \"akvprovider-demo\" nodePublishSecretRef : name : secrets-store-creds EOF After the pod starts, the mounted secret from the Azure Key Vault specified in your deployment YAML is available. To demonstrate this, let's run the following two quick oc exec commands: ## show secrets held in secrets-store oc exec secret-store-pod -- ls /mnt/secrets-store/DemoSecret ## print a test secret 'DemoSecret' held in secrets-store oc exec secret-store-pod -- cat /mnt/secrets-store/DemoSecret The output of this command will return: /mnt/secrets-store/DemoSecret MyExampleSecret Congratulations! You've successfully demonstrated using Azure Arc with your Azure Red Hat OpenShift cluster for observability and key vault.","title":"Key vault"},{"location":"ops/arc/observability/","text":"In order to see ARO resources (such as namespaces, pods, services, etc.) inside Azure Arc, you need to create a service account and provide the token to Azure Arc. To do so, run the following command: oc -n azure-arc create serviceaccount azure-arc-observability oc create clusterrolebinding azure-arc-observability-rb --clusterrole cluster-admin --serviceaccount azure-arc:azure-arc-observability Next, we need to create a secret to store our token. To do so, run the following command: cat <<EOF | oc apply -f - apiVersion: v1 kind: Secret metadata: name: azure-arc-observability-secret namespace: azure-arc annotations: kubernetes.io/service-account.name: azure-arc-observability type: kubernetes.io/service-account-token EOF Then, we can obtain the token for Azure Arc. To do so, run the following command: oc -n azure-arc get secret azure-arc-observability-secret -o jsonpath = '{$.data.token}' | base64 -d Make sure you copy this value, as you'll need it in a moment. Next, In the Azure Portal search for \"Azure Arc Kubernetes\" and click on the Kubernetes - Azure Arc option. Ensure that you DO NOT click on Azure Arc Kubernetes clusters! Select your cluster name from the page. Then, select Namespaces from the left side menu and paste the token from step three in the Service account bearer token field. You can now see and explore through the following OpenShift resources inside the Azure Arc portal: Namespaces Workloads Services and Ingress Storage Configurations","title":"Observability"},{"location":"ops/aso/app/","text":"Introduction # Applications running on Azure Red Hat OpenShift (ARO) often use other Azure services including databases, caching, message queues, and storage. Using ASO, these services can be managed directly inside the cluster. In this task we will deploy an Azure Cache for Redis that can be used by an application running on OpenShift. Azure Cache for Redis is a fully managed, in-memory cache that enables high-performance and scalable architectures. The voting app that will be deployed consists of a front end web-app that uses an Azure Cache for Redis instance to provide persistence of votes received for Cats and Dogs. The application interface has been built using Python and Flask. Deploy an Azure Cache for Redis instance # First, let's create a namespace (also known as a project in OpenShift). To do so, run the following command: oc new-project redis-ex Next, let's inherit our existing Azure Resource Group to hold Azure resources that we create with ASO. To do so, run the following commmand: cat <<EOF | oc apply -f - apiVersion : resources.azure.com/v1beta20200601 kind : ResourceGroup metadata : name : \"${AZ_RG}\" namespace : redis-ex annotations : serviceoperator.azure.com/reconcile-policy : skip spec : location : eastus EOF Let's verify that our Azure Resource Group has been successfully inherited. To do so, run the following command: oc get resourcegroup.resources.azure.com/ ${ AZ_RG } You should receive output that shows your resource group is Ready and Succeeded , similar to this: NAME READY REASON MESSAGE user1-rg True Succeeded Next, we need to deploy the Redis cache itself. To do so, run the following command: cat <<EOF | oc apply -f - apiVersion : cache.azure.com/v1beta20201201 kind : Redis metadata : name : redis-${UNIQUE} namespace : redis-ex spec : location : eastus owner : name : \"${AZ_RG}\" sku : family : C name : Basic capacity : 0 enableNonSslPort : true redisConfiguration : maxmemory-delta : \"10\" maxmemory-policy : allkeys-lru redisVersion : \"6\" operatorSpec : secrets : primaryKey : name : redis-secret key : primaryKey secondaryKey : name : redis-secret key : secondaryKey hostName : name : redis-secret key : hostName port : name : redis-secret key : port EOF This will take a few minutes to complete (sometimes up to 10 minutes). It is not unusual for there to be a lab between a resource being created in ASO and showing up in the Azure Portal. To monitor the creation process, run the following command: watch ~/bin/oc -n redis-ex get redis Your output will look like this: NAME READY SEVERITY REASON MESSAGE redis-3686 False Info Reconciling The resource is in the process of being reconciled by the operator Eventually, the result will show: NAME READY SEVERITY REASON MESSAGE redis-3686 True Succeeded Info Watch will refresh the output of a command every second. Hit CTRL and c on your keyboard to exit the watch command when you're ready to move on to the next part of the workshop. (Optional) If you'd like to monitor the creation of the resource in the Azure Portal, you can search for \"Redis\" in the search bar. Once the Redis instance has successfully deployed, you can move on to deploying the voting app. Deploy the voting app # The Azure Voting App will be deployed from a pre-built container that is stored in the public Microsoft Azure Container Registry. It's environment variables are configured to use the URL of the Redis cache deployed in the last step, and a Kubernetes Secret that was created as part of the cache deployment. Next, let's deploy our application and associated resources that will use our newly created Redis instance. To do so, run the following command: cat <<EOF | oc apply -f - apiVersion : apps/v1 kind : Deployment metadata : name : azure-vote-front namespace : redis-ex spec : replicas : 1 selector : matchLabels : app : azure-vote-front template : metadata : labels : app : azure-vote-front spec : containers : - name : azure-vote-front image : aroworkshop.azurecr.io/azure-vote:latest resources : requests : cpu : 100m memory : 128Mi limits : cpu : 250m memory : 256Mi ports : - containerPort : 8080 env : - name : REDIS valueFrom : secretKeyRef : name : redis-secret key : hostName - name : REDIS_NAME value : \"redis-${UNIQUE}\" - name : REDIS_PWD valueFrom : secretKeyRef : name : redis-secret key : primaryKey --- apiVersion : v1 kind : Service metadata : name : azure-vote-front namespace : redis-ex spec : ports : - port : 8080 targetPort : 8080 selector : app : azure-vote-front --- apiVersion : route.openshift.io/v1 kind : Route metadata : name : azure-vote namespace : redis-ex spec : port : targetPort : 8080 to : kind : Service name : azure-vote-front weight : 100 tls : insecureEdgeTerminationPolicy : Redirect termination : edge wildcardPolicy : None EOF Next, let's validate that the application has been deployed. To do so, run the following command: oc -n redis-ex get pod -l app = azure-vote-front Your output will look something like this: NAME READY STATUS RESTARTS AGE azure-vote-front-6b78d59df4-hbtkt 1 /1 Running 0 2m4s Once you see \"1/1\" and \"Running\", the application is available to access. And finally, view the voting app in your browser. To do so, get the route of your application by running the following command: oc -n redis-ex get route azure-vote -o jsonpath = '{.spec.host}' Then visit the URL presented in a new tab in your web browser (using HTTPS). For example, your output will look something similar to: azure-vote-redis-ex.apps.ce7l3kf6.eastus.aroapp.io In that case, you'd visit https://azure-vote-redis-ex.apps.ce7l3kf6.eastus.aroapp.io in your browser. Congratulations! You've successfully demonstrated the ability to deploy Azure resources using ASO and use those resources with applications on your ARO cluster.","title":"App"},{"location":"ops/aso/app/#introduction","text":"Applications running on Azure Red Hat OpenShift (ARO) often use other Azure services including databases, caching, message queues, and storage. Using ASO, these services can be managed directly inside the cluster. In this task we will deploy an Azure Cache for Redis that can be used by an application running on OpenShift. Azure Cache for Redis is a fully managed, in-memory cache that enables high-performance and scalable architectures. The voting app that will be deployed consists of a front end web-app that uses an Azure Cache for Redis instance to provide persistence of votes received for Cats and Dogs. The application interface has been built using Python and Flask.","title":"Introduction"},{"location":"ops/aso/app/#deploy-an-azure-cache-for-redis-instance","text":"First, let's create a namespace (also known as a project in OpenShift). To do so, run the following command: oc new-project redis-ex Next, let's inherit our existing Azure Resource Group to hold Azure resources that we create with ASO. To do so, run the following commmand: cat <<EOF | oc apply -f - apiVersion : resources.azure.com/v1beta20200601 kind : ResourceGroup metadata : name : \"${AZ_RG}\" namespace : redis-ex annotations : serviceoperator.azure.com/reconcile-policy : skip spec : location : eastus EOF Let's verify that our Azure Resource Group has been successfully inherited. To do so, run the following command: oc get resourcegroup.resources.azure.com/ ${ AZ_RG } You should receive output that shows your resource group is Ready and Succeeded , similar to this: NAME READY REASON MESSAGE user1-rg True Succeeded Next, we need to deploy the Redis cache itself. To do so, run the following command: cat <<EOF | oc apply -f - apiVersion : cache.azure.com/v1beta20201201 kind : Redis metadata : name : redis-${UNIQUE} namespace : redis-ex spec : location : eastus owner : name : \"${AZ_RG}\" sku : family : C name : Basic capacity : 0 enableNonSslPort : true redisConfiguration : maxmemory-delta : \"10\" maxmemory-policy : allkeys-lru redisVersion : \"6\" operatorSpec : secrets : primaryKey : name : redis-secret key : primaryKey secondaryKey : name : redis-secret key : secondaryKey hostName : name : redis-secret key : hostName port : name : redis-secret key : port EOF This will take a few minutes to complete (sometimes up to 10 minutes). It is not unusual for there to be a lab between a resource being created in ASO and showing up in the Azure Portal. To monitor the creation process, run the following command: watch ~/bin/oc -n redis-ex get redis Your output will look like this: NAME READY SEVERITY REASON MESSAGE redis-3686 False Info Reconciling The resource is in the process of being reconciled by the operator Eventually, the result will show: NAME READY SEVERITY REASON MESSAGE redis-3686 True Succeeded Info Watch will refresh the output of a command every second. Hit CTRL and c on your keyboard to exit the watch command when you're ready to move on to the next part of the workshop. (Optional) If you'd like to monitor the creation of the resource in the Azure Portal, you can search for \"Redis\" in the search bar. Once the Redis instance has successfully deployed, you can move on to deploying the voting app.","title":"Deploy an Azure Cache for Redis instance"},{"location":"ops/aso/app/#deploy-the-voting-app","text":"The Azure Voting App will be deployed from a pre-built container that is stored in the public Microsoft Azure Container Registry. It's environment variables are configured to use the URL of the Redis cache deployed in the last step, and a Kubernetes Secret that was created as part of the cache deployment. Next, let's deploy our application and associated resources that will use our newly created Redis instance. To do so, run the following command: cat <<EOF | oc apply -f - apiVersion : apps/v1 kind : Deployment metadata : name : azure-vote-front namespace : redis-ex spec : replicas : 1 selector : matchLabels : app : azure-vote-front template : metadata : labels : app : azure-vote-front spec : containers : - name : azure-vote-front image : aroworkshop.azurecr.io/azure-vote:latest resources : requests : cpu : 100m memory : 128Mi limits : cpu : 250m memory : 256Mi ports : - containerPort : 8080 env : - name : REDIS valueFrom : secretKeyRef : name : redis-secret key : hostName - name : REDIS_NAME value : \"redis-${UNIQUE}\" - name : REDIS_PWD valueFrom : secretKeyRef : name : redis-secret key : primaryKey --- apiVersion : v1 kind : Service metadata : name : azure-vote-front namespace : redis-ex spec : ports : - port : 8080 targetPort : 8080 selector : app : azure-vote-front --- apiVersion : route.openshift.io/v1 kind : Route metadata : name : azure-vote namespace : redis-ex spec : port : targetPort : 8080 to : kind : Service name : azure-vote-front weight : 100 tls : insecureEdgeTerminationPolicy : Redirect termination : edge wildcardPolicy : None EOF Next, let's validate that the application has been deployed. To do so, run the following command: oc -n redis-ex get pod -l app = azure-vote-front Your output will look something like this: NAME READY STATUS RESTARTS AGE azure-vote-front-6b78d59df4-hbtkt 1 /1 Running 0 2m4s Once you see \"1/1\" and \"Running\", the application is available to access. And finally, view the voting app in your browser. To do so, get the route of your application by running the following command: oc -n redis-ex get route azure-vote -o jsonpath = '{.spec.host}' Then visit the URL presented in a new tab in your web browser (using HTTPS). For example, your output will look something similar to: azure-vote-redis-ex.apps.ce7l3kf6.eastus.aroapp.io In that case, you'd visit https://azure-vote-redis-ex.apps.ce7l3kf6.eastus.aroapp.io in your browser. Congratulations! You've successfully demonstrated the ability to deploy Azure resources using ASO and use those resources with applications on your ARO cluster.","title":"Deploy the voting app"},{"location":"ops/aso/deploy/","text":"Introduction # The Azure Service Operator (ASO) is an open-source project by Microsoft. ASO gives you the ability to provision and manage Azure resources such as compute, databases, resource groups, networking, etc. as objects in Kubernetes using declarative Kubernetes manifests. Azure Service Operator is currently in BETA Azure Service Operator is in its second incarnation (v2) and is in beta. This means ASO is not fully supported and should not be used in production. In addition, at this time, ASO is not available in OperatorHub and has to be installed using Helm or raw manifests. We are using it in this workshop as a demonstration. ASO consists of: Custom Resource Definitions (CRDs) for each of the Azure services that a Kubernetes user can provision. A Kubernetes controller that manages the Azure resources represented by the user-specified Custom Resources. The controller attempts to synchronize the desired state in the user-specified Custom Resource with the actual state of that resource in Azure, creating it if it doesn't exist, updating it if it has been changed, or deleting it. We will deploy ASO on an ARO cluster to provision and manage Azure resources. To install ASO we need: An Azure Service Principal with Contributor permissions in the Azure Subscription. An Azure Service Principal is an identity created for use with applications, hosted services, and automated tools to access Azure resources. This has been pre-created for you as a part of the workshop. A cert-manager instance. ASO needs cert-manager to programmatically create self-signed certificates. Install and configure the Azure Service Operator (ASO) # Install the Cert Manager Operator # The cert-manager operator can easily be installed from the OpenShift Console OperatorHub. Return to your tab with the OpenShift Web Console. If you need to reauthenticate, follow the steps in the Access Your Cluster section. Using the menu on the left Select Operators -> OperatorHub . In the search box, search for \"cert-manager\" and click on the cert-manager Operator for Red Hat OpenShift box that has the Red Hat logo. Click on Install on the page that appears. Accept the defaults that are presented and select Install to install the operator. Allow the operator a few minutes to successfully install the cert-manager operator into the cluster. Install the Azure Service Operator (ASO) # First, let's get the necessary information for the Azure Service Operator to authenticate against Azure. To do so, run the following command: export AZURE_TENANT_ID = \" $( az account show -o tsv --query tenantId ) \" echo \"Tenant ID: ${ AZURE_TENANT_ID } \" export AZURE_SUBSCRIPTION_ID = \" $( az account show -o tsv --query id ) \" echo \"Subscription ID: ${ AZURE_SUBSCRIPTION_ID } \" export AZURE_CLIENT_ID = \" $( oc get secret azure-credentials -n kube-system -o json | jq -r .data.azure_client_id | base64 --decode ) \" echo \"Client ID: ${ AZURE_CLIENT_ID } \" export AZURE_CLIENT_SECRET = \" $( oc get secret azure-credentials -n kube-system -o json | jq -r .data.azure_client_secret | base64 --decode ) \" echo \"Secret (Sensitive Information): ${ AZURE_CLIENT_SECRET } \" Next, let's install the latest Azure Service Operator (v2) using the Helm Chart that Microsoft provides. To do so, run the following command: helm repo add aso2 \\ https://raw.githubusercontent.com/Azure/azure-service-operator/main/v2/charts helm repo update helm upgrade --install --devel aso2 aso2/azure-service-operator \\ --create-namespace \\ --namespace = azureserviceoperator-system \\ --set azureSubscriptionID = \" ${ AZURE_SUBSCRIPTION_ID } \" \\ --set azureTenantID = \" ${ AZURE_TENANT_ID } \" \\ --set azureClientID = \" ${ AZURE_CLIENT_ID } \" \\ --set azureClientSecret = \" ${ AZURE_CLIENT_SECRET } \" Within a minute or less, you should see output that looks similar to: \"aso2\" has been added to your repositories Hang tight while we grab the latest from your chart repositories... ...Successfully got an update from the \"aso2\" chart repository Update Complete. \u2388Happy Helming!\u2388 Release \"aso2\" does not exist. Installing it now. NAME: aso2 LAST DEPLOYED: Tue Nov 15 03 :07:17 2022 NAMESPACE: azureserviceoperator-system STATUS: deployed REVISION: 1 TEST SUITE: None Info It takes a few minutes for the Azure Service Operator pod to be ready. It takes a few minutes for the Azure Service Operator pod to become ready. To check the status of the pod, run the following command: oc -n azureserviceoperator-system get pod Your output should look something like this: NAME READY STATUS RESTARTS AGE azureserviceoperator-controller-manager-76d5cf659-zznkr 2 /2 Running 0 2m3s Once you see \"2/2\" and \"Running\", you're ready to move to the next phase of deploying resources with the Azure Service Operator.","title":"Deploy"},{"location":"ops/aso/deploy/#introduction","text":"The Azure Service Operator (ASO) is an open-source project by Microsoft. ASO gives you the ability to provision and manage Azure resources such as compute, databases, resource groups, networking, etc. as objects in Kubernetes using declarative Kubernetes manifests. Azure Service Operator is currently in BETA Azure Service Operator is in its second incarnation (v2) and is in beta. This means ASO is not fully supported and should not be used in production. In addition, at this time, ASO is not available in OperatorHub and has to be installed using Helm or raw manifests. We are using it in this workshop as a demonstration. ASO consists of: Custom Resource Definitions (CRDs) for each of the Azure services that a Kubernetes user can provision. A Kubernetes controller that manages the Azure resources represented by the user-specified Custom Resources. The controller attempts to synchronize the desired state in the user-specified Custom Resource with the actual state of that resource in Azure, creating it if it doesn't exist, updating it if it has been changed, or deleting it. We will deploy ASO on an ARO cluster to provision and manage Azure resources. To install ASO we need: An Azure Service Principal with Contributor permissions in the Azure Subscription. An Azure Service Principal is an identity created for use with applications, hosted services, and automated tools to access Azure resources. This has been pre-created for you as a part of the workshop. A cert-manager instance. ASO needs cert-manager to programmatically create self-signed certificates.","title":"Introduction"},{"location":"ops/aso/deploy/#install-and-configure-the-azure-service-operator-aso","text":"","title":"Install and configure the Azure Service Operator (ASO)"},{"location":"ops/aso/deploy/#install-the-cert-manager-operator","text":"The cert-manager operator can easily be installed from the OpenShift Console OperatorHub. Return to your tab with the OpenShift Web Console. If you need to reauthenticate, follow the steps in the Access Your Cluster section. Using the menu on the left Select Operators -> OperatorHub . In the search box, search for \"cert-manager\" and click on the cert-manager Operator for Red Hat OpenShift box that has the Red Hat logo. Click on Install on the page that appears. Accept the defaults that are presented and select Install to install the operator. Allow the operator a few minutes to successfully install the cert-manager operator into the cluster.","title":"Install the Cert Manager Operator"},{"location":"ops/aso/deploy/#install-the-azure-service-operator-aso","text":"First, let's get the necessary information for the Azure Service Operator to authenticate against Azure. To do so, run the following command: export AZURE_TENANT_ID = \" $( az account show -o tsv --query tenantId ) \" echo \"Tenant ID: ${ AZURE_TENANT_ID } \" export AZURE_SUBSCRIPTION_ID = \" $( az account show -o tsv --query id ) \" echo \"Subscription ID: ${ AZURE_SUBSCRIPTION_ID } \" export AZURE_CLIENT_ID = \" $( oc get secret azure-credentials -n kube-system -o json | jq -r .data.azure_client_id | base64 --decode ) \" echo \"Client ID: ${ AZURE_CLIENT_ID } \" export AZURE_CLIENT_SECRET = \" $( oc get secret azure-credentials -n kube-system -o json | jq -r .data.azure_client_secret | base64 --decode ) \" echo \"Secret (Sensitive Information): ${ AZURE_CLIENT_SECRET } \" Next, let's install the latest Azure Service Operator (v2) using the Helm Chart that Microsoft provides. To do so, run the following command: helm repo add aso2 \\ https://raw.githubusercontent.com/Azure/azure-service-operator/main/v2/charts helm repo update helm upgrade --install --devel aso2 aso2/azure-service-operator \\ --create-namespace \\ --namespace = azureserviceoperator-system \\ --set azureSubscriptionID = \" ${ AZURE_SUBSCRIPTION_ID } \" \\ --set azureTenantID = \" ${ AZURE_TENANT_ID } \" \\ --set azureClientID = \" ${ AZURE_CLIENT_ID } \" \\ --set azureClientSecret = \" ${ AZURE_CLIENT_SECRET } \" Within a minute or less, you should see output that looks similar to: \"aso2\" has been added to your repositories Hang tight while we grab the latest from your chart repositories... ...Successfully got an update from the \"aso2\" chart repository Update Complete. \u2388Happy Helming!\u2388 Release \"aso2\" does not exist. Installing it now. NAME: aso2 LAST DEPLOYED: Tue Nov 15 03 :07:17 2022 NAMESPACE: azureserviceoperator-system STATUS: deployed REVISION: 1 TEST SUITE: None Info It takes a few minutes for the Azure Service Operator pod to be ready. It takes a few minutes for the Azure Service Operator pod to become ready. To check the status of the pod, run the following command: oc -n azureserviceoperator-system get pod Your output should look something like this: NAME READY STATUS RESTARTS AGE azureserviceoperator-controller-manager-76d5cf659-zznkr 2 /2 Running 0 2m3s Once you see \"2/2\" and \"Running\", you're ready to move to the next phase of deploying resources with the Azure Service Operator.","title":"Install the Azure Service Operator (ASO)"},{"location":"ops/day2/autoscaling/","text":"Introduction # The cluster autoscaler adjusts the size of an OpenShift Container Platform cluster to meet its current deployment needs. The cluster autoscaler increases the size of the cluster when there are pods that fail to schedule on any of the current worker nodes due to insufficient resources or when another node is necessary to meet deployment needs. The cluster autoscaler does not increase the cluster resources beyond the limits that you specify. To learn more visit the documentation for cluster autoscaling . A ClusterAutoscaler must have at least 1 machine autoscaler in order for the cluster autoscaler to scale the machines. The cluster autoscaler uses the annotations on machine sets that the machine autoscaler sets to determine the resources that it can scale. If you define a cluster autoscaler without also defining machine autoscalers, the cluster autoscaler will never scale your cluster. Create a Machine Autoscaler # This can be accomplished via the Web Console or through the CLI with a YAML file for the custom resource definition. We'll use the latter. Download the sample MachineAutoscaler resource definition and open it in your favorite editor. For metadata.name give this machine autoscaler a name. Technically, this can be anything you want. But to make it easier to identify which machine set this machine autoscaler affects, specify or include the name of the machine set to scale. The machine set name takes the following form: clusterid-machineset-region-az. For spec.ScaleTargetRef.name enter the name of the exact MachineSet you want this to apply to. Below is an example of a completed file. machine-autoscaler.yaml apiVersion: \"autoscaling.openshift.io/v1beta1\" kind: \"MachineAutoscaler\" metadata: name: \"tstacey-01-6fnwk-worker-eastus1-autoscaler\" namespace: \"openshift-machine-api\" spec: minReplicas: 1 maxReplicas: 3 scaleTargetRef: apiVersion: machine.openshift.io/v1beta1 kind: MachineSet name: tstacey-01-6fnwk-worker-eastus1 Save your file. Then create the resource in the cluster. Assuming you kept the same filename: oc create -f machine-autoscaler.yaml You will see the following output: machineautoscaler.autoscaling.openshift.io/ok0620-rq5tl-worker-westus21-mautoscaler created You can also confirm this by checking the web console under \"MachineAutoscalers\" or by running: oc get machineautoscaler -n openshift-machine-api You should see output similar to: NAME REF KIND REF NAME MIN MAX AGE ok0620-rq5tl-worker-westus21 MachineSet ok0620-rq5tl-worker-westus2 1 7 40s Create the Cluster Autoscaler # This is the sample ClusterAutoscaler resource definition for this workshop: cluster-autoscaler.yaml apiVersion: \"autoscaling.openshift.io/v1\" kind: \"ClusterAutoscaler\" metadata: name: \"default\" spec: podPriorityThreshold: -10 resourceLimits: maxNodesTotal: 10 cores: min: 8 max: 128 memory: min: 4 max: 256 scaleDown: enabled: true delayAfterAdd: 2m delayAfterDelete: 1m delayAfterFailure: 15s unneededTime: 1m See the documentation for a detailed explanation of each parameter. You shouldn't need to edit this file. Create the resource in the cluster: <<<<<<< HEAD:aro-content/ops/day2/autoscaling.md oc create -f https://ws.mobb.cloud/assets/job-maxscale.yaml ======= oc create -f https://rh-mobb.github.io/aro-hackathon-content/assets/cluster-autoscaler.yaml a78436f (initial v2):aro-content/ops/2-3-autoscaling.md Output: clusterautoscaler.autoscaling.openshift.io/default created Test the Cluster Autoscaler # We will be testing out the autoscaler in the next section when we scale up the frontend.","title":"Autoscaling"},{"location":"ops/day2/autoscaling/#introduction","text":"The cluster autoscaler adjusts the size of an OpenShift Container Platform cluster to meet its current deployment needs. The cluster autoscaler increases the size of the cluster when there are pods that fail to schedule on any of the current worker nodes due to insufficient resources or when another node is necessary to meet deployment needs. The cluster autoscaler does not increase the cluster resources beyond the limits that you specify. To learn more visit the documentation for cluster autoscaling . A ClusterAutoscaler must have at least 1 machine autoscaler in order for the cluster autoscaler to scale the machines. The cluster autoscaler uses the annotations on machine sets that the machine autoscaler sets to determine the resources that it can scale. If you define a cluster autoscaler without also defining machine autoscalers, the cluster autoscaler will never scale your cluster.","title":"Introduction"},{"location":"ops/day2/autoscaling/#create-a-machine-autoscaler","text":"This can be accomplished via the Web Console or through the CLI with a YAML file for the custom resource definition. We'll use the latter. Download the sample MachineAutoscaler resource definition and open it in your favorite editor. For metadata.name give this machine autoscaler a name. Technically, this can be anything you want. But to make it easier to identify which machine set this machine autoscaler affects, specify or include the name of the machine set to scale. The machine set name takes the following form: clusterid-machineset-region-az. For spec.ScaleTargetRef.name enter the name of the exact MachineSet you want this to apply to. Below is an example of a completed file. machine-autoscaler.yaml apiVersion: \"autoscaling.openshift.io/v1beta1\" kind: \"MachineAutoscaler\" metadata: name: \"tstacey-01-6fnwk-worker-eastus1-autoscaler\" namespace: \"openshift-machine-api\" spec: minReplicas: 1 maxReplicas: 3 scaleTargetRef: apiVersion: machine.openshift.io/v1beta1 kind: MachineSet name: tstacey-01-6fnwk-worker-eastus1 Save your file. Then create the resource in the cluster. Assuming you kept the same filename: oc create -f machine-autoscaler.yaml You will see the following output: machineautoscaler.autoscaling.openshift.io/ok0620-rq5tl-worker-westus21-mautoscaler created You can also confirm this by checking the web console under \"MachineAutoscalers\" or by running: oc get machineautoscaler -n openshift-machine-api You should see output similar to: NAME REF KIND REF NAME MIN MAX AGE ok0620-rq5tl-worker-westus21 MachineSet ok0620-rq5tl-worker-westus2 1 7 40s","title":"Create a Machine Autoscaler"},{"location":"ops/day2/autoscaling/#create-the-cluster-autoscaler","text":"This is the sample ClusterAutoscaler resource definition for this workshop: cluster-autoscaler.yaml apiVersion: \"autoscaling.openshift.io/v1\" kind: \"ClusterAutoscaler\" metadata: name: \"default\" spec: podPriorityThreshold: -10 resourceLimits: maxNodesTotal: 10 cores: min: 8 max: 128 memory: min: 4 max: 256 scaleDown: enabled: true delayAfterAdd: 2m delayAfterDelete: 1m delayAfterFailure: 15s unneededTime: 1m See the documentation for a detailed explanation of each parameter. You shouldn't need to edit this file. Create the resource in the cluster: <<<<<<< HEAD:aro-content/ops/day2/autoscaling.md oc create -f https://ws.mobb.cloud/assets/job-maxscale.yaml ======= oc create -f https://rh-mobb.github.io/aro-hackathon-content/assets/cluster-autoscaler.yaml a78436f (initial v2):aro-content/ops/2-3-autoscaling.md Output: clusterautoscaler.autoscaling.openshift.io/default created","title":"Create the Cluster Autoscaler"},{"location":"ops/day2/autoscaling/#test-the-cluster-autoscaler","text":"We will be testing out the autoscaler in the next section when we scale up the frontend.","title":"Test the Cluster Autoscaler"},{"location":"ops/day2/labels/","text":"Introduction # Labels are a useful way to select which nodes that an application will run on. These nodes are created by machines which are defined by the MachineSets we worked with in previous sections of this workshop. An example of this would be running a memory intensive application only on a specific node type. While you can directly add a label to a node, it is not recommended because nodes can be recreated, which would cause the label to disappear. Therefore we need to label the MachineSet itself. An important caveat to this process is that only new machines created by the MachineSet will get the label. This means you will need to either scale the MachineSet down to zero then back up to create new machines with the label, or you can label the existing machines directly. Set a label for the MachineSet # Just like the last section, let's pick a MachineSet to add our label. To do so, run the following command: MACHINESET = $( oc -n openshift-machine-api get machinesets -o name | head -1 ) echo ${ MACHINESET } Now, let's patch the MachineSet with our new label. To do so, run the following command: oc -n openshift-machine-api patch ${ MACHINESET } --type = merge -p '{\"spec\":{\"template\":{\"spec\":{\"metadata\":{\"labels\":{\"tier\":\"frontend\"}}}}}}' As you'll remember, the existing machines won't get this label, but all new machines will. While we could just scale this MachineSet down to zero and back up again, that could disrupt our workloads. Instead, let's just loop through and add the label to all of our nodes in that MachineSet. To do so, run the following command: MACHINES = $( oc -n openshift-machine-api get machines -o name -l \"machine.openshift.io/cluster-api-machineset= $( echo $MACHINESET | cut -d / -f2 ) \" | xargs ) oc label -n openshift-machine-api ${ MACHINES } tier = frontend NODES = $( echo $MACHINES | sed 's/machine.machine.openshift.io/node/g' ) oc label ${ NODES } tier = frontend Info Just like MachineSets, machines do not automatically label their existing child resources, this means we need to relabel them ourselves to avoid having to recreate them. Now, let's verify the nodes are properly labeled. To do so, run the following command: oc get nodes --selector = 'tier=frontend' Your output will look something like this: NAME STATUS ROLES AGE VERSION user1-cluster-8kvh4-worker-eastus1-hd5cw Ready worker 7h31m v1.23.5+3afdacb user1-cluster-8kvh4-worker-eastus1-zj7dl Ready worker 7h22m v1.23.5+3afdacb Pending that your output shows one or more node, this demonstrates that our MachineSet and associated nodes are properly annotated! Deploy an app to the labeled nodes # Now that we've successfully labeled our nodes, let's deploy a workload to demonstrate app placement using nodeSelector . This should force our app to only our labeled nodes. First, let's create a namespace (also known as a project in OpenShift). To do so, run the following command: oc new-project nodeselector-ex Next, let's deploy our application and associated resources that will target our labeled nodes. To do so, run the following command: oc create -f https://ws.mobb.cloud/assets/node-select-deployment.yaml Wondering what we just created? This is the app deployment and associated resource definition that will target our labeled worker nodes. node-select-deployment.yaml kind: Deployment apiVersion: apps/v1 metadata: name: nodeselector-app namespace: nodeselector-ex spec: replicas: 1 selector: matchLabels: app: nodeselector-app template: metadata: labels: app: nodeselector-app spec: nodeSelector: tier: frontend containers: - name: hello-openshift image: \"docker.io/openshift/hello-openshift\" ports: - containerPort: 8080 protocol: TCP - containerPort: 8888 protocol: TCP --- apiVersion: v1 kind: Service metadata: name: nodeselector-app namespace: nodeselector-ex spec: ports: - port: 8080 targetPort: 8080 selector: app: nodeselector-app --- apiVersion: route.openshift.io/v1 kind: Route metadata: name: nodeselector-app namespace: nodeselector-ex spec: port: targetPort: 8080 to: kind: Service name: nodeselector-app weight: 100 tls: insecureEdgeTerminationPolicy: Redirect termination: edge wildcardPolicy: None Now, let's validate that the application has been deployed to one of the labeled nodes. To do so, run the following command: oc -n nodeselector-ex get pod -l app = nodeselector-app -o wide Your output will look something like this: NAME READY STATUS RESTARTS AGE IP NODE NOMINATED NODE READINESS GATES nodeselector-app-7746c49485-tbnmd 1 /1 Running 0 74s 10 .131.2.73 user1-cluster-8kvh4-worker-eastus1-zj7dl <none> <none> Verify that the app was scheduled on a node that matches the output from the previous section's step four. And finally, if you'd like to view the app in your browser, get the route of the application. To do so, run the following command: oc -n nodeselector-ex get route nodeselector-app -o jsonpath = '{.spec.host}' Then visit the URL presented in a new tab in your web browser (using HTTPS). For example, your output will look something similar to: nodeselector-app-nodeselector-ex.apps.ce7l3kf6.eastus.aroapp.io In that case, you'd visit https://nodeselector-app-nodeselector-ex.apps.ce7l3kf6.eastus.aroapp.io in your browser. Congratulations! You've successfully demonstrated the ability to label nodes and target those nodes using nodeSelector .","title":"Labels"},{"location":"ops/day2/labels/#introduction","text":"Labels are a useful way to select which nodes that an application will run on. These nodes are created by machines which are defined by the MachineSets we worked with in previous sections of this workshop. An example of this would be running a memory intensive application only on a specific node type. While you can directly add a label to a node, it is not recommended because nodes can be recreated, which would cause the label to disappear. Therefore we need to label the MachineSet itself. An important caveat to this process is that only new machines created by the MachineSet will get the label. This means you will need to either scale the MachineSet down to zero then back up to create new machines with the label, or you can label the existing machines directly.","title":"Introduction"},{"location":"ops/day2/labels/#set-a-label-for-the-machineset","text":"Just like the last section, let's pick a MachineSet to add our label. To do so, run the following command: MACHINESET = $( oc -n openshift-machine-api get machinesets -o name | head -1 ) echo ${ MACHINESET } Now, let's patch the MachineSet with our new label. To do so, run the following command: oc -n openshift-machine-api patch ${ MACHINESET } --type = merge -p '{\"spec\":{\"template\":{\"spec\":{\"metadata\":{\"labels\":{\"tier\":\"frontend\"}}}}}}' As you'll remember, the existing machines won't get this label, but all new machines will. While we could just scale this MachineSet down to zero and back up again, that could disrupt our workloads. Instead, let's just loop through and add the label to all of our nodes in that MachineSet. To do so, run the following command: MACHINES = $( oc -n openshift-machine-api get machines -o name -l \"machine.openshift.io/cluster-api-machineset= $( echo $MACHINESET | cut -d / -f2 ) \" | xargs ) oc label -n openshift-machine-api ${ MACHINES } tier = frontend NODES = $( echo $MACHINES | sed 's/machine.machine.openshift.io/node/g' ) oc label ${ NODES } tier = frontend Info Just like MachineSets, machines do not automatically label their existing child resources, this means we need to relabel them ourselves to avoid having to recreate them. Now, let's verify the nodes are properly labeled. To do so, run the following command: oc get nodes --selector = 'tier=frontend' Your output will look something like this: NAME STATUS ROLES AGE VERSION user1-cluster-8kvh4-worker-eastus1-hd5cw Ready worker 7h31m v1.23.5+3afdacb user1-cluster-8kvh4-worker-eastus1-zj7dl Ready worker 7h22m v1.23.5+3afdacb Pending that your output shows one or more node, this demonstrates that our MachineSet and associated nodes are properly annotated!","title":"Set a label for the MachineSet"},{"location":"ops/day2/labels/#deploy-an-app-to-the-labeled-nodes","text":"Now that we've successfully labeled our nodes, let's deploy a workload to demonstrate app placement using nodeSelector . This should force our app to only our labeled nodes. First, let's create a namespace (also known as a project in OpenShift). To do so, run the following command: oc new-project nodeselector-ex Next, let's deploy our application and associated resources that will target our labeled nodes. To do so, run the following command: oc create -f https://ws.mobb.cloud/assets/node-select-deployment.yaml Wondering what we just created? This is the app deployment and associated resource definition that will target our labeled worker nodes. node-select-deployment.yaml kind: Deployment apiVersion: apps/v1 metadata: name: nodeselector-app namespace: nodeselector-ex spec: replicas: 1 selector: matchLabels: app: nodeselector-app template: metadata: labels: app: nodeselector-app spec: nodeSelector: tier: frontend containers: - name: hello-openshift image: \"docker.io/openshift/hello-openshift\" ports: - containerPort: 8080 protocol: TCP - containerPort: 8888 protocol: TCP --- apiVersion: v1 kind: Service metadata: name: nodeselector-app namespace: nodeselector-ex spec: ports: - port: 8080 targetPort: 8080 selector: app: nodeselector-app --- apiVersion: route.openshift.io/v1 kind: Route metadata: name: nodeselector-app namespace: nodeselector-ex spec: port: targetPort: 8080 to: kind: Service name: nodeselector-app weight: 100 tls: insecureEdgeTerminationPolicy: Redirect termination: edge wildcardPolicy: None Now, let's validate that the application has been deployed to one of the labeled nodes. To do so, run the following command: oc -n nodeselector-ex get pod -l app = nodeselector-app -o wide Your output will look something like this: NAME READY STATUS RESTARTS AGE IP NODE NOMINATED NODE READINESS GATES nodeselector-app-7746c49485-tbnmd 1 /1 Running 0 74s 10 .131.2.73 user1-cluster-8kvh4-worker-eastus1-zj7dl <none> <none> Verify that the app was scheduled on a node that matches the output from the previous section's step four. And finally, if you'd like to view the app in your browser, get the route of the application. To do so, run the following command: oc -n nodeselector-ex get route nodeselector-app -o jsonpath = '{.spec.host}' Then visit the URL presented in a new tab in your web browser (using HTTPS). For example, your output will look something similar to: nodeselector-app-nodeselector-ex.apps.ce7l3kf6.eastus.aroapp.io In that case, you'd visit https://nodeselector-app-nodeselector-ex.apps.ce7l3kf6.eastus.aroapp.io in your browser. Congratulations! You've successfully demonstrated the ability to label nodes and target those nodes using nodeSelector .","title":"Deploy an app to the labeled nodes"},{"location":"ops/day2/scaling-nodes/","text":"Introduction # <<<<<<< HEAD:aro-content/ops/day2/scaling-nodes.md When deploying your Azure Red Hat OpenShift (ARO) cluster, you can configure many aspects of your worker nodes, but what happens when you need to change your worker nodes after they've already been created? These activities include scaling the number of nodes, changing the instance type, adding labels or taints, just to name a few. Many of these changes are done using MachineSets. MachineSets ensure that a specified number of Machine replicas are running at any given time. Think of a MachineSet as a \"template\" for the kinds of Machines that make up the worker nodes of your cluster. These are similar to other Kubernetes resources, like a ReplicaSet is to Pods. One important caveat, is that MachineSets allow users to manage many Machines as a single entity, but are contained to a specific availability zone. If you'd like to learn more, see the Red Hat documentation on machine management . # There may be times when you need to change aspects of your worker nodes. Things like scaling, changing the type, adding labels or taints to name a few. Most of these things are done through the use of machine sets. A machine is a unit that describes the host for a node and a machine set is a group of machines. Think of a machine set as a \u201ctemplate\u201d for the kinds of machines that make up the worker nodes of your cluster. Similar to how a replicaset is to pods. A machine set allows users to manage many machines as a single entity though it is contained to a specific availability zone. If you'd like to learn more see Overview of machine management a78436f (initial v2):aro-content/ops/2-2-worker-nodes.md Scaling worker nodes # View the machine sets that are in the cluster # Let's see which machine sets we have in our cluster. If you are following this lab, you should only have three so far (one for each availability zone). From the terminal run: oc get machinesets -n openshift-machine-api You will see a response like: $ oc get machinesets -n openshift-machine-api NAME DESIRED CURRENT READY AVAILABLE AGE ok0620-rq5tl-worker-westus21 1 1 1 1 72m ok0620-rq5tl-worker-westus22 1 1 1 1 72m ok0620-rq5tl-worker-westus23 1 1 1 1 72m This is telling us that there is a machine set defined for each availability zone in westus2 and that each has one machine. <<<<<<< HEAD:aro-content/ops/day2/scaling-nodes.md For this workshop, we've deployed your ARO cluster with six total machines (three workers machines and three control plane machines), one in each availability zone. The output will look something like this: ======= View the machines that are in the cluster # a78436f (initial v2):aro-content/ops/2-2-worker-nodes.md Let's see which machines (nodes) we have in our cluster. From the terminal run: oc get machine -n openshift-machine-api You will see a response like: $ oc get machine -n openshift-machine-api NAME PHASE TYPE REGION ZONE AGE ok0620-rq5tl-master-0 Running Standard_D8s_v3 westus2 1 73m ok0620-rq5tl-master-1 Running Standard_D8s_v3 westus2 2 73m ok0620-rq5tl-master-2 Running Standard_D8s_v3 westus2 3 73m ok0620-rq5tl-worker-westus21-n6lcs Running Standard_D4s_v3 westus2 1 73m ok0620-rq5tl-worker-westus22-ggcmv Running Standard_D4s_v3 westus2 2 73m ok0620-rq5tl-worker-westus23-hzggb Running Standard_D4s_v3 westus2 3 73m As you can see we have 3 master nodes, 3 worker nodes, the types of nodes, and which region/zone they are in. <<<<<<< HEAD:aro-content/ops/day2/scaling-nodes.md oc -n openshift-machine-api scale --replicas = 2 ${ MACHINESET } ======= Scale the number of nodes up via the CLI # a78436f (initial v2):aro-content/ops/2-2-worker-nodes.md Now that we know that we have 3 worker nodes, let's scale the cluster up to have 4 worker nodes. We can accomplish this through the CLI or through the OpenShift Web Console. We'll explore both. <<<<<<< HEAD:aro-content/ops/day2/scaling-nodes.md oc -n openshift-machine-api get machinesets The output should look something like this: ======= From the terminal run the following to imperatively scale up a machine set to 2 worker nodes for a total of 4. Remember that each machine set is tied to an availability zone so with 3 machine sets with 1 machine each, in order to get to a TOTAL of 4 nodes we need to select one of the machine sets to scale up to 2 machines. a78436f (initial v2):aro-content/ops/2-2-worker-nodes.md oc scale --replicas = 2 machineset <machineset> -n openshift-machine-api <<<<<<< HEAD:aro-content/ops/day2/scaling-nodes.md Note, that the number of desired and current nodes matches the scale we specified, but only one is ready and available . ======= For example: a78436f (initial v2):aro-content/ops/2-2-worker-nodes.md $ oc scale --replicas=2 machineset ok0620-rq5tl-worker-westus23 -n openshift-machine-api machineset.machine.openshift.io/ok0620-rq5tl-worker-westus23 scaled <<<<<<< HEAD:aro-content/ops/day2/scaling-nodes.md oc -n openshift-machine-api get machine The output should look something like this: ======= View the machine set a78436f (initial v2):aro-content/ops/2-2-worker-nodes.md oc get machinesets -n openshift-machine-api You will now see that the desired number of machines in the machine set we scaled is \"2\". <<<<<<< HEAD:aro-content/ops/day2/scaling-nodes.md Now let's scale the cluster back down to a total of 3 worker nodes, but this time, from the web console. 1. Return to your tab with the OpenShift Web Console. If you need to reauthenticate, follow the steps in the Access Your Cluster section. # $ oc get machinesets -n openshift-machine-api NAME DESIRED CURRENT READY AVAILABLE AGE ok0620-rq5tl-worker-westus21 1 1 1 1 73m ok0620-rq5tl-worker-westus22 1 1 1 1 73m ok0620-rq5tl-worker-westus23 2 2 1 1 73m If we check the machines in the clusters a78436f (initial v2):aro-content/ops/2-2-worker-nodes.md oc get machine -n openshift-machine-api <<<<<<< HEAD:aro-content/ops/day2/scaling-nodes.md In the overview you will see the same information about the MachineSets that you saw on the command line. Now, locate the MachineSet which has \"2 of 2\" machines, and click on the \u22ee icon, then select Edit machine count . Next, reduce the count from \"2\" to \"1\" and click Save to save your changes. Congratulations! You've successfully scaled your cluster up and back down to three nodes. # You will see that one is in the \"Provisioned\" phase (and in the zone of the machineset we scaled) and will shortly be in \"running\" phase. $ oc get machine -n openshift-machine-api NAME PHASE TYPE REGION ZONE AGE ok0620-rq5tl-master-0 Running Standard_D8s_v3 westus2 1 74m ok0620-rq5tl-master-1 Running Standard_D8s_v3 westus2 2 74m ok0620-rq5tl-master-2 Running Standard_D8s_v3 westus2 3 74m ok0620-rq5tl-worker-westus21-n6lcs Running Standard_D4s_v3 westus2 1 74m ok0620-rq5tl-worker-westus22-ggcmv Running Standard_D4s_v3 westus2 2 74m ok0620-rq5tl-worker-westus23-5fhm5 Provisioned Standard_D4s_v3 westus2 3 54s ok0620-rq5tl-worker-westus23-hzggb Running Standard_D4s_v3 westus2 3 74m Scale the number of nodes down via the Web Console # Now let's scale the cluster back down to a total of 3 worker nodes, but this time, from the web console. (If you need the URL or credentials in order to access it please go back to the relevant portion of Lab 1) Access your OpenShift web console from the relevant URL. If you need to find the URL you can run: az aro show \\ --name <CLUSTER-NAME> \\ --resource-group <RESOURCEGROUP> \\ --query \"consoleProfile.url\" -o tsv Expand \"Compute\" in the left menu and then click on \"MachineSets\" In the main pane you will see the same information about the machine sets from the command line. Now click on the \"three dots\" at the end of the line for the machine set that you scaled up to \"2\". Select \"Edit machine count\" and decrease it to \"1\". Click save. This will now decrease that machine set to only have one machine in it. a78436f (initial v2):aro-content/ops/2-2-worker-nodes.md","title":"Scaling nodes"},{"location":"ops/day2/scaling-nodes/#introduction","text":"<<<<<<< HEAD:aro-content/ops/day2/scaling-nodes.md When deploying your Azure Red Hat OpenShift (ARO) cluster, you can configure many aspects of your worker nodes, but what happens when you need to change your worker nodes after they've already been created? These activities include scaling the number of nodes, changing the instance type, adding labels or taints, just to name a few.","title":"Introduction"},{"location":"ops/day2/scaling-nodes/#many-of-these-changes-are-done-using-machinesets-machinesets-ensure-that-a-specified-number-of-machine-replicas-are-running-at-any-given-time-think-of-a-machineset-as-a-template-for-the-kinds-of-machines-that-make-up-the-worker-nodes-of-your-cluster-these-are-similar-to-other-kubernetes-resources-like-a-replicaset-is-to-pods-one-important-caveat-is-that-machinesets-allow-users-to-manage-many-machines-as-a-single-entity-but-are-contained-to-a-specific-availability-zone-if-youd-like-to-learn-more-see-the-red-hat-documentation-on-machine-management","text":"There may be times when you need to change aspects of your worker nodes. Things like scaling, changing the type, adding labels or taints to name a few. Most of these things are done through the use of machine sets. A machine is a unit that describes the host for a node and a machine set is a group of machines. Think of a machine set as a \u201ctemplate\u201d for the kinds of machines that make up the worker nodes of your cluster. Similar to how a replicaset is to pods. A machine set allows users to manage many machines as a single entity though it is contained to a specific availability zone. If you'd like to learn more see Overview of machine management a78436f (initial v2):aro-content/ops/2-2-worker-nodes.md","title":"Many of these changes are done using MachineSets. MachineSets ensure that a specified number of Machine replicas are running at any given time. Think of a MachineSet as a \"template\" for the kinds of Machines that make up the worker nodes of your cluster. These are similar to other Kubernetes resources, like a ReplicaSet is to Pods. One important caveat, is that MachineSets allow users to manage many Machines as a single entity, but are contained to a specific availability zone. If you'd like to learn more, see the Red Hat documentation on machine management."},{"location":"ops/day2/scaling-nodes/#scaling-worker-nodes","text":"","title":"Scaling worker nodes"},{"location":"ops/day2/scaling-nodes/#view-the-machine-sets-that-are-in-the-cluster","text":"Let's see which machine sets we have in our cluster. If you are following this lab, you should only have three so far (one for each availability zone). From the terminal run: oc get machinesets -n openshift-machine-api You will see a response like: $ oc get machinesets -n openshift-machine-api NAME DESIRED CURRENT READY AVAILABLE AGE ok0620-rq5tl-worker-westus21 1 1 1 1 72m ok0620-rq5tl-worker-westus22 1 1 1 1 72m ok0620-rq5tl-worker-westus23 1 1 1 1 72m This is telling us that there is a machine set defined for each availability zone in westus2 and that each has one machine. <<<<<<< HEAD:aro-content/ops/day2/scaling-nodes.md For this workshop, we've deployed your ARO cluster with six total machines (three workers machines and three control plane machines), one in each availability zone. The output will look something like this: =======","title":"View the machine sets that are in the cluster"},{"location":"ops/day2/scaling-nodes/#view-the-machines-that-are-in-the-cluster","text":"a78436f (initial v2):aro-content/ops/2-2-worker-nodes.md Let's see which machines (nodes) we have in our cluster. From the terminal run: oc get machine -n openshift-machine-api You will see a response like: $ oc get machine -n openshift-machine-api NAME PHASE TYPE REGION ZONE AGE ok0620-rq5tl-master-0 Running Standard_D8s_v3 westus2 1 73m ok0620-rq5tl-master-1 Running Standard_D8s_v3 westus2 2 73m ok0620-rq5tl-master-2 Running Standard_D8s_v3 westus2 3 73m ok0620-rq5tl-worker-westus21-n6lcs Running Standard_D4s_v3 westus2 1 73m ok0620-rq5tl-worker-westus22-ggcmv Running Standard_D4s_v3 westus2 2 73m ok0620-rq5tl-worker-westus23-hzggb Running Standard_D4s_v3 westus2 3 73m As you can see we have 3 master nodes, 3 worker nodes, the types of nodes, and which region/zone they are in. <<<<<<< HEAD:aro-content/ops/day2/scaling-nodes.md oc -n openshift-machine-api scale --replicas = 2 ${ MACHINESET } =======","title":"View the machines that are in the cluster"},{"location":"ops/day2/scaling-nodes/#scale-the-number-of-nodes-up-via-the-cli","text":"a78436f (initial v2):aro-content/ops/2-2-worker-nodes.md Now that we know that we have 3 worker nodes, let's scale the cluster up to have 4 worker nodes. We can accomplish this through the CLI or through the OpenShift Web Console. We'll explore both. <<<<<<< HEAD:aro-content/ops/day2/scaling-nodes.md oc -n openshift-machine-api get machinesets The output should look something like this: ======= From the terminal run the following to imperatively scale up a machine set to 2 worker nodes for a total of 4. Remember that each machine set is tied to an availability zone so with 3 machine sets with 1 machine each, in order to get to a TOTAL of 4 nodes we need to select one of the machine sets to scale up to 2 machines. a78436f (initial v2):aro-content/ops/2-2-worker-nodes.md oc scale --replicas = 2 machineset <machineset> -n openshift-machine-api <<<<<<< HEAD:aro-content/ops/day2/scaling-nodes.md Note, that the number of desired and current nodes matches the scale we specified, but only one is ready and available . ======= For example: a78436f (initial v2):aro-content/ops/2-2-worker-nodes.md $ oc scale --replicas=2 machineset ok0620-rq5tl-worker-westus23 -n openshift-machine-api machineset.machine.openshift.io/ok0620-rq5tl-worker-westus23 scaled <<<<<<< HEAD:aro-content/ops/day2/scaling-nodes.md oc -n openshift-machine-api get machine The output should look something like this: ======= View the machine set a78436f (initial v2):aro-content/ops/2-2-worker-nodes.md oc get machinesets -n openshift-machine-api You will now see that the desired number of machines in the machine set we scaled is \"2\". <<<<<<< HEAD:aro-content/ops/day2/scaling-nodes.md Now let's scale the cluster back down to a total of 3 worker nodes, but this time, from the web console.","title":"Scale the number of nodes up via the CLI"},{"location":"ops/day2/scaling-nodes/#1-return-to-your-tab-with-the-openshift-web-console-if-you-need-to-reauthenticate-follow-the-steps-in-the-access-your-cluster-section","text":"$ oc get machinesets -n openshift-machine-api NAME DESIRED CURRENT READY AVAILABLE AGE ok0620-rq5tl-worker-westus21 1 1 1 1 73m ok0620-rq5tl-worker-westus22 1 1 1 1 73m ok0620-rq5tl-worker-westus23 2 2 1 1 73m If we check the machines in the clusters a78436f (initial v2):aro-content/ops/2-2-worker-nodes.md oc get machine -n openshift-machine-api <<<<<<< HEAD:aro-content/ops/day2/scaling-nodes.md In the overview you will see the same information about the MachineSets that you saw on the command line. Now, locate the MachineSet which has \"2 of 2\" machines, and click on the \u22ee icon, then select Edit machine count . Next, reduce the count from \"2\" to \"1\" and click Save to save your changes.","title":"1. Return to your tab with the OpenShift Web Console. If you need to reauthenticate, follow the steps in the Access Your Cluster section."},{"location":"ops/day2/scaling-nodes/#congratulations-youve-successfully-scaled-your-cluster-up-and-back-down-to-three-nodes","text":"You will see that one is in the \"Provisioned\" phase (and in the zone of the machineset we scaled) and will shortly be in \"running\" phase. $ oc get machine -n openshift-machine-api NAME PHASE TYPE REGION ZONE AGE ok0620-rq5tl-master-0 Running Standard_D8s_v3 westus2 1 74m ok0620-rq5tl-master-1 Running Standard_D8s_v3 westus2 2 74m ok0620-rq5tl-master-2 Running Standard_D8s_v3 westus2 3 74m ok0620-rq5tl-worker-westus21-n6lcs Running Standard_D4s_v3 westus2 1 74m ok0620-rq5tl-worker-westus22-ggcmv Running Standard_D4s_v3 westus2 2 74m ok0620-rq5tl-worker-westus23-5fhm5 Provisioned Standard_D4s_v3 westus2 3 54s ok0620-rq5tl-worker-westus23-hzggb Running Standard_D4s_v3 westus2 3 74m","title":"Congratulations! You've successfully scaled your cluster up and back down to three nodes."},{"location":"ops/day2/scaling-nodes/#scale-the-number-of-nodes-down-via-the-web-console","text":"Now let's scale the cluster back down to a total of 3 worker nodes, but this time, from the web console. (If you need the URL or credentials in order to access it please go back to the relevant portion of Lab 1) Access your OpenShift web console from the relevant URL. If you need to find the URL you can run: az aro show \\ --name <CLUSTER-NAME> \\ --resource-group <RESOURCEGROUP> \\ --query \"consoleProfile.url\" -o tsv Expand \"Compute\" in the left menu and then click on \"MachineSets\" In the main pane you will see the same information about the machine sets from the command line. Now click on the \"three dots\" at the end of the line for the machine set that you scaled up to \"2\". Select \"Edit machine count\" and decrease it to \"1\". Click save. This will now decrease that machine set to only have one machine in it. a78436f (initial v2):aro-content/ops/2-2-worker-nodes.md","title":"Scale the number of nodes down via the Web Console"},{"location":"ops/day2/upgrades/","text":"Introduction # <<<<<<< HEAD:aro-content/ops/day2/upgrades.md Azure Red Hat OpenShift (ARO) provides fully-managed cluster updates. These updates can be triggered from inside the OpenShift Console, or scheduled in advance by utilizing the Managed Upgrade Operator. All updates are monitored and managed by the Red Hat and Microsoft ARO SRE team. For more information on how OpenShift's Upgrade Service works, please see the Red Hat documentation . Upgrade using the OpenShift Web Console # Return to your tab with the OpenShift Web Console. If you need to reauthenticate, follow the steps in the Access Your Cluster section. Using the menu on the left Select Administration -> Cluster Settings . Click on the Not Configured link under the Upgrade Channel heading. Upgrade channel is not configured by default By default, the upgrade channel (which is used to recommend the appropriate release versions for cluster updates), is not set in ARO. In the Channel field, enter stable-4.10 to set the upgrade channel to the stable releases of OpenShift 4.10 and click Save . In a moment, you'll begin to see what upgrades are available for your cluster. From here, you could click the Select a version button and upgrade the cluster, or you could follow the instructions below to use the Managed Upgrade Operator. Upgrade using the Managed Upgrade Operator # ======= a78436f (initial v2):aro-content/ops/2-1-upgrades.md The Managed Upgrade Operator has been created to manage the orchestration of automated in-place cluster upgrades. Whilst the operator's job is to invoke a cluster upgrade, it does not perform any activities of the cluster upgrade process itself. This remains the responsibility of the OpenShift Container Platform. The operator's goal is to satisfy the operating conditions that a managed cluster must hold, both pre- and post-invocation of the cluster upgrade. Examples of activities that are not core to an OpenShift upgrade process but could be handled by the operator include: Pre and post-upgrade health checks. Worker capacity scaling during the upgrade period. Alerting silence window management. Configuring the Managed Upgrade Operator for ARO ensures that your cluster functions as you need it to during upgrades. The process of executing upgrades is shown here: <<<<<<< HEAD:aro-content/ops/day2/upgrades.md 1. First, let's check for available upgrades on your current upgrade channel. To do so, run the following command: # Enable the Managed Upgrade Operator # a78436f (initial v2):aro-content/ops/2-1-upgrades.md Run this oc command to enable the Managed Upgrade Operator (MUO) oc patch cluster.aro.openshift.io cluster --patch \\ '{\"spec\":{\"operatorflags\":{\"rh.srep.muo.enabled\": \"true\",\"rh.srep.muo.managed\": \"true\",\"rh.srep.muo.deploy.pullspec\":\"arosvc.azurecr.io/managed-upgrade-operator@sha256:f57615aa690580a12c1e5031ad7ea674ce249c3d0f54e6dc4d070e42a9c9a274\"}}}' \\ --type=merge Wait a few moments to ensure the Management Upgrade Operator is ready, the status of the operator can be verified with: oc -n openshift-managed-upgrade-operator \\ get deployment managed-upgrade-operator NAME READY UP-TO-DATE AVAILABLE AGE managed-upgrade-operator 1/1 1 1 2m2s Configure the Managed Upgrade Operator # <<<<<<< HEAD:aro-content/ops/day2/upgrades.md 1. Once created, we can see that the update is pending by running the following command: ======= Next, configure the Managed Upgrade Operator by using the following YAML: a78436f (initial v2):aro-content/ops/2-1-upgrades.md muo-config-map.yaml apiVersion: v1 kind: ConfigMap metadata: name: managed-upgrade-operator-config namespace: openshift-managed-upgrade-operator data: config.yaml: | configManager: source: LOCAL localConfigName: managed-upgrade-config watchInterval: 1 maintenance: controlPlaneTime: 90 ignoredAlerts: controlPlaneCriticals: - ClusterOperatorDown - ClusterOperatorDegraded upgradeWindow: delayTrigger: 30 timeOut: 120 nodeDrain: timeOut: 45 expectedNodeDrainTime: 8 scale: timeOut: 30 healthCheck: ignoredCriticals: - PrometheusRuleFailures - CannotRetrieveUpdates - FluentdNodeDown ignoredNamespaces: - openshift-logging - openshift-redhat-marketplace - openshift-operators - openshift-user-workload-monitoring - openshift-pipelines You can apply the ConfigMap with this command: oc apply -f https://rh-mobb.github.io/aro-hackathon-content/assets/muo-config-map.yaml <<<<<<< HEAD:aro-content/ops/day2/upgrades.md Congratulations! You've successfully scheduled an upgrade of your cluster for tomorrow at this time. While the workshop environment will be deleted before then, you now have the experience to schedule upgrades in the future. ======= Restart the Managed Upgrade Operator oc -n openshift-managed-upgrade-operator \\ scale deployment managed-upgrade-operator --replicas=0 oc -n openshift-managed-upgrade-operator \\ scale deployment managed-upgrade-operator --replicas=1 Look for available Upgrades Info If the output is nil there are no available upgrades and you cannot continue. oc get clusterversion version -o jsonpath = '{.status.availableUpdates}' Schedule an Upgrade # Info Set the Channel and Version in the UpgradeConfig file to the desired values from the above list of available upgrades. The configuration below will schedule an upgrade for the current date / time + 5 minutes, allow PDB-blocked nodes to drain for 60 minutes before a drain is forced, and sets a capacity reservation so that workloads are not interrupted during an upgrade. muo-upgrade-config.yaml apiVersion: upgrade.managed.openshift.io/v1alpha1 kind: UpgradeConfig metadata: name: managed-upgrade-config namespace: openshift-managed-upgrade-operator spec: type: \"ARO\" upgradeAt: $(date -u --iso-8601=seconds --date \"+5 minutes\") PDBForceDrainTimeout: 60 capacityReservation: true desired: channel: \"stable-4.10\" version: \"4.10.28\" To apply the UpgradeConfig you can run the following commands: oc apply -f https://rh-mobb.github.io/aro-hackathon-content/assets/muo-upgrade-config.yaml Warning If the cluster is on the latest version, the upgrade will not apply. Check the status of the scheduled upgrade c -n openshift-managed-upgrade-operator get \\ upgradeconfigs.upgrade.managed.openshift.io \\ managed-upgrade-config -o jsonpath = '{.status}' | jq Info The output of this command should show upgrades in progress { \"history\" : [ { \"conditions\" : [ { \"lastProbeTime\" : \"2022-04-12T14:42:02Z\" , \"lastTransitionTime\" : \"2022-04-12T14:16:44Z\" , \"message\" : \"ControlPlaneUpgraded still in progress\" , \"reason\" : \"ControlPlaneUpgraded not done\" , \"startTime\" : \"2022-04-12T14:16:44Z\" , \"status\" : \"False\" , \"type\" : \"ControlPlaneUpgraded\" }, You can verify the upgrade has completed successfully via the following oc get clusterversion version NAME VERSION AVAILABLE PROGRESSING SINCE STATUS version 4 .9.27 True False 161m Cluster version is 4 .9.27 a78436f (initial v2):aro-content/ops/2-1-upgrades.md","title":"Managing Upgrades"},{"location":"ops/day2/upgrades/#introduction","text":"<<<<<<< HEAD:aro-content/ops/day2/upgrades.md Azure Red Hat OpenShift (ARO) provides fully-managed cluster updates. These updates can be triggered from inside the OpenShift Console, or scheduled in advance by utilizing the Managed Upgrade Operator. All updates are monitored and managed by the Red Hat and Microsoft ARO SRE team. For more information on how OpenShift's Upgrade Service works, please see the Red Hat documentation .","title":"Introduction"},{"location":"ops/day2/upgrades/#upgrade-using-the-openshift-web-console","text":"Return to your tab with the OpenShift Web Console. If you need to reauthenticate, follow the steps in the Access Your Cluster section. Using the menu on the left Select Administration -> Cluster Settings . Click on the Not Configured link under the Upgrade Channel heading. Upgrade channel is not configured by default By default, the upgrade channel (which is used to recommend the appropriate release versions for cluster updates), is not set in ARO. In the Channel field, enter stable-4.10 to set the upgrade channel to the stable releases of OpenShift 4.10 and click Save . In a moment, you'll begin to see what upgrades are available for your cluster. From here, you could click the Select a version button and upgrade the cluster, or you could follow the instructions below to use the Managed Upgrade Operator.","title":"Upgrade using the OpenShift Web Console"},{"location":"ops/day2/upgrades/#upgrade-using-the-managed-upgrade-operator","text":"======= a78436f (initial v2):aro-content/ops/2-1-upgrades.md The Managed Upgrade Operator has been created to manage the orchestration of automated in-place cluster upgrades. Whilst the operator's job is to invoke a cluster upgrade, it does not perform any activities of the cluster upgrade process itself. This remains the responsibility of the OpenShift Container Platform. The operator's goal is to satisfy the operating conditions that a managed cluster must hold, both pre- and post-invocation of the cluster upgrade. Examples of activities that are not core to an OpenShift upgrade process but could be handled by the operator include: Pre and post-upgrade health checks. Worker capacity scaling during the upgrade period. Alerting silence window management. Configuring the Managed Upgrade Operator for ARO ensures that your cluster functions as you need it to during upgrades. The process of executing upgrades is shown here: <<<<<<< HEAD:aro-content/ops/day2/upgrades.md","title":"Upgrade using the Managed Upgrade Operator"},{"location":"ops/day2/upgrades/#1-first-lets-check-for-available-upgrades-on-your-current-upgrade-channel-to-do-so-run-the-following-command","text":"","title":"1. First, let's check for available upgrades on your current upgrade channel. To do so, run the following command:"},{"location":"ops/day2/upgrades/#enable-the-managed-upgrade-operator","text":"a78436f (initial v2):aro-content/ops/2-1-upgrades.md Run this oc command to enable the Managed Upgrade Operator (MUO) oc patch cluster.aro.openshift.io cluster --patch \\ '{\"spec\":{\"operatorflags\":{\"rh.srep.muo.enabled\": \"true\",\"rh.srep.muo.managed\": \"true\",\"rh.srep.muo.deploy.pullspec\":\"arosvc.azurecr.io/managed-upgrade-operator@sha256:f57615aa690580a12c1e5031ad7ea674ce249c3d0f54e6dc4d070e42a9c9a274\"}}}' \\ --type=merge Wait a few moments to ensure the Management Upgrade Operator is ready, the status of the operator can be verified with: oc -n openshift-managed-upgrade-operator \\ get deployment managed-upgrade-operator NAME READY UP-TO-DATE AVAILABLE AGE managed-upgrade-operator 1/1 1 1 2m2s","title":"Enable the Managed Upgrade Operator"},{"location":"ops/day2/upgrades/#configure-the-managed-upgrade-operator","text":"<<<<<<< HEAD:aro-content/ops/day2/upgrades.md 1. Once created, we can see that the update is pending by running the following command: ======= Next, configure the Managed Upgrade Operator by using the following YAML: a78436f (initial v2):aro-content/ops/2-1-upgrades.md muo-config-map.yaml apiVersion: v1 kind: ConfigMap metadata: name: managed-upgrade-operator-config namespace: openshift-managed-upgrade-operator data: config.yaml: | configManager: source: LOCAL localConfigName: managed-upgrade-config watchInterval: 1 maintenance: controlPlaneTime: 90 ignoredAlerts: controlPlaneCriticals: - ClusterOperatorDown - ClusterOperatorDegraded upgradeWindow: delayTrigger: 30 timeOut: 120 nodeDrain: timeOut: 45 expectedNodeDrainTime: 8 scale: timeOut: 30 healthCheck: ignoredCriticals: - PrometheusRuleFailures - CannotRetrieveUpdates - FluentdNodeDown ignoredNamespaces: - openshift-logging - openshift-redhat-marketplace - openshift-operators - openshift-user-workload-monitoring - openshift-pipelines You can apply the ConfigMap with this command: oc apply -f https://rh-mobb.github.io/aro-hackathon-content/assets/muo-config-map.yaml <<<<<<< HEAD:aro-content/ops/day2/upgrades.md Congratulations! You've successfully scheduled an upgrade of your cluster for tomorrow at this time. While the workshop environment will be deleted before then, you now have the experience to schedule upgrades in the future. ======= Restart the Managed Upgrade Operator oc -n openshift-managed-upgrade-operator \\ scale deployment managed-upgrade-operator --replicas=0 oc -n openshift-managed-upgrade-operator \\ scale deployment managed-upgrade-operator --replicas=1 Look for available Upgrades Info If the output is nil there are no available upgrades and you cannot continue. oc get clusterversion version -o jsonpath = '{.status.availableUpdates}'","title":"Configure the Managed Upgrade Operator"},{"location":"ops/day2/upgrades/#schedule-an-upgrade","text":"Info Set the Channel and Version in the UpgradeConfig file to the desired values from the above list of available upgrades. The configuration below will schedule an upgrade for the current date / time + 5 minutes, allow PDB-blocked nodes to drain for 60 minutes before a drain is forced, and sets a capacity reservation so that workloads are not interrupted during an upgrade. muo-upgrade-config.yaml apiVersion: upgrade.managed.openshift.io/v1alpha1 kind: UpgradeConfig metadata: name: managed-upgrade-config namespace: openshift-managed-upgrade-operator spec: type: \"ARO\" upgradeAt: $(date -u --iso-8601=seconds --date \"+5 minutes\") PDBForceDrainTimeout: 60 capacityReservation: true desired: channel: \"stable-4.10\" version: \"4.10.28\" To apply the UpgradeConfig you can run the following commands: oc apply -f https://rh-mobb.github.io/aro-hackathon-content/assets/muo-upgrade-config.yaml Warning If the cluster is on the latest version, the upgrade will not apply. Check the status of the scheduled upgrade c -n openshift-managed-upgrade-operator get \\ upgradeconfigs.upgrade.managed.openshift.io \\ managed-upgrade-config -o jsonpath = '{.status}' | jq Info The output of this command should show upgrades in progress { \"history\" : [ { \"conditions\" : [ { \"lastProbeTime\" : \"2022-04-12T14:42:02Z\" , \"lastTransitionTime\" : \"2022-04-12T14:16:44Z\" , \"message\" : \"ControlPlaneUpgraded still in progress\" , \"reason\" : \"ControlPlaneUpgraded not done\" , \"startTime\" : \"2022-04-12T14:16:44Z\" , \"status\" : \"False\" , \"type\" : \"ControlPlaneUpgraded\" }, You can verify the upgrade has completed successfully via the following oc get clusterversion version NAME VERSION AVAILABLE PROGRESSING SINCE STATUS version 4 .9.27 True False 161m Cluster version is 4 .9.27 a78436f (initial v2):aro-content/ops/2-1-upgrades.md","title":"Schedule an Upgrade"},{"location":"service-mesh/deploy-control-plane/","text":"Red Hat OpenShift Service Mesh # Based on the open source Istio project, Red Hat OpenShift Service Mesh adds a transparent layer on existing distributed applications without requiring any changes to the service code. You add Red Hat OpenShift Service Mesh support to services by deploying a special sidecar proxy to relevant services in the mesh that intercepts all network communication between microservices. You configure and manage the Service Mesh using the Service Mesh control plane features. Deploy Control Plane # Create a project named istio-system. oc new-project istio-system Look over this example ServiceMeshControlPlane resource Example version 2.2 istio-installation.yaml apiVersion : maistra.io/v2 kind : ServiceMeshControlPlane metadata : name : basic namespace : istio-system spec : version : v2.2 tracing : type : Jaeger sampling : 10000 addons : jaeger : name : jaeger install : storage : type : Memory kiali : enabled : true name : kiali grafana : enabled : true Run the following command to deploy the Service Mesh control plane. oc create -n istio-system -f \\ https://raw.githubusercontent.com/rh-mobb/aro-hackathon-content/main/aro-content/assets/istio_installation.yaml To watch the progress of the pod deployment, run the following command: oc get pods -n istio-system -w You should see output similar to the following: NAME READY STATUS RESTARTS AGE grafana-b4d59bd7-mrgbr 2/2 Running 0 65m istio-egressgateway-678dc97b4c-wrjkp 1/1 Running 0 108s istio-ingressgateway-b45c9d54d-4qg6n 1/1 Running 0 108s istiod-basic-55d78bbbcd-j5556 1/1 Running 0 108s jaeger-67c75bd6dc-jv6k6 2/2 Running 0 65m kiali-6476c7656c-x5msp 1/1 Running 0 43m prometheus-58954b8d6b-m5std 2/2 Running 0 66m wasm-cacher-basic-8c986c75-vj2cd 1/1 Running 0 65m Run the following command to verify the Service Mesh control plane installation, where istio-system is the namespace where you installed the Service Mesh control plane. oc get smcp -n istio-system The installation has finished successfully when the STATUS column is ComponentsReady NAME READY STATUS PROFILES VERSION AGE basic 10/10 ComponentsReady [\"default\"] 2.1.1 66m","title":"[Red Hat OpenShift Service Mesh](https://docs.openshift.com/container-platform/4.11/service_mesh/v1x/ossm-architecture.html)"},{"location":"service-mesh/deploy-control-plane/#red-hat-openshift-service-mesh","text":"Based on the open source Istio project, Red Hat OpenShift Service Mesh adds a transparent layer on existing distributed applications without requiring any changes to the service code. You add Red Hat OpenShift Service Mesh support to services by deploying a special sidecar proxy to relevant services in the mesh that intercepts all network communication between microservices. You configure and manage the Service Mesh using the Service Mesh control plane features.","title":"Red Hat OpenShift Service Mesh"},{"location":"service-mesh/deploy-control-plane/#deploy-control-plane","text":"Create a project named istio-system. oc new-project istio-system Look over this example ServiceMeshControlPlane resource Example version 2.2 istio-installation.yaml apiVersion : maistra.io/v2 kind : ServiceMeshControlPlane metadata : name : basic namespace : istio-system spec : version : v2.2 tracing : type : Jaeger sampling : 10000 addons : jaeger : name : jaeger install : storage : type : Memory kiali : enabled : true name : kiali grafana : enabled : true Run the following command to deploy the Service Mesh control plane. oc create -n istio-system -f \\ https://raw.githubusercontent.com/rh-mobb/aro-hackathon-content/main/aro-content/assets/istio_installation.yaml To watch the progress of the pod deployment, run the following command: oc get pods -n istio-system -w You should see output similar to the following: NAME READY STATUS RESTARTS AGE grafana-b4d59bd7-mrgbr 2/2 Running 0 65m istio-egressgateway-678dc97b4c-wrjkp 1/1 Running 0 108s istio-ingressgateway-b45c9d54d-4qg6n 1/1 Running 0 108s istiod-basic-55d78bbbcd-j5556 1/1 Running 0 108s jaeger-67c75bd6dc-jv6k6 2/2 Running 0 65m kiali-6476c7656c-x5msp 1/1 Running 0 43m prometheus-58954b8d6b-m5std 2/2 Running 0 66m wasm-cacher-basic-8c986c75-vj2cd 1/1 Running 0 65m Run the following command to verify the Service Mesh control plane installation, where istio-system is the namespace where you installed the Service Mesh control plane. oc get smcp -n istio-system The installation has finished successfully when the STATUS column is ComponentsReady NAME READY STATUS PROFILES VERSION AGE basic 10/10 ComponentsReady [\"default\"] 2.1.1 66m","title":"Deploy Control Plane"},{"location":"service-mesh/deploy-workload/","text":"Deploying Workloads # Create project. oc new-project bookinfo oc label namespace bookinfo istio-injection = enabled Run the following command to create the Service Mesh Member Roll The ServiceMeshMemberRoll lists the projects that belong to the Service Mesh control plane. Only projects listed in the ServiceMeshMemberRoll are affected by the control plane. A project does not belong to a service mesh until you add it to the member roll for a particular control plane deployment. You must create a ServiceMeshMemberRoll resource named default in the same project as the ServiceMeshControlPlane , for example istio-system . cat << EOF | oc create -n istio-system -f - apiVersion: maistra.io/v1 kind: ServiceMeshMemberRoll metadata: name: default spec: members: - bookinfo EOF Run the following command to verify the ServiceMeshMemberRoll was created successfully. oc get smmr -n istio-system -o wide The installation has finished successfully when the STATUS column is Configured. NAME READY STATUS AGE MEMBERS default 1/1 Configured 70s [\"bookinfo\"] From the CLI, deploy the Bookinfo application in the bookinfo project by applying the bookinfo.yaml file: oc apply -n bookinfo -f \\ https://raw.githubusercontent.com/rh-mobb/aro-hackathon-content/main/aro-content/assets/bookinfo.yaml You should see output similar to the following: service/details created serviceaccount/bookinfo-details created deployment.apps/details-v1 created service/ratings created serviceaccount/bookinfo-ratings created deployment.apps/ratings-v1 created service/reviews created serviceaccount/bookinfo-reviews created deployment.apps/reviews-v1 created deployment.apps/reviews-v2 created deployment.apps/reviews-v3 created service/productpage created serviceaccount/bookinfo-productpage created deployment.apps/productpage-v1 created Create the ingress gateway by applying the bookinfo-gateway.yaml file: oc apply -n bookinfo -f \\ https://raw.githubusercontent.com/rh-mobb/aro-hackathon-content/main/aro-content/assets/bookinfo-gateway.yaml You should see output similar to the following: gateway.networking.istio.io/bookinfo-gateway created virtualservice.networking.istio.io/bookinfo created Set the value for the GATEWAY_URL parameter: export GATEWAY_URL = $( oc -n istio-system get route istio-ingressgateway -o jsonpath = '{.spec.host}' ) echo \"export GATEWAY_URL= ${ GATEWAY_URL } \" >> ~/.workshoprc Adding default destination rules # To add destination rules, run one of the following commands: oc apply -n bookinfo -f \\ https://raw.githubusercontent.com/rh-mobb/aro-hackathon-content/main/aro-content/assets/destination-rule-all.yaml You should see output similar to the following: destinationrule.networking.istio.io/productpage created destinationrule.networking.istio.io/reviews created destinationrule.networking.istio.io/ratings created destinationrule.networking.istio.io/details created Verifying the Bookinfo installation # Verify that all pods are ready with this command: oc get pods -n bookinfo All pods should have a status of Running. You should see output similar to the following: NAME READY STATUS RESTARTS AGE details-v1-55b869668-jh7hb 2/2 Running 0 12m productpage-v1-6fc77ff794-nsl8r 2/2 Running 0 12m ratings-v1-7d7d8d8b56-55scn 2/2 Running 0 12m reviews-v1-868597db96-bdxgq 2/2 Running 0 12m reviews-v2-5b64f47978-cvssp 2/2 Running 0 12m reviews-v3-6dfd49b55b-vcwpf 2/2 Running 0 12m Run the following command to retrieve the URL for the product page: echo \"http:// $GATEWAY_URL /productpage\" Copy and paste the output in a web browser to verify the Bookinfo product page is deployed. You should see a book review of \"The Comedy of Errors\".","title":"Deploy workload"},{"location":"service-mesh/deploy-workload/#deploying-workloads","text":"Create project. oc new-project bookinfo oc label namespace bookinfo istio-injection = enabled Run the following command to create the Service Mesh Member Roll The ServiceMeshMemberRoll lists the projects that belong to the Service Mesh control plane. Only projects listed in the ServiceMeshMemberRoll are affected by the control plane. A project does not belong to a service mesh until you add it to the member roll for a particular control plane deployment. You must create a ServiceMeshMemberRoll resource named default in the same project as the ServiceMeshControlPlane , for example istio-system . cat << EOF | oc create -n istio-system -f - apiVersion: maistra.io/v1 kind: ServiceMeshMemberRoll metadata: name: default spec: members: - bookinfo EOF Run the following command to verify the ServiceMeshMemberRoll was created successfully. oc get smmr -n istio-system -o wide The installation has finished successfully when the STATUS column is Configured. NAME READY STATUS AGE MEMBERS default 1/1 Configured 70s [\"bookinfo\"] From the CLI, deploy the Bookinfo application in the bookinfo project by applying the bookinfo.yaml file: oc apply -n bookinfo -f \\ https://raw.githubusercontent.com/rh-mobb/aro-hackathon-content/main/aro-content/assets/bookinfo.yaml You should see output similar to the following: service/details created serviceaccount/bookinfo-details created deployment.apps/details-v1 created service/ratings created serviceaccount/bookinfo-ratings created deployment.apps/ratings-v1 created service/reviews created serviceaccount/bookinfo-reviews created deployment.apps/reviews-v1 created deployment.apps/reviews-v2 created deployment.apps/reviews-v3 created service/productpage created serviceaccount/bookinfo-productpage created deployment.apps/productpage-v1 created Create the ingress gateway by applying the bookinfo-gateway.yaml file: oc apply -n bookinfo -f \\ https://raw.githubusercontent.com/rh-mobb/aro-hackathon-content/main/aro-content/assets/bookinfo-gateway.yaml You should see output similar to the following: gateway.networking.istio.io/bookinfo-gateway created virtualservice.networking.istio.io/bookinfo created Set the value for the GATEWAY_URL parameter: export GATEWAY_URL = $( oc -n istio-system get route istio-ingressgateway -o jsonpath = '{.spec.host}' ) echo \"export GATEWAY_URL= ${ GATEWAY_URL } \" >> ~/.workshoprc","title":"Deploying Workloads"},{"location":"service-mesh/deploy-workload/#adding-default-destination-rules","text":"To add destination rules, run one of the following commands: oc apply -n bookinfo -f \\ https://raw.githubusercontent.com/rh-mobb/aro-hackathon-content/main/aro-content/assets/destination-rule-all.yaml You should see output similar to the following: destinationrule.networking.istio.io/productpage created destinationrule.networking.istio.io/reviews created destinationrule.networking.istio.io/ratings created destinationrule.networking.istio.io/details created","title":"Adding default destination rules"},{"location":"service-mesh/deploy-workload/#verifying-the-bookinfo-installation","text":"Verify that all pods are ready with this command: oc get pods -n bookinfo All pods should have a status of Running. You should see output similar to the following: NAME READY STATUS RESTARTS AGE details-v1-55b869668-jh7hb 2/2 Running 0 12m productpage-v1-6fc77ff794-nsl8r 2/2 Running 0 12m ratings-v1-7d7d8d8b56-55scn 2/2 Running 0 12m reviews-v1-868597db96-bdxgq 2/2 Running 0 12m reviews-v2-5b64f47978-cvssp 2/2 Running 0 12m reviews-v3-6dfd49b55b-vcwpf 2/2 Running 0 12m Run the following command to retrieve the URL for the product page: echo \"http:// $GATEWAY_URL /productpage\" Copy and paste the output in a web browser to verify the Bookinfo product page is deployed. You should see a book review of \"The Comedy of Errors\".","title":"Verifying the Bookinfo installation"},{"location":"service-mesh/install/","text":"Operator Overview # Red Hat OpenShift Service Mesh requires the following four Operators: # OpenShift Elasticsearch - (Optional) Provides database storage for tracing and logging with the distributed tracing platform. It is based on the open source Elasticsearch project. Red Hat OpenShift distributed tracing platform - Provides distributed tracing to monitor and troubleshoot transactions in complex distributed systems. It is based on the open source Jaeger project. Kiali - Provides observability for your service mesh. Allows you to view configurations, monitor traffic, and analyze traces in a single console. It is based on the open source Kiali project. Red Hat OpenShift Service Mesh - Allows you to connect, secure, control, and observe the microservices that comprise your applications. The Service Mesh Operator defines and monitors the ServiceMeshControlPlane resources that manage the deployment, updating, and deletion of the Service Mesh components. It is based on the open source Istio project. Installing the Operators # To install Red Hat OpenShift Service Mesh, install following Operators in this order. Repeat the procedure for each Operator. # OpenShift Elasticsearch Red Hat OpenShift distributed tracing platform Kiali Red Hat OpenShift Service Mesh Procedure # Log in to the OpenShift Container Platform web console as a user with the cluster-admin role. If you use Red Hat OpenShift Dedicated, you must have an account with the dedicated-admin role. In the OpenShift Container Platform web console, click Operators \u2192 OperatorHub. Type the name of the Operator into the filter box and select the Red Hat version of the Operator. Community versions of the Operators are not supported. Click Install . On the Install Operator page for each Operator, accept the default settings. Click Install . Wait until the Operator has installed before repeating the steps for the next Operator in the list. The OpenShift Elasticsearch Operator is installed in the openshift-operators-redhat namespace and is available for all namespaces in the cluster. The Red Hat OpenShift distributed tracing platform is installed in the openshift-distributed-tracing namespace and is available for all namespaces in the cluster. The Kiali and Red Hat OpenShift Service Mesh Operators are installed in the openshift-operators namespace and are available for all namespaces in the cluster. After all you have installed all four Operators, click Operators \u2192 Installed Operators to verify that your Operators installed.","title":"Install"},{"location":"service-mesh/install/#operator-overview","text":"","title":"Operator Overview"},{"location":"service-mesh/install/#red-hat-openshift-service-mesh-requires-the-following-four-operators","text":"OpenShift Elasticsearch - (Optional) Provides database storage for tracing and logging with the distributed tracing platform. It is based on the open source Elasticsearch project. Red Hat OpenShift distributed tracing platform - Provides distributed tracing to monitor and troubleshoot transactions in complex distributed systems. It is based on the open source Jaeger project. Kiali - Provides observability for your service mesh. Allows you to view configurations, monitor traffic, and analyze traces in a single console. It is based on the open source Kiali project. Red Hat OpenShift Service Mesh - Allows you to connect, secure, control, and observe the microservices that comprise your applications. The Service Mesh Operator defines and monitors the ServiceMeshControlPlane resources that manage the deployment, updating, and deletion of the Service Mesh components. It is based on the open source Istio project.","title":"Red Hat OpenShift Service Mesh requires the following four Operators:"},{"location":"service-mesh/install/#installing-the-operators","text":"","title":"Installing the Operators"},{"location":"service-mesh/install/#to-install-red-hat-openshift-service-mesh-install-following-operators-in-this-order-repeat-the-procedure-for-each-operator","text":"OpenShift Elasticsearch Red Hat OpenShift distributed tracing platform Kiali Red Hat OpenShift Service Mesh","title":"To install Red Hat OpenShift Service Mesh, install following Operators in this order. Repeat the procedure for each Operator."},{"location":"service-mesh/install/#procedure","text":"Log in to the OpenShift Container Platform web console as a user with the cluster-admin role. If you use Red Hat OpenShift Dedicated, you must have an account with the dedicated-admin role. In the OpenShift Container Platform web console, click Operators \u2192 OperatorHub. Type the name of the Operator into the filter box and select the Red Hat version of the Operator. Community versions of the Operators are not supported. Click Install . On the Install Operator page for each Operator, accept the default settings. Click Install . Wait until the Operator has installed before repeating the steps for the next Operator in the list. The OpenShift Elasticsearch Operator is installed in the openshift-operators-redhat namespace and is available for all namespaces in the cluster. The Red Hat OpenShift distributed tracing platform is installed in the openshift-distributed-tracing namespace and is available for all namespaces in the cluster. The Kiali and Red Hat OpenShift Service Mesh Operators are installed in the openshift-operators namespace and are available for all namespaces in the cluster. After all you have installed all four Operators, click Operators \u2192 Installed Operators to verify that your Operators installed.","title":"Procedure"},{"location":"service-mesh/introduction/","text":"Red Hat Service Mesh # What is Red Hat Service Mesh? # As your applications evolve into collections of decentralized microservices, monitoring and managing the network communications and security among those multiple services becomes more challenging. Red Hat OpenShift Service Mesh is based on the open source project Istio. It provides a uniform way to connect, manage, and observe microservices based applications. It provides behavioral insight into and control of the networked microservices in your service mesh. Why Red Hat Service Mesh? # Applications are changing from monoliths into collections of small, independent, and loosely coupled services often referred to as cloud-native applications. These services are organized in a microservices architecture. Managing the communication between different services, and analyzing and maintaining security, can be a challenge. This can be greatly simplified and optimized by using a service mesh to route requests from one service to another, and optimizing how the different services work with one another. With Red Hat OpenShift Service Mesh, you get a uniform way to connect, manage, and observe your microservices, without requiring you to redesign your application. As your containers and services evolve, Service Mesh allows you control of\u2014the networked microservices through the use of a sidecar proxy that intercepts network communication between microservices. OpenShift Service Mesh provides integrated metrics, logging, and tracing, traditionally available only deep within the application or service. Red Hat Service Mesh Benefits # Ready for production # Installs easily on Red Hat OpenShift, the hybrid cloud enterprise Kubernetes platform trusted by thousands of organizations around the globe. Red Hat OpenShift Service Mesh is pre-validated and fully supported to work on Red Hat OpenShift, straight out of the box. Security-focused # Red Hat OpenShift Service Mesh provides comprehensive application networking security. This is achieved through transparent mTLS encryption and fine-grained policies that facilitate zero-trust networking. Based on open source # Based on the open source Istio project, Red Hat OpenShift Service Mesh provides additional functionality with the inclusion of other open source projects like Kiali (Istio console) and Jaeger (distributed tracing), which supports collaboration with leading members of the Istio community. Use Cases # Connectivity: Connect Traffic Flow, Blue/Green Deployments, Circuit Breaking, Virtual Services Security: Data-in-transit Encryption, Authentication, Authorization, Secure Naming Control: Configuration, Apply/Enforce Policies, Fair Resource Distribution Observability: Layer 7 Visibility, Monitoring, Logging, Distributed Tracing Difference Between Istio # OpenShift Service Mesh installs a multi-tenant control plane by default OpenShift Service Mesh extends Role Based Access Control (RBAC) features OpenShift Service Mesh replaces BoringSSL with OpenSSL Kiali and Jaeger are enabled by default in OpenShift Service Mesh What is the advantage of choosing Red Hat Service Mesh? # Red Hat helps you get started faster because OpenShift Service Mesh is engineered to be ready for production. With OpenShift Service Mesh developers can increase productivity by integrating communication policies without changing application code or integrating language-specific libraries. OpenShift Service Mesh can also make things easier for operations because it installs easily on Red Hat OpenShift, has been tested with other Red Hat products, and comes with access to award-winning support.","title":"Red Hat Service Mesh"},{"location":"service-mesh/introduction/#red-hat-service-mesh","text":"","title":"Red Hat Service Mesh"},{"location":"service-mesh/introduction/#what-is-red-hat-service-mesh","text":"As your applications evolve into collections of decentralized microservices, monitoring and managing the network communications and security among those multiple services becomes more challenging. Red Hat OpenShift Service Mesh is based on the open source project Istio. It provides a uniform way to connect, manage, and observe microservices based applications. It provides behavioral insight into and control of the networked microservices in your service mesh.","title":"What is Red Hat Service Mesh?"},{"location":"service-mesh/introduction/#why-red-hat-service-mesh","text":"Applications are changing from monoliths into collections of small, independent, and loosely coupled services often referred to as cloud-native applications. These services are organized in a microservices architecture. Managing the communication between different services, and analyzing and maintaining security, can be a challenge. This can be greatly simplified and optimized by using a service mesh to route requests from one service to another, and optimizing how the different services work with one another. With Red Hat OpenShift Service Mesh, you get a uniform way to connect, manage, and observe your microservices, without requiring you to redesign your application. As your containers and services evolve, Service Mesh allows you control of\u2014the networked microservices through the use of a sidecar proxy that intercepts network communication between microservices. OpenShift Service Mesh provides integrated metrics, logging, and tracing, traditionally available only deep within the application or service.","title":"Why Red Hat Service Mesh?"},{"location":"service-mesh/introduction/#red-hat-service-mesh-benefits","text":"","title":"Red Hat Service Mesh Benefits"},{"location":"service-mesh/introduction/#ready-for-production","text":"Installs easily on Red Hat OpenShift, the hybrid cloud enterprise Kubernetes platform trusted by thousands of organizations around the globe. Red Hat OpenShift Service Mesh is pre-validated and fully supported to work on Red Hat OpenShift, straight out of the box.","title":"Ready for production"},{"location":"service-mesh/introduction/#security-focused","text":"Red Hat OpenShift Service Mesh provides comprehensive application networking security. This is achieved through transparent mTLS encryption and fine-grained policies that facilitate zero-trust networking.","title":"Security-focused"},{"location":"service-mesh/introduction/#based-on-open-source","text":"Based on the open source Istio project, Red Hat OpenShift Service Mesh provides additional functionality with the inclusion of other open source projects like Kiali (Istio console) and Jaeger (distributed tracing), which supports collaboration with leading members of the Istio community.","title":"Based on open source"},{"location":"service-mesh/introduction/#use-cases","text":"Connectivity: Connect Traffic Flow, Blue/Green Deployments, Circuit Breaking, Virtual Services Security: Data-in-transit Encryption, Authentication, Authorization, Secure Naming Control: Configuration, Apply/Enforce Policies, Fair Resource Distribution Observability: Layer 7 Visibility, Monitoring, Logging, Distributed Tracing","title":"Use Cases"},{"location":"service-mesh/introduction/#difference-between-istio","text":"OpenShift Service Mesh installs a multi-tenant control plane by default OpenShift Service Mesh extends Role Based Access Control (RBAC) features OpenShift Service Mesh replaces BoringSSL with OpenSSL Kiali and Jaeger are enabled by default in OpenShift Service Mesh","title":"Difference Between Istio"},{"location":"service-mesh/introduction/#what-is-the-advantage-of-choosing-red-hat-service-mesh","text":"Red Hat helps you get started faster because OpenShift Service Mesh is engineered to be ready for production. With OpenShift Service Mesh developers can increase productivity by integrating communication policies without changing application code or integrating language-specific libraries. OpenShift Service Mesh can also make things easier for operations because it installs easily on Red Hat OpenShift, has been tested with other Red Hat products, and comes with access to award-winning support.","title":"What is the advantage of choosing Red Hat Service Mesh?"},{"location":"service-mesh/kiali/","text":"Kiali Web Console # Obtain the address for the Kiali web console. # Login to the OpenShift Container Platform web console as a user with cluster-admin rights. If you use Red Hat OpenShift Dedicated, you must have an account with the dedicated-admin role. Navigate to project to Networking \u2192 Routes. Click on the Routes tab, select the Service Mesh control plane project, for example istio-system, from the Namespace menu. The Location column displays the linked address for each route. Click the link in the Location column for Kiali. Click Login With OpenShift . The Kiali Overview screen presents tiles for each project namespace. Use Cluster Credentials to login. az aro list-credentials \\ --name $AZR_CLUSTER \\ --resource-group $AZR_RESOURCE_GROUP \\ -o tsv Refresh URL atleast 10 times in the browser to generate traffic for your graph. Kiali Console. Change Time Settings to Last 6 hours and Every 15 minutes. In Kiali, click Graph. Select bookinfo from the Namespace list, and App graph from the Graph Type list. Click Display idle nodes. View Graph and change display settings to add or remove information from the graph. Click Workload tab Select Details Workload","title":"Kiali"},{"location":"service-mesh/kiali/#kiali-web-console","text":"","title":"Kiali Web Console"},{"location":"service-mesh/kiali/#obtain-the-address-for-the-kiali-web-console","text":"Login to the OpenShift Container Platform web console as a user with cluster-admin rights. If you use Red Hat OpenShift Dedicated, you must have an account with the dedicated-admin role. Navigate to project to Networking \u2192 Routes. Click on the Routes tab, select the Service Mesh control plane project, for example istio-system, from the Namespace menu. The Location column displays the linked address for each route. Click the link in the Location column for Kiali. Click Login With OpenShift . The Kiali Overview screen presents tiles for each project namespace. Use Cluster Credentials to login. az aro list-credentials \\ --name $AZR_CLUSTER \\ --resource-group $AZR_RESOURCE_GROUP \\ -o tsv Refresh URL atleast 10 times in the browser to generate traffic for your graph. Kiali Console. Change Time Settings to Last 6 hours and Every 15 minutes. In Kiali, click Graph. Select bookinfo from the Namespace list, and App graph from the Graph Type list. Click Display idle nodes. View Graph and change display settings to add or remove information from the graph. Click Workload tab Select Details Workload","title":"Obtain the address for the Kiali web console."},{"location":"service-mesh/weighted-routing/","text":"Configuring virtual services # Requests are routed to services within a service mesh with virtual services. Each virtual service consists of a set of routing rules that are evaluated in order. Red Hat OpenShift Service Mesh matches each given request to the virtual service to a specific real destination within the mesh. Without virtual services, Red Hat OpenShift Service Mesh distributes traffic using round-robin load balancing between all service instances. With a virtual service, you can specify traffic behavior for one or more hostnames. Routing rules in the virtual service tell Red Hat OpenShift Service Mesh how to send the traffic for the virtual service to appropriate destinations. Route destinations can be versions of the same service or entirely different services. Weighted Load Balancing # Weighted: Requests are forwarded to instances in the pool according to a specific percentage. Deploy virtual service. virtual-service-reviews-80-20.yaml apiVersion: networking.istio.io/v1alpha3 kind: VirtualService metadata: name: reviews spec: hosts: - reviews http: - route: - destination: host: reviews subset: v1 weight: 80 - destination: host: reviews subset: v2 weight: 20 oc apply -f https://raw.githubusercontent.com/rh-mobb/aro-hackathon-content/main/aro-content/assets/virtual-service-reviews-80-20.yaml <<<<<<< HEAD:aro-content/service-mesh/weighted-routing.md cat << EOF | oc create -f - apiVersion: networking.istio.io/v1alpha3 kind: VirtualService metadata: name: reviews spec: hosts: - reviews http: - route: - destination: host: reviews subset: v1 weight: 80 - destination: host: reviews subset: v2 weight: 20 EOF Refresh the browser tab containing Bookinfo URL a few times and you'll see that occasionally you'll see the v2 of the book review app which has star ratings. Generate traffic by using the following snippet while true ; do curl -sSL \"http:// $GATEWAY_URL /productpage\" | head -n 5 ; sleep 1 ; done 1. Leave the loop running and move onto the next steps. # Refresh Bookinfo URL and view changes in traffic for reviews app on the Graph tab in Kiali. a78436f (initial v2):aro-content/service-meshv2/3-weighted-routing.md","title":"Weighted routing"},{"location":"service-mesh/weighted-routing/#configuring-virtual-services","text":"Requests are routed to services within a service mesh with virtual services. Each virtual service consists of a set of routing rules that are evaluated in order. Red Hat OpenShift Service Mesh matches each given request to the virtual service to a specific real destination within the mesh. Without virtual services, Red Hat OpenShift Service Mesh distributes traffic using round-robin load balancing between all service instances. With a virtual service, you can specify traffic behavior for one or more hostnames. Routing rules in the virtual service tell Red Hat OpenShift Service Mesh how to send the traffic for the virtual service to appropriate destinations. Route destinations can be versions of the same service or entirely different services.","title":"Configuring virtual services"},{"location":"service-mesh/weighted-routing/#weighted-load-balancing","text":"Weighted: Requests are forwarded to instances in the pool according to a specific percentage. Deploy virtual service. virtual-service-reviews-80-20.yaml apiVersion: networking.istio.io/v1alpha3 kind: VirtualService metadata: name: reviews spec: hosts: - reviews http: - route: - destination: host: reviews subset: v1 weight: 80 - destination: host: reviews subset: v2 weight: 20 oc apply -f https://raw.githubusercontent.com/rh-mobb/aro-hackathon-content/main/aro-content/assets/virtual-service-reviews-80-20.yaml <<<<<<< HEAD:aro-content/service-mesh/weighted-routing.md cat << EOF | oc create -f - apiVersion: networking.istio.io/v1alpha3 kind: VirtualService metadata: name: reviews spec: hosts: - reviews http: - route: - destination: host: reviews subset: v1 weight: 80 - destination: host: reviews subset: v2 weight: 20 EOF Refresh the browser tab containing Bookinfo URL a few times and you'll see that occasionally you'll see the v2 of the book review app which has star ratings. Generate traffic by using the following snippet while true ; do curl -sSL \"http:// $GATEWAY_URL /productpage\" | head -n 5 ; sleep 1 ; done","title":"Weighted Load Balancing"},{"location":"service-mesh/weighted-routing/#1-leave-the-loop-running-and-move-onto-the-next-steps","text":"Refresh Bookinfo URL and view changes in traffic for reviews app on the Graph tab in Kiali. a78436f (initial v2):aro-content/service-meshv2/3-weighted-routing.md","title":"1. Leave the loop running and move onto the next steps."},{"location":"service-meshv2/1-deploy-control-plane/","text":"Red Hat OpenShift Service Mesh # Based on the open source Istio project, Red Hat OpenShift Service Mesh adds a transparent layer on existing distributed applications without requiring any changes to the service code. You add Red Hat OpenShift Service Mesh support to services by deploying a special sidecar proxy to relevant services in the mesh that intercepts all network communication between microservices. You configure and manage the Service Mesh using the Service Mesh control plane features. Terminal Login # Click kubeadmin drop-down. Click display token. Copy oc login command into terminal. Deploy Control Plane # Log in to the OpenShift Container Platform CLI. oc login https://<HOSTNAME>:6443 Create a project named istio-system. oc new-project istio-system Create a ServiceMeshControlPlane file named istio-installation.yaml. Example version 2.2 istio-installation.yaml apiVersion: maistra.io/v2 kind: ServiceMeshControlPlane metadata: name: basic namespace: istio-system spec: version: v2.2 tracing: type: Jaeger sampling: 10000 addons: jaeger: name: jaeger install: storage: type: Memory kiali: enabled: true name: kiali grafana: enabled: true 4. Run the following command to deploy the Service Mesh control plane. oc create -n istio-system -f https://raw.githubusercontent.com/rh-mobb/aro-hackathon-content/main/aro-content/assets/istio_installation.yaml 5. To watch the progress of the pod deployment, run the following command: oc get pods -n istio-system -w You should see output similar to the following: NAME READY STATUS RESTARTS AGE grafana-b4d59bd7-mrgbr 2/2 Running 0 65m istio-egressgateway-678dc97b4c-wrjkp 1/1 Running 0 108s istio-ingressgateway-b45c9d54d-4qg6n 1/1 Running 0 108s istiod-basic-55d78bbbcd-j5556 1/1 Running 0 108s jaeger-67c75bd6dc-jv6k6 2/2 Running 0 65m kiali-6476c7656c-x5msp 1/1 Running 0 43m prometheus-58954b8d6b-m5std 2/2 Running 0 66m wasm-cacher-basic-8c986c75-vj2cd 1/1 Running 0 65m Validating your SMCP installation with the CLI # Run the following command to verify the Service Mesh control plane installation, where istio-system is the namespace where you installed the Service Mesh control plane. oc get smcp -n istio-system The installation has finished successfully when the STATUS column is ComponentsReady NAME READY STATUS PROFILES VERSION AGE basic 10 /10 ComponentsReady [ \"default\" ] 2 .1.1 66m","title":"[Red Hat OpenShift Service Mesh](https://docs.openshift.com/container-platform/4.11/service_mesh/v1x/ossm-architecture.html)"},{"location":"service-meshv2/1-deploy-control-plane/#red-hat-openshift-service-mesh","text":"Based on the open source Istio project, Red Hat OpenShift Service Mesh adds a transparent layer on existing distributed applications without requiring any changes to the service code. You add Red Hat OpenShift Service Mesh support to services by deploying a special sidecar proxy to relevant services in the mesh that intercepts all network communication between microservices. You configure and manage the Service Mesh using the Service Mesh control plane features.","title":"Red Hat OpenShift Service Mesh"},{"location":"service-meshv2/1-deploy-control-plane/#terminal-login","text":"Click kubeadmin drop-down. Click display token. Copy oc login command into terminal.","title":"Terminal Login"},{"location":"service-meshv2/1-deploy-control-plane/#deploy-control-plane","text":"Log in to the OpenShift Container Platform CLI. oc login https://<HOSTNAME>:6443 Create a project named istio-system. oc new-project istio-system Create a ServiceMeshControlPlane file named istio-installation.yaml. Example version 2.2 istio-installation.yaml apiVersion: maistra.io/v2 kind: ServiceMeshControlPlane metadata: name: basic namespace: istio-system spec: version: v2.2 tracing: type: Jaeger sampling: 10000 addons: jaeger: name: jaeger install: storage: type: Memory kiali: enabled: true name: kiali grafana: enabled: true 4. Run the following command to deploy the Service Mesh control plane. oc create -n istio-system -f https://raw.githubusercontent.com/rh-mobb/aro-hackathon-content/main/aro-content/assets/istio_installation.yaml 5. To watch the progress of the pod deployment, run the following command: oc get pods -n istio-system -w You should see output similar to the following: NAME READY STATUS RESTARTS AGE grafana-b4d59bd7-mrgbr 2/2 Running 0 65m istio-egressgateway-678dc97b4c-wrjkp 1/1 Running 0 108s istio-ingressgateway-b45c9d54d-4qg6n 1/1 Running 0 108s istiod-basic-55d78bbbcd-j5556 1/1 Running 0 108s jaeger-67c75bd6dc-jv6k6 2/2 Running 0 65m kiali-6476c7656c-x5msp 1/1 Running 0 43m prometheus-58954b8d6b-m5std 2/2 Running 0 66m wasm-cacher-basic-8c986c75-vj2cd 1/1 Running 0 65m","title":"Deploy Control Plane"},{"location":"service-meshv2/1-deploy-control-plane/#validating-your-smcp-installation-with-the-cli","text":"Run the following command to verify the Service Mesh control plane installation, where istio-system is the namespace where you installed the Service Mesh control plane. oc get smcp -n istio-system The installation has finished successfully when the STATUS column is ComponentsReady NAME READY STATUS PROFILES VERSION AGE basic 10 /10 ComponentsReady [ \"default\" ] 2 .1.1 66m","title":"Validating your SMCP installation with the CLI"},{"location":"service-meshv2/2-deplying-workloads/","text":"Deploying Workloads # Create project. oc new-project bookinfo oc label namespace bookinfo istio-injection = enabled 2. Run the following command to create the Service Mesh Member Roll The ServiceMeshMemberRoll lists the projects that belong to the Service Mesh control plane. Only projects listed in the ServiceMeshMemberRoll are affected by the control plane. A project does not belong to a service mesh until you add it to the member roll for a particular control plane deployment. You must create a ServiceMeshMemberRoll resource named default in the same project as the ServiceMeshControlPlane, for example istio-system. oc create -n istio-system -f https://raw.githubusercontent.com/rh-mobb/aro-hackathon-content/main/aro-content/assets/servicemeshmemberroll-default.yaml 3. Run the following command to verify the ServiceMeshMemberRoll was created successfully. oc get smmr -n istio-system -o wide The installation has finished successfully when the STATUS column is Configured. NAME READY STATUS AGE MEMBERS default 1 /1 Configured 70s [ \"bookinfo\" ] 4. From the CLI, deploy the Bookinfo application in the bookinfo project by applying the bookinfo.yaml file: oc apply -n bookinfo -f https://raw.githubusercontent.com/rh-mobb/aro-hackathon-content/main/aro-content/assets/bookinfo.yaml You should see output similar to the following: service/details created serviceaccount/bookinfo-details created deployment.apps/details-v1 created service/ratings created serviceaccount/bookinfo-ratings created deployment.apps/ratings-v1 created service/reviews created serviceaccount/bookinfo-reviews created deployment.apps/reviews-v1 created deployment.apps/reviews-v2 created deployment.apps/reviews-v3 created service/productpage created serviceaccount/bookinfo-productpage created deployment.apps/productpage-v1 created 5. Create the ingress gateway by applying the bookinfo-gateway.yaml file: oc apply -n bookinfo -f https://raw.githubusercontent.com/rh-mobb/aro-hackathon-content/main/aro-content/assets/bookinfo-gateway.yaml You should see output similar to the following: gateway.networking.istio.io/bookinfo-gateway created virtualservice.networking.istio.io/bookinfo created 6. Set the value for the GATEWAY_URL parameter: export GATEWAY_URL = $( oc -n istio-system get route istio-ingressgateway -o jsonpath = '{.spec.host}' ) Adding default destination rules # To add destination rules, run one of the following commands: oc apply -n bookinfo -f https://raw.githubusercontent.com/rh-mobb/aro-hackathon-content/main/aro-content/assets/destination-rule-all.yaml You should see output similar to the following: destinationrule.networking.istio.io/productpage created destinationrule.networking.istio.io/reviews created destinationrule.networking.istio.io/ratings created destinationrule.networking.istio.io/details created Verifying the Bookinfo installation # Verify that all pods are ready with this command: oc get pods -n bookinfo All pods should have a status of Running. You should see output similar to the following: NAME READY STATUS RESTARTS AGE details-v1-55b869668-jh7hb 2 /2 Running 0 12m productpage-v1-6fc77ff794-nsl8r 2 /2 Running 0 12m ratings-v1-7d7d8d8b56-55scn 2 /2 Running 0 12m reviews-v1-868597db96-bdxgq 2 /2 Running 0 12m reviews-v2-5b64f47978-cvssp 2 /2 Running 0 12m reviews-v3-6dfd49b55b-vcwpf 2 /2 Running 0 12m Run the following command to retrieve the URL for the product page: echo \"http:// $GATEWAY_URL /productpage\" Copy and paste the output in a web browser to verify the Bookinfo product page is deployed. Verify in Kiali # Kiali Dashboard","title":"2 deplying workloads"},{"location":"service-meshv2/2-deplying-workloads/#deploying-workloads","text":"Create project. oc new-project bookinfo oc label namespace bookinfo istio-injection = enabled 2. Run the following command to create the Service Mesh Member Roll The ServiceMeshMemberRoll lists the projects that belong to the Service Mesh control plane. Only projects listed in the ServiceMeshMemberRoll are affected by the control plane. A project does not belong to a service mesh until you add it to the member roll for a particular control plane deployment. You must create a ServiceMeshMemberRoll resource named default in the same project as the ServiceMeshControlPlane, for example istio-system. oc create -n istio-system -f https://raw.githubusercontent.com/rh-mobb/aro-hackathon-content/main/aro-content/assets/servicemeshmemberroll-default.yaml 3. Run the following command to verify the ServiceMeshMemberRoll was created successfully. oc get smmr -n istio-system -o wide The installation has finished successfully when the STATUS column is Configured. NAME READY STATUS AGE MEMBERS default 1 /1 Configured 70s [ \"bookinfo\" ] 4. From the CLI, deploy the Bookinfo application in the bookinfo project by applying the bookinfo.yaml file: oc apply -n bookinfo -f https://raw.githubusercontent.com/rh-mobb/aro-hackathon-content/main/aro-content/assets/bookinfo.yaml You should see output similar to the following: service/details created serviceaccount/bookinfo-details created deployment.apps/details-v1 created service/ratings created serviceaccount/bookinfo-ratings created deployment.apps/ratings-v1 created service/reviews created serviceaccount/bookinfo-reviews created deployment.apps/reviews-v1 created deployment.apps/reviews-v2 created deployment.apps/reviews-v3 created service/productpage created serviceaccount/bookinfo-productpage created deployment.apps/productpage-v1 created 5. Create the ingress gateway by applying the bookinfo-gateway.yaml file: oc apply -n bookinfo -f https://raw.githubusercontent.com/rh-mobb/aro-hackathon-content/main/aro-content/assets/bookinfo-gateway.yaml You should see output similar to the following: gateway.networking.istio.io/bookinfo-gateway created virtualservice.networking.istio.io/bookinfo created 6. Set the value for the GATEWAY_URL parameter: export GATEWAY_URL = $( oc -n istio-system get route istio-ingressgateway -o jsonpath = '{.spec.host}' )","title":"Deploying Workloads"},{"location":"service-meshv2/2-deplying-workloads/#adding-default-destination-rules","text":"To add destination rules, run one of the following commands: oc apply -n bookinfo -f https://raw.githubusercontent.com/rh-mobb/aro-hackathon-content/main/aro-content/assets/destination-rule-all.yaml You should see output similar to the following: destinationrule.networking.istio.io/productpage created destinationrule.networking.istio.io/reviews created destinationrule.networking.istio.io/ratings created destinationrule.networking.istio.io/details created","title":"Adding default destination rules"},{"location":"service-meshv2/2-deplying-workloads/#verifying-the-bookinfo-installation","text":"Verify that all pods are ready with this command: oc get pods -n bookinfo All pods should have a status of Running. You should see output similar to the following: NAME READY STATUS RESTARTS AGE details-v1-55b869668-jh7hb 2 /2 Running 0 12m productpage-v1-6fc77ff794-nsl8r 2 /2 Running 0 12m ratings-v1-7d7d8d8b56-55scn 2 /2 Running 0 12m reviews-v1-868597db96-bdxgq 2 /2 Running 0 12m reviews-v2-5b64f47978-cvssp 2 /2 Running 0 12m reviews-v3-6dfd49b55b-vcwpf 2 /2 Running 0 12m Run the following command to retrieve the URL for the product page: echo \"http:// $GATEWAY_URL /productpage\" Copy and paste the output in a web browser to verify the Bookinfo product page is deployed.","title":"Verifying the Bookinfo installation"},{"location":"service-meshv2/2-deplying-workloads/#verify-in-kiali","text":"Kiali Dashboard","title":"Verify in Kiali"},{"location":"setup/access-cluster/","text":"Access the OpenShift Console and CLI # Login to the OpenShift Web Console # First, let's ensure that your workshop environment has our helper variables configured. To do so, let's run the following command: env | grep -E 'AZ_|OCP' You should see a list of variables including AZ_USER and OCP_CONSOLE . Helper Variables We use helper variables extensively throughout this workshop, but we also include the commands we used to populate these helper variables to ensure you can craft these commands later. To access the OpenShift CLI tools ( oc ) and web console you will need to retrieve your cluster credentials. The helper variables from above will make this simple! To retrieve the credentials, run the following command: az aro list-credentials --name \" ${ AZ_ARO } \" --resource-group \" ${ AZ_RG } \" Next retrieve the console URL by running the following command: az aro show --name \" ${ AZ_ARO } \" --resource-group \\ \" ${ AZ_RG } \" -o tsv --query consoleProfile Finally, open the link to the console provided in a separate tab, and login with the provided credentials. Login to the OpenShift CLI # Now that you're logged into the cluster's console, return to your Azure Cloud Shell. To login to the cluster using the OpenShift CLI tools ( oc ), first we need to retrieve the API server endpoint. To do so, run the following command: az aro show -g \" ${ AZ_RG } \" -n \" ${ AZ_ARO } \" --query apiserverProfile.url -o tsv Now that we've captured the API server endpoint, we can login to the cluster by running the following command: oc login \" ${ OCP_API } \" -u \" ${ OCP_USER } \" -p \" ${ OCP_PASS } \" Once logged in, you'll see output that looks like this: Login successful. You have access to 68 projects, the list has been suppressed. You can list all projects with 'oc projects' Using project \"default\" . Congratulations, you're now logged into the cluster and ready to move on to the workshop content.","title":"Access cluster"},{"location":"setup/access-cluster/#access-the-openshift-console-and-cli","text":"","title":"Access the OpenShift Console and CLI"},{"location":"setup/access-cluster/#login-to-the-openshift-web-console","text":"First, let's ensure that your workshop environment has our helper variables configured. To do so, let's run the following command: env | grep -E 'AZ_|OCP' You should see a list of variables including AZ_USER and OCP_CONSOLE . Helper Variables We use helper variables extensively throughout this workshop, but we also include the commands we used to populate these helper variables to ensure you can craft these commands later. To access the OpenShift CLI tools ( oc ) and web console you will need to retrieve your cluster credentials. The helper variables from above will make this simple! To retrieve the credentials, run the following command: az aro list-credentials --name \" ${ AZ_ARO } \" --resource-group \" ${ AZ_RG } \" Next retrieve the console URL by running the following command: az aro show --name \" ${ AZ_ARO } \" --resource-group \\ \" ${ AZ_RG } \" -o tsv --query consoleProfile Finally, open the link to the console provided in a separate tab, and login with the provided credentials.","title":"Login to the OpenShift Web Console"},{"location":"setup/access-cluster/#login-to-the-openshift-cli","text":"Now that you're logged into the cluster's console, return to your Azure Cloud Shell. To login to the cluster using the OpenShift CLI tools ( oc ), first we need to retrieve the API server endpoint. To do so, run the following command: az aro show -g \" ${ AZ_RG } \" -n \" ${ AZ_ARO } \" --query apiserverProfile.url -o tsv Now that we've captured the API server endpoint, we can login to the cluster by running the following command: oc login \" ${ OCP_API } \" -u \" ${ OCP_USER } \" -p \" ${ OCP_PASS } \" Once logged in, you'll see output that looks like this: Login successful. You have access to 68 projects, the list has been suppressed. You can list all projects with 'oc projects' Using project \"default\" . Congratulations, you're now logged into the cluster and ready to move on to the workshop content.","title":"Login to the OpenShift CLI"},{"location":"setup/environment/","text":"The Workshop Environment You Are Using # Your workshop environment consists of several components which have been pre-configured and are ready to use. This includes a Microsoft Azure account, an Azure Red Hat OpenShift cluster, and many other supporting resources. To access your working environment, you'll need to log into the Microsoft Azure portal by clicking here . When prompted, you'll log in with the credentials provided by the workshop team. Log out of existing Microsoft Azure sessions While these commands can be run in any Microsoft Azure account, we've completed many of the prerequisites for you to ensure they work in the workshop environment. As such, we recommend ensuring that you are logged out of any other Microsoft Azure sessions. Pre-created Resources # Resource Group vNet (with two subnets) Azure Red Hat OpenShift Cluster Azure AD Service Principal Azure DNS Zone Access Azure Cloud Shell # Azure Cloud Shell is an interactive, authenticated, browser-accessible shell for managing Azure resources. In this workshop, we'll use Azure Cloud Shell extensively to execute commands. First, go ahead and skip the tour of the Azure Portal by clicking the Maybe Later button. To start Azure Cloud Shell, click on the >_ button at the top right corner of the Azure Portal. Once prompted, select Bash from the Welcome screen. On the next screen, you'll receive a message that says \"You have no storage mounted\". Select the Show advanced settings link. While we've pre-created a number of resources, including a storage account for you to use with Azure Cloud Shell, you'll need to configure Azure Cloud Shell using the table below. Option Value Example Subscription Red Hat Cloud Services - Microsoft Azure Sponsorship N/A Cloud Shell region East US N/A Show VNET isolation settings Leave Unchecked N/A Resource group user#-rg (Select Use Existing Button) user2-rg Storage account user#atl (Select Create New Button) user2atl File share clouddrive (Select Create New Button) N/A Your options should look like the screenshot below once filled out: Once completed, click on the Create Storage button to start your Azure Cloud Shell session. When your shell is ready and you are at the bash prompt, run the following command to prepare your Cloud Shell environment for the remainder of the workshop: curl https://ws.mobb.cloud/assets/cloudshell-setup.sh | bash You will see a significant amount of output as the script prepares your environment for the workshop. Once it is complete follow its instructions and source the ~/.workshoprc file which contains credentials and other useful environment variables for your cluster. source ~/.workshoprc Congratulations, your Azure Cloud Shell is now configured and you're ready to move on to the next page.","title":"Environment"},{"location":"setup/environment/#the-workshop-environment-you-are-using","text":"Your workshop environment consists of several components which have been pre-configured and are ready to use. This includes a Microsoft Azure account, an Azure Red Hat OpenShift cluster, and many other supporting resources. To access your working environment, you'll need to log into the Microsoft Azure portal by clicking here . When prompted, you'll log in with the credentials provided by the workshop team. Log out of existing Microsoft Azure sessions While these commands can be run in any Microsoft Azure account, we've completed many of the prerequisites for you to ensure they work in the workshop environment. As such, we recommend ensuring that you are logged out of any other Microsoft Azure sessions.","title":"The Workshop Environment You Are Using"},{"location":"setup/environment/#pre-created-resources","text":"Resource Group vNet (with two subnets) Azure Red Hat OpenShift Cluster Azure AD Service Principal Azure DNS Zone","title":"Pre-created Resources"},{"location":"setup/environment/#access-azure-cloud-shell","text":"Azure Cloud Shell is an interactive, authenticated, browser-accessible shell for managing Azure resources. In this workshop, we'll use Azure Cloud Shell extensively to execute commands. First, go ahead and skip the tour of the Azure Portal by clicking the Maybe Later button. To start Azure Cloud Shell, click on the >_ button at the top right corner of the Azure Portal. Once prompted, select Bash from the Welcome screen. On the next screen, you'll receive a message that says \"You have no storage mounted\". Select the Show advanced settings link. While we've pre-created a number of resources, including a storage account for you to use with Azure Cloud Shell, you'll need to configure Azure Cloud Shell using the table below. Option Value Example Subscription Red Hat Cloud Services - Microsoft Azure Sponsorship N/A Cloud Shell region East US N/A Show VNET isolation settings Leave Unchecked N/A Resource group user#-rg (Select Use Existing Button) user2-rg Storage account user#atl (Select Create New Button) user2atl File share clouddrive (Select Create New Button) N/A Your options should look like the screenshot below once filled out: Once completed, click on the Create Storage button to start your Azure Cloud Shell session. When your shell is ready and you are at the bash prompt, run the following command to prepare your Cloud Shell environment for the remainder of the workshop: curl https://ws.mobb.cloud/assets/cloudshell-setup.sh | bash You will see a significant amount of output as the script prepares your environment for the workshop. Once it is complete follow its instructions and source the ~/.workshoprc file which contains credentials and other useful environment variables for your cluster. source ~/.workshoprc Congratulations, your Azure Cloud Shell is now configured and you're ready to move on to the next page.","title":"Access Azure Cloud Shell"}]}